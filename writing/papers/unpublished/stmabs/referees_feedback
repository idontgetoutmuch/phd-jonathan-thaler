19-Mar-2019

Dear Mr. Thaler:

I write you in regards to manuscript # TOMACS-2018-0105 entitled "A Tale Of Lock-Free Agents - The potential of Software Transactional Memory in parallel ABS" which you submitted to the Transactions on Modeling and Computer Simulation.

In view of the evaluation of the reviewers found at the bottom of this letter, your manuscript has been denied publication in the Transactions on Modeling and Computer Simulation.

Thank you for considering the Transactions on Modeling and Computer Simulation for the publication of your research.  I hope the outcome of this specific submission will not discourage you from the submission of future manuscripts.

Best Regards,
Adelinde Uhrmacher
Editor in Chief, Transactions on Modeling and Computer Simulation
adelinde.uhrmacher@uni-rostock.de


====================
Editor's Comments to Author
====================
Associate Editor
Comments to the Author:
The paper presents and analyses two toy agent-based benchmark models using Haskell as the programming language to investigate the performance of Software Transaction Memory in this context, and therefore the suitability of Haskell for parallel agent-based modelling. 

In addition to the detailed comments provided by the reviewers I have the following concerns with the paper: 

 (a) The contextual positioning of the work and the related work 
The paper fails to demonstrate knowledge in the current state of the art in the field.  This is manifested for instance by the statement on PDES (lines 899-901) in the future research section and that such an approach could be theoretically implemented. PDES has been applied extensively for agent-based modelling for almost 20 years now. The parallelisation of agent-based models raises important issues regarding data distribution and query management, interest management, synchronisation, load balancing etc and there have been significant advances and some very sophisticated work by the PDES community in this directions for both shared memory and distributed memory platforms. A pioneering effort to study in depth event-driven, asynchronous decentralised simulation of agents models back in late 1990s/early 2000s have been the PDES-MAS system which was the first to apply optimistic synchronisation as envisioned by the paper - see papers DOI: 10.1016/j.procs.2013.05.231, DOI: 10.1109/5.910853, DOI:10.1177/0037549708096691  and DOI:  10.1145/2517449.  Other early efforts in this direction have been SPADES (dl.acm.org/citation.cfm?id=1030926), MACE3J (DOI: 10.1145/544862.544918), James II (DOI: 10.1109/ANSS.2007.34), and RePast-HLA which has ported RePast on HLA (DOI:10.1002/cpe.1280.). RepastHPC (that the paper mentions) also uses PDES – both conservative and optimistic (DOI: 10.22360/SpringSim.2016.HPC.046) should give the authors an insight and a starting point. Note also that hardware transactional memory has been investigated in the context of PDES (e.g. DOI: 10.1145/2769458.2769462), not for agents though. A survey of agent simulation toolkits is DOI:10.1016/j.cosrev.2017.03.001

Another indicative statement is at lines 888-889: sense-think-act was not introduced in [31] but it has been the predominant agent/robot control methodology since the 1980s at least. The aforementioned papers actually use and exploit the sense-think-act feature. The solution not to interfere with global state is not the sense-think-act as such but what is collectively known as interest management: DOI: 10.1145/2535417. 

I suggest the authors perform a proper literature review, update their related work and future research section and properly position and contrast their work with the current state of the art. 
 
 (b) the experimental analysis is superficial and limited and the reviewers have provided some detailed comments on this. 

For RePast the HPC version of it would be more suitable, an earlier version supported shared-memory too and would provide a better baseline.  Also why use the provided statechart and not develop the benchmark from scratch in RePast?

The explanation about RePast performance in lines 386-428 does not seem plausible. JVM introduces a lot of overhead and in anycase this is cannot be a scenario to compare two languages are there are some many more parameters involved. RePast is a discrete  event simulation engine so it may be that the RePast model the authors are using is event-driven and therefore much faster to execute? In line 523, do the authors really compare STM with Java Repast or a time driven model with an event-driven one?

Line 516-517: nondeterminism is not a result of STM but a result of parallelism. 

Table 2: what is the metric used?
I would expect to see a more thorough analysis to extract deeper insights about the behaviour of the system and explain these results – i.e. CPU utilisation, bus and memory/cache usage, messages exchanged, state variables accessed etc. Also larger models to demonstrate scalability and tipping points, proper speedup metrics and a comparison with a PDES model.

(c) Other points:

-Line 105: not clear what concurrent message passing is

-Line 266-269: A time-driven approach to simulation where simulated time advances in time increments of fixed constant size and processes are time-stepped is a basic concept in discrete event simulation since its conception. Are the authors seriously claiming that they introduced this concept in their [27] paper?

- Section 4 – STM is ABS, is central to the work however this is very short and superficial. One would expect to see here the internal architecture of the agent, the actions it performs, and the way it accesses state and explain how these map to (a) Haskell and (b)the STM model as well as the architecture of the simulation. 

Since the performance results presented here indicate that this approach does not yield good speedup it may seem that its future is not promising. However the insights and the lessons learnt for such an experimental analysis with Haskell is useful to future modellers. I therefore encourage the authors to revise their paper and resubmit. I hope they will find the comments and pointers in the reviews useful in this endeavour.

======================
Reviewers' Comments to Author
======================
Referee: 1

Comments to the Author
Summary of content: the manuscript evaluates the performance achievable using software-transactional memory (STM) for orchestrating the access to a shared environment in agent-based simulations. Different implementations in the Haskell programming language are compared to a lock-based approach as well as the established simulator RePast. The considered case studies are a SIR model and Sugarscape. Overall, the STM approach outperforms the lock-based approach, in particular when carrying out transactions on individual cells of the simulation space instead of globally.

Overall evaluation: the authors are investigating a very interesting subject. STM may relieve modelers of much of the complexities when parallelizing agent-based models. The manuscript is well-structured and reasonably well-written. However, there are issues with the interpretation of the results, as well as some important aspects that need clarification. In particular, to allow the reader to draw reliable conclusions, the experiments and their interpretation should clearly separate the effects of using Haskell from those of relying on STM. I suggest a major revision to improve these aspects (detailed below).


--- Interpretation of results ---

I take the description of the lock-based approach on pages 7 and 13 to mean that there is a single global lock protecting accesses to the environment, shared by all threads. If that is the case, this naive approach is obviously not scalable. While the comparison with the TVar approach seems fair, the authors conclude in Section 6.6 "A well implemented STM approach with a carefully selected transactional data-structure consistently outperforms the lock-based approach and scales up to multiple cores considerably better." The most substantial performance differences were seen when comparing a global lock to STM based on TArray orchestrating the access to individual cells. A fair comparison would require a comparison to fine-grained locking, e.g, on a cell-by-cell basis. The locking overhead may still allow STM to outperform the lock-based approach, but that is not known at this time.

Considering Table 3, both STM and lock-based achieve the same near-linear scaling with the problem size: when multiplying the number of cells by 4, the simulation takes 4 time as long. 

The caption of Figure 3 states "Note that the Lock-Based implementation performs worse on 4 than on 3 cores due to lock-contention." This is not supported by the numbers, which show the that 4 cores outperform 3 cores for all but the smallest scenario size, where the difference is < 10%.

Given that the lock-based approach scales linearly (i.e., perfectly), its worse performance compared to STM seems to be due to a base overhead for acquiring locks (or some other difference to the STM implementation) rather than related to lock contention.

The results for RePast are surprising: on a single core, multiplying the cell number by 4 increases the simulation time by a factor of 10. This warrants further investigation. It seems likely that a simple profiling can explain this inefficiency.



In Section 6.6, the authors state: "Selecting the right transactional data-structure is very model-specific and can lead to dramatically different performance results. In this case the TArray performed best due to many writes but in the SIR case-study a TVar showed good enough results due to the very low number of writes."

The conclusion drawn in the first sentence is not supported by the second sentence. TArray may have performed just as well in the SIR study. In that case, TArray would always be the best choice. It was not clear to me from the text why TArray was not tried in the SIR example.


--- Interaction between Haskell concepts and results ---

It is not very clear how the properties of Haskell affect the observed results. In particular, the focus on Haskell seems to need better justification. In Section 3.2.3, the authors state "[...] we argue, that it is in Haskell with its type-system and the way how side-effects are treated where it truly shines." It might be that the argument is the aim to separate pure computation from state changes, which is shared both by Haskell and the STM concept, but even then it is not clear whether this is an argument towards usability, reduction of code complexity. avoidance of deadlocks, performance, or some other aspect. This should be clarified. The remainder of the manuscript itself is concerned only with performance.

Since STM libraries are available for other languages as well, it would have been very interesting to see a comparison between a lock-based and STM implementation in a language more commonly used in a high-performance context. This would separate the differences in performance due to language/compiler differences and due to locking vs. STM.

The authors stress the lazy evaluation of Haskell programs and state on page 16: "We hypothesize that due to Haskells laziness the agents actually never look at the content of the cells in this case but only the number which means that the cells themselves are never evaluated which further increases performance." This seems like a very interesting aspect, but it is not investigated further. Further, it is not clear in which situations avoiding computations using lazy evaluation would be possible in the agent-based simulation context.

--- Correctness ---

On page 13, the authors state: "The model specification requires to shuffle agents before every step (Footnote 12 on page 26 [7]).  In the Sequential approach we do this explicitly but in the Lock-Based and both STM approaches this happens automatically due to race-conditions in concurrency thus we arrive at an effectively shuffled processing of agents: we implicitly assume that the order of the agents is effectively random in every step. Not making assumptions of the ordering of thread execution is a core principle of concurrent programming, which we exploit in this case to assume an effective randomness. The important difference between the two approaches is that in the Sequential approach we have full control over this randomness but in the STM not - also this means that repeated runs with the same initial conditions might lead to slightly different results."

This decision leads to the execution order among agents being ignored, which is problematic because it leads to indeterminism (as the authors acknowledge) as well as bias in the simulation results; in effect, the scheduling of agent actions is deferred to the scheduling policy for Haskell's logical threads and the scheduling policy for the underlying OS-level threads. Both policies are unlikely to produce uniform distributions. This is further complicated by aspects such as the time taken by threads to perform their actions as well as jitter, making it unlikely that randomness in any meaningful sense can be achieved.

Of course, this aspect is not the main focus of the article, but at minimum there should be an evaluation of the simulation output statistics to check for a reasonable correspondence among the simulator implementations. Further, the underlying subject of update order and conflict resolution is central enough to the manuscript to deserve a dedicated discussion, particularly since there is a tension between correctness and performance. The related work section currently focuses on STM and Haskell. In my view, the problem of contention for the agents' environment, for which the lock-based and STM approach provide solutions, should be discussed first.

Unfortunately, there is also an instance of faulty reasoning in the sentence "Not making assumptions of the ordering of thread execution is a core principle of concurrent programming, which we exploit in this case to assume an effective randomness."
The cited principle is commonly understood to express the exact opposite: programs should produce the same results regardless of the thread execution order. Requiring the order to be (uniformly) random is a violation of this principle.



Minor points:
  - Section 6.3 "Scaling up Agents" might be better phrased as "Scaling up the Number of Agents" or "Scaling up Agent Count". Similarly, Section 6.2 "Constant Agent Size"
  - The label text in the plots should be enlarged.
  - colloquial wording (p.8: "What comes a bit as a surprise is, [...]", p.5: "all bets are off because everything is possible", p.18: "indisputable benefits of using STM"), contractions ("doesn't" etc)
  - p15: "[...] the ability to terminate and fork threads dynamically [...]": the term forking typically refers to process creation through copying.
  - p17: "The very high performance on the GPU does not concern us here as it follows a very different approach than ours. We focus on speeding up implementations on the CPU as directly as possible without locking overhead. When following a GPU approach one needs to map the model to the GPU which is a delicate and non-trivial matter. With our approach we show that speed up with concurrency is very possible without the low-level locking details or the need to map to GPU.  Also some features as bilateral trading between agents, where a pair of agents needs to come to a conclusion over multiple synchronous steps, is difficult to implement on a GPU whereas this is easily possible using STM." This paragraph has two issues: 1. "speedup is possible": given that speedup is a quantitative measure, this is a weak statement. The relevant aspect is the simulation running time given the cost in terms of hardware resources or energy. 2. Some specific simulation aspects are mentioned to be difficult to implement on a GPU, but it is not stated why this is so. Maybe a discussion can be found in [16] cited in Section 8, but the discussion on p.17 does not make that clear (nor does it cite that paper).
  - p11: "Amazon S2" is possibly supposed to be "Amazon EC2" or "Amazon S3"
  - Table 4: the "Ratio" column could be reported in scientific notation to indicate whether it changes with the grid size. The constant ratio of 0.0 could otherwise simply be reported in the text.


Referee: 2

Comments to the Author
Overall comments:

Overall, the paper tries to thread a needle, in that it is presenting a topic that is not of general interest to computer scientists, for whom STM is not novel, or to researchers applying agent-based modeling approaches, who would be most likely utilizing existing open source or proprietary ABM toolkits, but rather to those who are intimately involved in developing the software that enables ABMs. As such, the considerations that go into the appropriateness of this paper for TOMACS fall into the following categories of questions:
a) Is this of broad enough interest for the general TOMACS readership?
b) Is this work innovative or compelling for ABM software developers? 

I would defer to the editors for a definitive answer to a), but my sense is that this is too much of a niche topic to be of general interest. Part of this sense is due to the fact that the authors rely heavily on their own pre-existing work or existing literature on STM-related topics for developing a comprehensive description of the topic area. The authors fail to, in my opinion, create a compelling case within the article for why a general TOMACS reader would be interested in the topic, and instead  seem to rely on the reader to seek out external sources for a topic that they may not know enough to be interested in.

As for b), I'm not sure that the authors sufficiently motivated the issues with parallel programming that exist in Python, Java and C++. In the introduction, the authors state:
"Unfortunately the established imperative languages in the ABS field, Python, Java, C++, follow mostly a lock-based approach to concurrency which is error prone and does not compose."
Regarding the first statement, yes, concurrency is more difficult than not using parallelism, but there are now plenty of abstractions, in the form of libraries or base language constructs, that allow programmers to exploit multi-core architectures quite easily in all of the mentioned programming languages. So a deeper dive into why ABM developers should care about the benefits that the presented flavor of parallelism would be helpful. Regarding the "does not compose" part, this appears to be a very specific reference to atomic operations, which STM does enable, but I don't recall a compelling case being made for why ABM developers would find this particular capability (at times described as difficult, and others as impossible [see below]) to be critical, and not just, say, helpful for specific applications.
The authors continue:
"Further, data-parallelism in an imperative language is susceptible to side-effects because these languages cannot distinguish between data-parallelism and concurrency in the types."
Here again, I would have liked to see why this is critical and not just a "convenient to have" feature for ABM.

Furthermore, the final "product" is not a performant version of currently available capabilities but rather a theoretical description of the possibility that STM and functional approaches, if implemented in more performant languages than Haskell, could yield benefits to ABM developers. Here too, the authors ask these prospective adopters of STM to accept that the evidence provided is compelling and then to proceed to implement it into their models/toolkits. So a compelling enough case needs to be made to overcome the "activation threshold" of the adoptees.

Finally, in the opinion of this reviewer, the analysis gives the impression that this is a report of work in progress rather than something that is ready for publication for the general readership of a publication like TOMACS.

The following are more detailed comments that may help strengthen the paper:

Abstract

- One CCS Concept used to describe the work is "Massively parallel and high- performance simulations". This is somewhat misleading since the experiments are done on single nodes and only up to 32 cores. If one takes a look at publications under that heading, they seem to be about HPC-resource based work (https://dl.acm.org/ccs/ccs.cfm?id=10010362&lid=0.10010147.10010341.10010349.10010362) 

- The authors refer to the use of AWS resources, but these are essentially used as large, local multi-core CPUs, so the fact that these are cloud resources isn't really relevant. To make the message of the relevant content in the paper more accurate, I would suggest removing references to AWS in the abstract.

Section 1. Introduction
- "Amazon S2" -> "Amazon EC2"?

- The authors indicate that they will only "hypothesise that the reduced complexity and increased performance will be directly applicable to ABS as well" but I would like this to be more of a demonstration that this is likely to be true.

- The authors state:
"Our contribution is that to the best of our knowledge we are the first to systematically investigate the use of STM in ABS and compare its performance with sequential, lock-based and imperative implementations both on local and Amazon Cloud Service machinery."
I would suggest that the authors focus on sequential, lock-based and STM-based approaches. If there is a need to compare with existing ABM tools, I would suggest that the broad description of them as simply "imperative implementations" needs to be more nuanced. Also see my comments elsewhere about calling out AWS specifically and doing all the experiments on AWS resources.

Section 2. Related Work
- This section seems out of place as it introduces complex topics that are yet to be defined and would be confusing to a reader. I suggest that at the very least this section is moved past the Background section, if not later in the paper.


Section 3. Background

"Worse, concurrency does not compose. It is very difficult to write two functions (or methods in an object) acting on concurrent data which can be composed into a larger concurrent behaviour. The reason for it is that one has to know about internal details of locking, which breaks encapsulation and makes composition dependent on knowledge about their implementation. Therefore, it is impossible to compose two functions e.g. where one withdraws some amount of money from an account and the other deposits this amount of money into a different account: one ends up with a temporary state where the money is in none of either accounts, creating an inconsistency - a potential source for errors because threads can be rescheduled at any time."
This is somewhat sloppy writing. First the authors state that composition is difficult because it breaks encapsulation. The following sentence proceeds to declare it to be an impossible task.

The paragraph starting with, "[i]n the paper [11] the authors use a model of STM..." seems out of place, and might better fit in a related work section.

The authors provide a lot of information about the benefits of Haskell itself, but later in the paper indicate that it may not be as performant as other languages commonly used in ABM development. To avoid confusion, the authors might focus on the benefits of STM rather than those found in Haskell itself, if the main message is that people should adopt STM techniques.
 
Section 5. CASE STUDY 1: SPATIAL SIR MODEL

It's unclear what the role of communication is in SIR model. More importantly, I didn't see a description of the model details in the paper. I think it's unrealistic to expect a reader to go elsewhere for the details of what looks to be a pretty simple model, if that's the authors' intent. Given the importance to the subsequent analyses, there needs to be a sufficiently detailed model description included.

Regarding the comparison to Repast (Simphony) [Note: The authors incorrectly refer to the Java-based toolkit as RePast. Repast refers to the suite of ABM toolkits, including Repast Simphony and Repast HPC. Furthermore, Repast does not have its "p" capitalized. See https://repast.github.io .], the authors state the following:
"Although there exists a RePast High Performance Computing library for implementing large-scale distributed simulations in C++, we leave this for further research as an implementation and comparison is out of the scope of this paper."
While it is true that Repast HPC can be used to distribute agents across computing nodes for very large-scale simulations (and so is reasonably stated to be out of scope for this investigation of only multi-core parallelism), this statement seems leaves out the parallelism that can be implemented using various Java means within Repast Simphony, when targeting individual computing nodes with multiple cores. I would suggest to state that the implementation that was chosen for comparison in this paper was a non-parallel implementation done with Repast Simphony, but not suggest that parallel implementations would require the use of Repast HPC.

"Each experiment was run until t = 100 and stepped using ∆t = 0.1 except in RePast for which we don’t have access to the underlying implementation of the state-chart and left it as it is." 
It's unclear what this statement means. Furthermore, if there was not much control over the software, a reader would wonder why this was even included for a comparison. The authors state that it provides an estimate of "single core performance of imperative approaches" but that is hard to take at face value. This is measuring Java performance within Repast Simphony, but how does that compare to, e.g., Scala/Java performance in NetLogo, or C++ performance with Repast HPC, and what is the reader meant to take away from the comparison? I would suggest thinking about whether this comparison is needed at all. 

For the lock-based scenario, it was not clear to me whether the lock is being used for both reading and writing, and if it's for both, an explanation as to why individual reads need to be synchronized with other reads would be helpful.

If the goal was to just compare model performance, the Repast implementation should probably be run in a headless fashion, without any GUI updating. This just further confuses the need for this comparison.

Also, if performance is one of the key takeaways of this study, this statement doesn't help the message:
"Also, we build on the concepts developed in [26] to implement our ABS which make heavy use of Functional Reactive Programming, which can be substantially slower than imperative approaches [12, 20]."

Regarding the "Going Large-Scale" subsection, I would suggest that some readers would take issue with labeling 32 cores as large-scale when we have 64 and larger core technologies proliferating. Furthermore, since this is not really about cloud computing, why not side-step this whole issue and just run all of the experiments on AWS instances, from 1 through 32?

Section 6. CASE STUDY 2: SUGARSCAPE

The analysis in subsection 6.3 Scaling up Agents points to a need for coming up with better experiments for conveying a cleaner story with a clear takeaway. The reader is left with discussions about lazy evaluations, full grids, etc. when I don't believe that those are central points to the story.


Referee: 3

Comments to the Author
Summary
The paper proposes some studies devoted to assessing performances of lock-based and STM-based implementation of concurrent agent-based programs.  Performances were evaluated by considering a variable number of agents and by both considering a variable number of CPUs on a single machine, and an execution runtime environments based on Amazon Cloud Services. The functional language Haskell was used for implementation purposes. For assessing performances, two case studies were purposely proposed, a first one based on a spatial SIR model, and a second one based on a Sugarscape model. Sequential execution of such models, based on the RePast toolkit, was also considered for performance comparison.

Evaluation
The topic of the paper is interesting. Anyway, the paper as it was submitted suffers from many drawbacks as listed in the following. 
-It seems a little bit strange and confusing that Java-based RePast models were considered for comparative studies, especially given the fact that lock-free data structures are also available in Java (as well as in other programming languages) but this kind of data structures are not considered at all. Why comparing Java and Haskell?
-The statement “Unfortunately the established programming languages in the field, Python, Java, and C++, are not very well suited to tackle the complexities of parallel programming” is wrong in my opinion. For instances, Java (starting from version 5) offers a lot of data structures for dealing with parallel and distributed programs. If authors think the sentence is valid, it requires to be strongly motivated and contextualized. 
-Within the Background section:
(-) race conditions occur when multiple agents act concurrently (this is not tied to forgotten locks)
(-) deadlocks can occur not only for inconsistent lock ordering but also for forgotten locks
(-) a wrong use of locks really can cause a “break in encapsulation”, correct management of locks avoid this issue
-Very few details are provided about the models used for studying performances. It remains unclear how locks and how STM data structures are really used. It also remains unclear how STM data structures can be really exploited to write parallel programs (e.g., in order to simplify program writing). Code snippets are required in order to deal with these issues.
-It seems that a “single lock” is used to regulate the access to the shared environment in the   Sugarscape and SIR models. In such a way, the whole program tends to behave like a sequential program because no agents can access the shared data in parallel. This is a very unfear approach: if locks are used in a naif way, their performances drastically degrade. A more appropriate lock management is required (e.g., what happens if a single lock is used for each cell in the environment?).
-The obtained experimental results require to be better described and motivated when performances of locks and STM programs are compared. Confidence intervals require to be added.   
-Concepts like lock usage, STM, rollbacks, ABS, optimistic synchronization, laziness, and so forth should be adequately introduced. Also, some insight about SIR models and Sugarscape should be provided within the introduction. 
-The introduction should be improved by adding more bibliographic references about important topics like ABS, concurrency problems, and so forth.
-The related work section should be improved and extended by adding other approaches facing with concurrency issues. Many sentences remain unclear.
-Usually, agents interact via message passing and not through shared data. The use of shared data should be better motivated (e.g., for performers reasons) 
-Within the reported tables, the unit of measures should be added (e.g., seconds). In Table 4, a Ration equals to “0” is misleading, please use a notation (e.g., percentage)  that solves this problem. 
-The sentence “Interestingly, STM primitives map nicely to ABS concepts” should be better motivated. 
-In the section “Further Research” it should be better described how to map the approach in a distributed context. I think this is not an easy task because when moving toward the use of messages, the need for using shared variables reduce or disappear. How the authors think to deal with these issues?
  
Useful References to read:
[1] Tim Peierls, Brian Goetz, Joshua Bloch, Joseph Bowbeer, Doug Lea, and David Holmes. 2005. Java Concurrency in Practice. Addison-Wesley Professional.  
[2] Cicirelli, F., Giordano, A., & Nigro, L. (2015). Efficient environment management for distributed simulation of large‐scale situated multi‐agent systems. Concurrency and Computation: Practice and Experience, 27(3), 610-632.

