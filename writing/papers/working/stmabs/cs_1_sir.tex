\section{Case Study 1: Spatial SIR Model} %(First Encounter)
\label{sec:cs_sir}

Our first case study is the SIR model which is a very well studied and understood compartment model from epidemiology \cite{kermack_contribution_1927}, which allows to simulate the dynamics of an infectious disease like influenza, tuberculosis, chicken pox, rubella and measles spreading through a population \cite{enns_its_2010}.

In it, people in a population of size $N$ can be in either one of three states \textit{Susceptible}, \textit{Infected} or \textit{Recovered} at a particular time, where it is assumed that initially there is at least one infected person in the population. People interact \textit{on average} with a given rate of $\beta$ other people per time unit and become infected with a given probability $\gamma$ when interacting with an infected person. When infected, a person recovers \textit{on average} after $\delta$ time units and is then immune to further infections. An interaction between infected persons does not lead to re-infection, thus these interactions are ignored in this model. 

We followed in our agent-based implementation of the SIR model the work \cite{macal_agent-based_2010} but extended it by placing the agents on a discrete 2D grid using a Moore (8 surrounding cells) neighbourhood \cite{thaler_pure_2018}. A visualisation can be seen in Figure \ref{fig:vis_sir}.

Due to the continuous-time nature of the SIR model, our implementation follows the time driven \cite{meyer_event-driven_2014} approach. This requires us to sample the system with very small $\Delta t$, which means that we have comparatively few writes to the shared environment which will become important when discussing the performance results.

\subsection{Experiment Design}
In this case study we compare the performance of five (5) implementations under varying numbers of CPU cores and agent numbers. The code of all implementations can be accessed freely from the \href{https://github.com/thalerjonathan/haskell-stm-sir}{repository}~\cite{thaler_stm_sir_repository}.

\begin{enumerate}
	\item Sequential - This is the original implementation as discussed in \cite{thaler_pure_2018} where the discrete 2D grid is shared amongst all agents as read-only data and the agents are executed sequentially within the main thread without any concurrency.
	
	\item Lock-Based Naive - This is exactly the same implementation as the \textit{STM} one, but instead of running in the \texttt{STM} context, the agents now run in the \texttt{IO} context. They share the discrete 2D grid using a reference and have access to a lock to synchronise access to the reference.

	\item Lock-Based Read-Write Lock - This is the same implementation as \textit{Lock-Based Naive} but uses a read-write lock from the \href{http://hackage.haskell.org/package/concurrent-extra}{concurrent-extra library}~\cite{concurrent_extra_library} for a more fine-grained locking strategy, exploiting the fact that in the SIR model reads outnumber the writes by far, making a read-write lock much more appropriate.

	%\item Lock-Based Advanced - This is the same implementation as \textit{Lock-Based Naive} but instead of holding the lock unconditionally, it distinguishes more granularly between an unconditional read scenario and a conditional write scenario: it acquires and releases the lock to read the shared environment and re-acquires and re-reads the environment in case a write becomes necessary. This works in this case study for two reasons: First, data in Haskell is immutable, therefore it is possible to read it from the reference and then perform lookups on it; Second, in the SIR model, every agent writes only to its position, therefore the lock does not to be held for the entire operation.
	
	\item Hybrid (Lock-Based Atomic) - This is the same implementation as \textit{Lock-Based Naive} but uses an atomic modification operation to both read and write the shared environment. Strictly speaking, this is not a lock-based approach as it does not acquire locks but uses a compare-and-swap hardware instruction. A limitation of this is approach is that it is only applicable when there is just a single reference in the program and all operations need to go through the atomic modification operation.

	\item STM - This is the same implementation as the \textit{Sequential} but agents run now in the \texttt{STM} context and have access to the discrete 2D grid through a transactional variable \texttt{TVar}. This means that the agents now communicate indirectly by reads and writes through the \texttt{TVar}.
	
\end{enumerate}

Each experiment was run on our machine (see Table \ref{tab:machine_specs}) under no additional workload until $t = 100$ and stepped using $\Delta t = 0.1$. In the experiments we varied the number of agents (grid size) as well as the number of cores when running concurrently - the numbers are always indicated clearly. We checked the visual outputs and the dynamics and they look qualitatively the same as the reference \textit{Sequential} implementation \cite{thaler_pure_2018}. A rigorous comparison of all implementations is quite involved and therefore beyond the focus of this paper but as a remedy we refer to the use of property-based testing, as shown in \cite{thaler_show_2019}.

For robust performance measurements we used the microbenchmarking library Criterion \cite{criterion_serpentine, criterion_hackage}. It allows the definition and running of benchmark suites, measuring performance by executing them repeatedly, fitting actual against expected runtime, reporting mean and standard deviation for statistically robust results. By running each benchmark repeatedly, fitting it using linear regression analysis, Criterion is able to robustly determine whether the measurements fall within a normal range or are outliers (and therefore should be re-run) due to some external influences like additional workload on the machine. Therefore, we made sure to only include measurements Criterion labelled as normal. Criterion ran each of our benchmark 10 times with increasing increments of 1, 2, 3 and 4 times. In the results we report the estimates of ordinary least squares (OLS) regression together with the standard deviation because it gives the most reliable results in terms of statistical robustness.

%For varying the number of cores we compiled the executable using the tool \textit{stack} with the \textit{threaded} option and executed it with \textit{stack} using the +RTS -Nx option where x indicates the number of cores. 

\begin{table}
	\centering
	\begin{tabular}{ c || c }
		OS & Ubuntu 19.10 64-bit \\ \hline
		RAM & 16 GByte \\ \hline
		CPU & Intel Core i7-8550U @ 3.6GHz x 8 \\ \hline
		HD & 512Gbyte SSD \\ \hline
		Haskell & GHC 8.4.3 (stack resolver lts-12.4)
	\end{tabular}
	
	\caption{Machine and software details for all experiments}
	\label{tab:machine_specs}
\end{table}

\subsection{Constant Grid Size, Varying Cores}
In this experiment we held the grid size constant to 51 x 51 (2,601 agents) and varied the cores where possible. The results are reported in Table \ref{tab:sir_varyingcores_constgrid} and visualised in Figure \ref{fig:sir_varyingcores_constgrid}.

%\begin{table}
%	\centering
%	\begin{tabular}{cc|c}
%		\multicolumn{1}{ c||  }{\multirow{2}{*}{} } &
%		\multicolumn{1}{ |c| }{Cores} & Duration       \\ \hline \hline 
%		
%		\multicolumn{1}{ c||  }{\multirow{1}{*}{Sequential} } &
%		\multicolumn{1}{ |c| }{1} & 73.9 (2.06)      \\ \hline \hline 
%		
%		\multicolumn{1}{ c||  }{\multirow{4}{*}{Lock-Based Naive} } &
%		\multicolumn{1}{ |c| }{1} & 59.2 (0.16)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{2} & 46.5 (0.05)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{3} & 44.2 (0.08)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{4} & 47.4 (0.12)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{5} & 48.1 (0.13)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{6} & 49.1 (0.09)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{7} & 49.8 (0.09)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{8} & 57.2 (0.06)  \\ \hline \hline 
%		
%		\multicolumn{1}{ c||  }{\multirow{4}{*}{Lock-Based Read-Write} } &
%		\multicolumn{1}{ |c| }{1} & 55.0 (0.22)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{2} & 40.8 (0.18)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{3} & 35.8 (0.06)   \\ \cline{2-3} 
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{4} & 34.0 (0.32)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{5} & 34.5 (0.06)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{6} & 34.8 (0.03)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{7} & 35.9 (0.15)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{8} & 40.4 (0.21)   \\ \hline \hline 
%		
%%		\multicolumn{1}{ c||  }{\multirow{4}{*}{Lock-Based Advanced} } &
%%		\multicolumn{1}{ |c| }{1} & 56.8 (0.71)   \\ \cline{2-3}
%%		\multicolumn{1}{ c||  }{}                       &
%%		\multicolumn{1}{ |c| }{2} & 41.7 (0.06)   \\ \cline{2-3}
%%		\multicolumn{1}{ c||  }{}                       &
%%		\multicolumn{1}{ |c| }{3} & 35.2 (0.05)   \\ \cline{2-3}
%%		\multicolumn{1}{ c||  }{}                       &
%%		\multicolumn{1}{ |c| }{4} & 32.5 (0.11)   \\ \cline{2-3}
%%		\multicolumn{1}{ c||  }{}                       &
%%		\multicolumn{1}{ |c| }{5} & 33.4 (0.02)   \\ \cline{2-3}
%%		\multicolumn{1}{ c||  }{}                       &
%%		\multicolumn{1}{ |c| }{6} & 34.6 (0.23)   \\ \cline{2-3}
%%		\multicolumn{1}{ c||  }{}                       &
%%		\multicolumn{1}{ |c| }{7} & 35.2 (0.16)   \\ \cline{2-3}
%%		\multicolumn{1}{ c||  }{}                       &
%%		\multicolumn{1}{ |c| }{8} & 40.2 (0.05)   \\ \hline \hline 
%		
%		\multicolumn{1}{ c||  }{\multirow{4}{*}{Hybrid (Lock-Based Atomic)} } &
%		\multicolumn{1}{ |c| }{1} & 51.0 (0.11)  \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{2} & 32.4 (0.09)  \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{3} & 25.5 (0.09)  \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{4} & 22.7 (0.08)  \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{5} & 22.6 (0.03)  \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{6} & 22.3 (0.09)  \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{7} & 22.8 (0.07)  \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{8} & 25.8 (0.02)  \\ \hline \hline 
%		
%		\multicolumn{1}{ c||  }{\multirow{4}{*}{STM} } &
%		\multicolumn{1}{ |c| }{1} & 52.2 (0.23)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{2} & 33.2 (0.03)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{3} & 26.4 (0.05)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{4} & 23.3 (0.19)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{5} & 23.0 (0.06)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{6} & 23.1 (0.05)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{7} & 23.4 (0.22)   \\ \cline{2-3}
%		\multicolumn{1}{ c||  }{}                       &
%		\multicolumn{1}{ |c| }{8} & 26.2 (0.22)   \\ \hline \hline 
%		
%%		\multicolumn{1}{ c||  }{\multirow{1}{*}{RePast} } &
%%		\multicolumn{1}{ |c| }{1} & \textbf{10.8}      \\ \hline \hline 
%	\end{tabular}
%  	
%  	\caption{SIR performance comparisons on 51x51 (2,601 agents) grid with varying number of cores. Timings in seconds (lower is better). Standard deviation in parentheses.}
%	\label{tab:constgrid_varyingcores}
%\end{table}

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c | c | c }
        Cores & Sequential  & Lock-Based Naive   & Lock-Based Read-Write & Hybrid    & STM             \\ \hline \hline 
   		1     & 73.9 (2.06) & 59.2 (0.16) &  55.0 (0.22) & 51.0 (0.11) & 52.2 (0.23) \\ \hline
   		2     & -           & 46.5 (0.05) &  40.8 (0.18) & 32.4 (0.09) & 33.2 (0.03) \\ \hline
   		3     & -           & 44.2 (0.08) &  35.8 (0.06) & 25.5 (0.09) & 26.4 (0.05) \\ \hline
   		4     & -           & 47.4 (0.12) &  34.0 (0.32) & 22.7 (0.08) & 23.3 (0.19) \\ \hline
   		5     & -           & 48.1 (0.13) &  34.5 (0.06) & 22.6 (0.03) & 23.0 (0.06) \\ \hline
   		6     & -           & 49.1 (0.09) &  34.8 (0.03) & 22.3 (0.09) & 23.1 (0.05) \\ \hline
   		7     & -           & 49.8 (0.09) &  35.9 (0.15) & 22.8 (0.07) & 23.4 (0.22) \\ \hline
   		8     & -           & 57.2 (0.06) &  40.4 (0.21) & 25.8 (0.02) & 26.2 (0.22) \\ \hline \hline
  	\end{tabular}

		
  	\caption{SIR performance comparisons on 51x51 (2,601 agents) grid with varying number of cores. Timings in seconds (lower is better). Standard deviation in parentheses.}
	\label{tab:sir_varyingcores_constgrid}
\end{table}

TODO: rewrite 
Comparing the performance and scaling to multiple cores of the \textit{STM} and \textit{Lock-Based} implementations shows that the \textit{STM} implementation significantly outperforms the \textit{Lock-Based} one and scales better to multiple cores. The \textit{Lock-Based} implementation performs best with 3 cores and shows slightly worse performance on 4 cores as can be seen in Figure \ref{fig:sir_varyingcores_constgrid}. This is no surprise because the more cores are running at the same time, the more contention for the lock, thus the more likely synchronisation happening, resulting in higher potential for reduced performance. This is not an issue in \textit{STM} because no locks are taken in advance. 

%What comes a bit as a surprise is, that the single core RePast implementation significantly outperforms \textit{all} other implementations, even when they run on multiple cores and even with RePast doing complex visualisation in addition (something the functional implementations don't do). When looking at benchmarks \footnote{\url{https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/haskell.html}} comparing Haskell to Java, C and C++, Haskell is significantly outperformed in most of the cases. This is a strong indication that Haskell is in general not as fast as Java, C or C++. %Although there exist advanced techniques where Haskell can approach a performance like C \cite{kqr_competing_2017} we don't use them here as often this comes at the cost of more complex features, some of them not part of the language standard, more complex code and ultimately requires lots of experience .
%Also, we build on the concepts developed in \cite{thaler_pure_2019} to implement our ABS which make heavy use of Functional Reactive Programming, which can be substantially slower than imperative approaches \cite{nilsson_functional_2002, hudak_arrows_2003}. 

\subsection{Varying Grid Size, Constat Cores}
In this experiment we varied the grid size and used constantly 4 cores. Because in the previous experiment \textit{Lock-Based} performed best on 3 cores, we additionally ran Lock-Based on 3 cores as well. %Note that the RePast experiments all ran on a single (1) core and were conducted to have a rough estimate where the functional approach is in comparison to the imperative.
The results are reported in Table \ref{tab:sir_varyinggrid_constcores} and plotted in Figure \ref{fig:sir_varyinggrid_constcores}.

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c  }
        Grid Size          &  Lock-Based Read-Write & Hybrid       & STM                   \\ \hline \hline 
   		101 x 101 (10,201) &  139.0 (0.15)          & 91.1 (0.14)  & 96.5 (0.27)           \\ \hline
   		151 x 151 (22,801) &  314.0 (0.67)          & 204.0 (0.36) & 212.0 (0.16)          \\ \hline
   		201 x 201 (40,401) &  559.0 (1.22)          & 360.0 (0.61) & 382.0 (0.85)          \\ \hline
   		251 x 251 (63,001) &  861.0 (0.62)          & TODO         & TODO \textbf{495.7}   \\ \hline \hline
  	\end{tabular}

  	\caption{Performance comparison of \textit{STM}, \textit{Lock-Based} and \textit{Hybrid} SIR implementations on varying grid sizes and 4 cores. Timings in seconds (lower is better).}
	\label{tab:sir_varyinggrid_constcores}
\end{table}

TODO: rewrite
It is clear that the \textit{STM} implementation outperforms the \textit{Lock-Based} implementation by a substantial factor. Surprisingly, the \textit{Lock-Based} implementation on 4 core scales just slightly better with increasing agents number than on 3 cores, something we wouldn't have anticipated based on the results seen in Table \ref{tab:sir_varyingcores_constgrid}. %Also  while on a 51x51 grid the single (1) core Java \textit{RePast} version outperforms the 4 core Haskell \textit{STM} version by a factor of 2. The figure is inverted on a 251x251 grid where the 4 core Haskell \textit{STM} version outperforms the single core Java \textit{Repast} version by a factor of 6. This might not be entirely surprising because we compare single (1) core against multi-core performance - still the scaling is indeed impressive and we would not have anticipated an increase of factor 6. %The RePast implementation shows an exponential increase of computation time whereas the other implementations scale linearly which we attribute to the use of multi-cores.

\subsection{Retries}
Of very much interest when using STM is the retry ratio, which obviously depends highly on the read-write patterns of the respective model. We used the \href{http://hackage.haskell.org/package/stm-stats}{stm-stats}~\cite{stm_stats_library} library to record statistics of commits, retries and the ratio. The results are reported in Table \ref{tab:retries_stm}.

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c }
        Grid Size 		   & Commits     & Retries  & Ratio  \\ \hline \hline 
   		51 x 51 (2601)     & 2,601,000   & 1306     & 0.0    \\ \hline
   		101 x 101 (10201)  & 10,201,000  & 3712     & 0.0    \\ \hline
   		151 x 151 (22801)  & 22,801,000  & 8189     & 0.0    \\ \hline
   		201 x 201 (40401)  & 40,401,000  & 13285    & 0.0    \\ \hline
   		251 x 251 (63001)  & 63,001,000  & 21217    & 0.0    \\ \hline \hline
  	\end{tabular}
  	
  	\caption{Retry ratios of the SIR \textit{STM} implementation on varying grid sizes on 4 cores.}
	\label{tab:retries_stm}
\end{table}

Independent of the number of agents we always have a retry ratio of 0.0. This indicates that this model is \textit{very} well suited to STM, which is also directly reflected in the much better performance over the \textit{Lock-Based} implementation. Obviously this ratio stems from the fact, that in our implementation we have \textit{very} few writes, which happen only in case when an agent changes from \textit{Susceptible} to \textit{Infected} or from \textit{Infected} to \textit{Recovered}. 

\subsection{Going Large-Scale}
To test how far we can scale up the number of cores in both the \textit{Lock-Based} and \textit{STM} cases, we ran two experiments, 51x51 and 251x251, on Amazon EC instances with a larger number of cores than our local machinery, starting with 16 and 32 to see if we are running into decreasing returns. The results are reported in Table \ref{tab:sir_varying_cores_amazon}.

\begin{table}
	\centering
  	\begin{tabular}{cc|c|c}
		\multicolumn{1}{ c||  }{\multirow{2}{*}{} } &
		\multicolumn{1}{ |c| }{Cores} & 51x51    & 251x251       \\ \hline \hline 
		
		\multicolumn{1}{ c||  }{\multirow{2}{*}{Lock-Based} } &
		\multicolumn{1}{ |c| }{16} & 72.5    & 1830.5       \\ \cline{2-4}
		\multicolumn{1}{ c||  }{}                       &
		\multicolumn{1}{ |c| }{32} & 73.1    & 1882.2      \\ \hline \hline 
		
		\multicolumn{1}{ c||  }{\multirow{2}{*}{STM} } &
		\multicolumn{1}{ |c| }{16} & \textbf{8.6}     & \textbf{237.0}       \\ \cline{2-4}
		\multicolumn{1}{ c||  }{}                       &
		\multicolumn{1}{ |c| }{32} & 12.0    & 248.7      \\ \hline \hline 
	\end{tabular}

  	\caption{SIR \textit{STM} performance on 16 and 32 cores on Amazon EC2. Timings in seconds (lower is better).}
	\label{tab:sir_varying_cores_amazon}
\end{table}

As expected, the \textit{Lock-Based} approach doesn't scale up to many cores because each additional core brings more contention to the lock, resulting in an even more decreased performance. This is particularly obvious in the 251x251 experiment because of the much larger number of concurrent agents. The \textit{STM} approach returns better performance on 16 cores but fails to scale further up to 32 where the performance drops below the one with 16 cores. In both STM cases we measured a retry ratio of 0, thus we conclude that with 32 cores we become limited by the overhead of STM transactions \cite{perfumo_limits_2008} because the workload of an STM action in our SIR implementation is quite small.

% NOTE: 0 retries in both cases means that the STM transactions themselves are becoming the bottleneck. this makes sens because the STM trasnactions in our SIR implementation are very small (especially recovered and infected agent) and could therefore really cause substantial overhead as pointed out by \cite{perfumo_limits_2008}
%16 cores 251x251: 0.0 retry ratio
%32 cores 251x251: 0.0 retry ratio
%
%16 cores 51x51: 0.0 retry ratio
%32 cores 51x51: 0.0 retry ratio

\subsection{Discussion}
The timing measurements speak a clear language. Running in \texttt{STM} and sharing state using a transactional variable \texttt{TVar} is much more time efficient than both the \textit{Sequential} and \textit{Lock-Based} approach. On 4 cores \textit{STM} achieves a speedup factor of 3.6, nearly reaching the theoretical limit.
Obviously both \textit{STM} and \textit{Lock-Based} sacrifice determinism, which means that repeated runs might not lead to same dynamics despite same initial conditions. Still, by sticking to STM, we get the guarantee that the source of this nondeterminism is concurrency within the \texttt{STM} context but \textit{nothing else}. This we can not guarantee in the case of the \textit{Lock-Based} approach as all bets are off when running within the \texttt{IO} context. The fact to have \textit{both} the better performance \textit{and} the stronger static guarantees in the \textit{STM} approach makes it \textit{very} compelling.