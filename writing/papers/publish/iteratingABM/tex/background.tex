\section{Background}
In this section we define our understanding of \textit{agent} and ABS and how we understand and use it in this paper. Then we will give a description of the two kind of games which were the motivators for our research and case-studies. Finally we will present related work.

\subsection{Agent-Based Simulation}
We understand ABS as a method of modelling and simulating a system where the global behaviour may be unknown but the behaviour and interactions of the parts making up the system is known. Those parts, called agents, are modelled and simulated out of which then the aggregate global behaviour of the whole system emerges. So the central aspect of ABS is the concept of an agent which can be understood as a metaphor for a pro-active unit, situated in an environment, able to spawn new agents and interacting with other agents in a network of neighbours by exchange of messages \cite{wooldridge_introduction_2009}. It is important to note that we focus our understanding of ABS on a very specific kind of agents where the focus is on communicating entities with individual, localized behaviour from out of which the global behaviour of the system emerges. We informally assume the following about our agents:

\begin{itemize}
	\item They are uniquely addressable entities with some internal state.
	\item They can initiate actions on their own e.g. change their internal state, send messages, create new agents, kill themselves.
	\item They can react to messages they receive with actions as above.
	\item They can interact with an environment they are situated in.
\end{itemize} 

An implementation of an ABS must solve two fundamental problems:

\begin{enumerate}
	\item \textbf{Source of pro-activity} How can an agent initiate actions without the external stimuli of messages?
	\item \textbf{Semantics of Messaging} When is a message \textit{m}, sent by agent \textit{A} to agent \textit{B}, visible and processed by \textit{B}?
\end{enumerate}

In computer systems, pro-activity, the ability to initiate actions on its own without external stimuli, is only possible when there is some internal stimulus, most naturally represented by a continuous increasing time-flow. Due to the discrete nature of computer-system, this time-flow must be discretized in steps as well and each step must be made available to the agent, acting as the internal stimulus. This allows the agent then to perceive time and become pro-active depending on time. So we can understand an ABS as a discrete time-simulation where time is broken down into continuous, real-valued or discrete natural-valued time-steps. Independent of the representation of the time-flow we have the two fundamental choices whether the time-flow is local to the agent or whether it is a system-global time-flow. Time-flows in computer-systems can only be created through threads of execution where there are two ways of feeding time-flow into an agent. Either it has its own thread-of-execution or the system creates the illusion of its own thread-of-execution by sharing the global thread sequentially among the agents where an agent has to yield the execution back after it has executed its step. Note the similarity to an operating system with cooperative multitasking in the latter case and real multi-processing in the former.

The semantics of messaging define when sent messages are visible to the receivers and when the receivers process them. Message-processing could happen either immediately or delayed, depending on how message-delivery works. There are two ways of message-delivery: immediate or queued. In the case of immediate message-deliver the message is sent directly to the agent without any queuing in between e.g. a direct method-call. This would allow an agent to immediately react to this message as this call of the method transfers the thread-of-execution to the agent. This is not the case in the queued message-delivery where messages are posted to the message-box of an agent and the agent pro-actively processes the message-box at regular points in time.

\subsection{A discrete game: Prisoners Dilemma}
As an example of a discrete game we use the \textit{Prisoners Dilemma} as presented in \cite{nowak_evolutionary_1992}. In the prisoners dilemma one assumes that two persons are locked up in a prison and can choose to cooperate with each other or to defect by betraying the other one. Looking at a game-theoretic approach there are two options for each player which makes four possible outcomes. Each outcome is associated with a different payoff in the prisoner-dilemma. If both players cooperate both receive payoff R; if one player defects and the other cooperates the defector receives payoff T and the cooperator payoff S; if both defect both receive payoff P where T $>$ R $>$ P $>$ S. The dilemma is that the safest strategy for an individual is to defect but the best payoff is only achieved when both cooperate. 
In the version of \cite{nowak_evolutionary_1992} NxN agents are arranged on a 2D-grid where every agent has 8 neighbours except at the edges. Agents don't have a memory of the past and have one of two roles: either cooperator or defector. In every step an agent plays the game with all its neighbours, including itself and sums up the payoff. After the payoff sum is calculated the agent changes its role to the role of the agent with the highest payoff within its neighbourhood (including itself). The authors attribute the following payoffs: S=P=0, R=1, T$>$b, where b$>$1. They showed that when having a grid of only cooperators with a single defector at the center, the simulation will form beautiful structural patterns as shown in Figure \ref{fig:sync_patterns}.

\begin{figure}
	\centering
	\includegraphics[width=.4\textwidth, angle=0]{./fig/sync_patterns.png}
	\caption{Patterns formed by playing the \textit{Prisoners Dilemma} game on a 99x99 grid with 1.8 $<$ b $<$ 2 after 217 steps with all agents being cooperators except one defector at the center. Blue are cooperators, red are defectors, yellow are cooperators which were defectors in the previous step, green are defectors which were cooperators in the previous step. Picture taken from \cite{nowak_evolutionary_1992}.}
	\label{fig:sync_patterns}
\end{figure}

In \cite{huberman_evolutionary_1993} the authors show that the results of simulating the \textit{Prisoners Dilemma} as above depends on a very specific strategy of iterating the simulation and show that the beautiful patterns seen in Figure \ref{fig:sync_patterns} will not form when selecting a different update-strategy. They introduced the terms of synchronous and asynchronous updates and define synchronous to be as agents being updated in unison and asynchronous where one agent is updated and the others are held constant. Only the synchronous updates are able to reproduce the results. The authors differentiated between the two strategies but their description still lacks precision and detail, something we will provide in this paper. Although they didn't publish their work in the area of ABS but on computing in general, it has general implications for ABS as well which can be generalized in the main message of our paper as emphasised in the introduction. We will show that there are more than two update-strategies and will give results of simulating this discrete game using all of them. As will be shown later, the patterns emerge indeed only when selecting a specific update-strategy.
% TODO comment by peer: so it's not enough to distinguish between synchronous and asynchronous to describe when patterns appear?

\subsection{A continuous game: Heroes \& Cowards}
As an example for a continuous game we use the \textit{Heroes \& Cowards} game introduced by \cite{wilensky_introduction_2015}. In this game one starts with a crowd of agents where each agent is positioned randomly in a continuous 2D-space which is bounded by borders on all sides. Each of the agents then selects randomly one friend and one enemy (except itself) and decides with a given probability whether the agent acts in the role of a hero or a coward - friend, enemy and role don't change after the initial set-up. In each step the agent will move a small distance towards a target point as seen in Figure \ref{fig:heros_and_cowards}. If the agent is in the role of a hero this target point will be the half-way distance between the agents friend and enemy - the agent tries to protect the friend from the enemy. If the agent is acting like a coward it will try to hide behind the friend also the half-way distance between the agents friend and enemy, just in the opposite direction. Note that this simulation is determined by the random starting positions, random friend and enemy selection, random role selection and number of agents. Note also that during the simulation-stepping no randomness is incurred and given the initial random set-up, the simulation-model is completely deterministic. As will be shown later the results of simulating this model are invariant under different update-strategies.
%TODO comment by peer: has this got something to do with being deterministic?

\begin{figure}
	\centering
	\includegraphics[width=.4\textwidth, angle=0]{./fig/heros_and_cowards.png}
	\caption{A conceptual diagram of the \textit{Heroes \& Cowards} game. Hero (green) and coward (red) have the same agents as friend and enemy but act different: the hero tries to move in between the friend and enemy whereas the coward tries to hide behind its friend.}
	\label{fig:heros_and_cowards}
\end{figure}

\subsection{Related Research}
Besides \cite{nowak_evolutionary_1992} and \cite{huberman_evolutionary_1993} which both discuss asynchronous and synchronous updates, multiple other works mention these kind of updates but the meaning is different in each.
Asynchronous updates in the context of cellular automata was defined by \cite{bersini_asynchrony_1994} as picking a cell at random and updating it and synchronous as all cells updating at the same time and report different dynamics when switching between the two. The authors also raise the question which of both is correct and most faithful to reality as in an ideal solution both should deliver the similar spatio-temporal dynamics. They conclude that developers of simulations should pay attention to the fact that the dynamics and results are sensible to the updating procedures.
Asynchronous vs. synchronous updates are mentioned in the book of \cite{wilensky_introduction_2015} where they define asynchronous updates as having the property that changes made by an agent are seen immediately by the others whereas in synchronous updating the changes are only visible in the next tick. They also look into the notion of sequential vs. parallel actions and identify as sequential when only one agent acts at a time and parallel when agents act truly parallel, independent from each other. The same argumentation is followed by \cite{railsback_agent-based_2011} where they  discuss the importance of order of execution of the agents and describe asynchronous and synchronous updating.
Yet another definition of synchronous and asynchronous updates is given in \cite{page_incentives_1997}. They define asynchronous updating as updating agents sequentially one after another and synchronous updating as updating all agents at virtually the same time. They go further and discuss also random updates where the order of the agent-sequence is shuffled before updating all agents. They also introduce 
incentive based asynchronous updating where the agent which gains the most from the update is updated first, thus introducing an ordering on the sequence which is sorted by the benefit each agent gains from its update. They also compare the differences synchronous, random-asynchronous and incentive-asynchronous updating has on dynamics and come to the conclusion that the order of updating the agents has an impact on the dynamics and should be considered with great care when implementing a simulation.
Asynchronous and synchronous time-models are mentioned in \cite{dawson_opening_2014} where the authors describe basic inner workings of ABS environments and compare their implementation in C++ to the existing ABS environment AnyLogic which is programmed in Java. They interpret asynchronous time-models to be the ones in which an agent acts at random time intervals and synchronous time-models where agents are updated all in same time intervals.
A different interpretation of synchronous and asynchronous time-models is given in \cite{yuxuan_agent-based_2016}. He identifies the asynchronous time-model to be one in which updates are triggered by the exchange of messages and the synchronous ones which trigger changes immediately without the indirection of messages.
A different approach was taken in \cite{botta_time_2010} where they sketch a minimal ABS implementation in Haskell. Their research applies primarily to economic simulations and instead of iterating a simulation with a global time, their focus is on how to synchronize agents which have internal, local transition times. 
A very different approach to updating and iterating agents in ABS than to mechanisms used in existing software like AnyLogic, NetLogo or Repast was given in \cite{lysenko_framework_2008} where the authors mapped ABS on GPUs. They discuss execution order at length, highlight the problem of inducing a specific execution-order in a model which is problematic for parallel execution and give solutions how to circumvent these shortcomings. Although we haven't mapped our ideas to GPUs we explicitly include an approach for data-parallelism which can be utilized to roughly map their approach onto our terminology. 
