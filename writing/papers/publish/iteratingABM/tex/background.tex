\section{2 Background}
In this section we define our term and understanding of \textit{agent} and ABS and how we understand and use it in this paper. Then we will give a description of the two kind of games which were the motivators for our research and case-studies. Finally we will present related work.

\subsection{2.1 Agent-Based Simulation}
We understand ABS as a method of modelling and simulating a system where the global behaviour may be unknown but the behaviour and interactions of the parts making up the system is of knowledge. Those parts, called agents, are modelled and simulated out of which then the aggregate global behaviour of the whole system emerges. So the central aspect of ABS is the concept of an agent which can be understood as a metaphor for a pro-active unit, situated in an environment, able to spawn new agents and interacting with other agents in a network of neighbours by exchange of messages \cite{wooldridge_introduction_2009}. It is important to note that we focus our understanding of ABS on a very specific kind of agents where the focus is on communicating entities with individual, localized behaviour from out of which the global behaviour of the system emerges. We informally assume the following about our agents:

\begin{itemize}
	\item They are uniquely addressable entities with some internal state.
	\item They can initiate actions on their own e.g. change their internal state, send messages, create new agents, kill themselves.
	\item They can react to messages they receive with actions as above.
	\item They can interact with an environment they are situated in.
\end{itemize} 

An implementation of an ABS must solve two fundamental problems:

\begin{enumerate}
	\item \textbf{Source of pro-activity} How can an agent initiate actions without the external stimuli of messages?
	\item \textbf{Semantics of Messaging} When is a message \textit{m}, sent by agent \textit{A} to agent \textit{B}, visible and processed by \textit{B}?
\end{enumerate}

In computer systems, pro-activity, the ability to initiate actions on its own without external stimuli, is only possible when there is some internal stimulus, most naturally represented by some generic notion of monotonic increasing time-flow. Due to the discrete nature of computer-system, this time-flow must be discretized in steps as well and each step must be made available to the agent, acting as the internal stimulus. This allows the agent then to perceive time and become pro-active depending on time. So we can understand an ABS as a discrete time-simulation where time is broken down into continuous, real-valued or discrete natural-valued time-steps. Independent of the representation of the time-flow we have the two fundamental choices whether the time-flow is local to the agent or whether it is a system-global time-flow. Time-flows in computer-systems can only be created through threads of execution where there are two ways of feeding time-flow into an agent. Either it has its own thread-of-execution or the system creates the illusions of its own thread-of-execution by sharing the global one sequentially among the agents where an agent has to yield the execution back after it has executed its step. Note the similarity to an operating system with cooperative multitasking in the latter case and real multi-processing in the former.

The semantics of messaging define when sent messages are visible to the receivers and when the receivers process them. Message-processing could happen either immediately or delayed, depending on how message-delivery works. There are two ways of message-delivery: queued or immediate. In the case of immediate message-deliver the message is sent directly to the agent without any queuing in between e.g. a direct method-call. This would allow an agent to immediately react to this message as this call of the method transfers the thread-of-execution to the agent. This is not the case in the queued message-delivery where messages are posted to the message-box of an agent and the agent pro-actively processes the message-box at regular points in time.

\subsection{2.2 A discrete game: Prisoners Dilemma}
As an example of a discrete game we use the \textit{Prisoners Dilemma} as presented in \cite{nowak_evolutionary_1992}. In the prisoners dilemma two players play a game where in each step a player can either choose to cooperate or defect receiving a payoff. There are four possible payoffs: if both players cooperate both receive R; if one player defects and the other cooperates the defector receives T and the cooperator S; if both defect both receive P where T $>$ R $>$ P $>$ S.
In the version of \cite{nowak_evolutionary_1992} NxN agents are arranged on a 2D-grid where every agent has 8 neighbours except at the edges. Agents don't have a memory of the past and have one of two roles: either cooperator or defector. In every step an agent plays the game with all its neighbours, including itself (something which was not explicitly mentioned in the paper but if omitted, will not lead to their results) and sums up the payoff. After the payoff sum is calculated the agent changes its role to the role of the agent with the highest payoff within its neighbourhood (including itself). The authors attribute the following payoffs: S=P=0, R=1, T$>$b, where b$>$1. They showed that when having a grid of only cooperators with a single defector at the center, the simulation will form beautiful structural patterns as shown in Figure \ref{fig:sync_patterns}.

\begin{figure}
	\centering
	\includegraphics[width=.4\textwidth, angle=0]{./fig/sync_patterns.png}
	\caption{Patterns formed by playing the \textit{Prisoners Dilemma} game on a 99x99 grid with 1.8 $<$ b $<$ 2 after 217 steps with all agents being cooperators except one defector at the center. Blue are cooperators, red are defectors, yellow are cooperators which were defectors in the previous step, green are defectors which were cooperators in the previous step. Picture taken from \cite{nowak_evolutionary_1992}.}
	\label{fig:sync_patterns}
\end{figure}

In \cite{huberman_evolutionary_1993} the authors showed that the results of simulating the \textit{Prisoners Dilemma} as above depends on a very specific strategy of iterating the simulation and show that the beautiful patterns seen in Figure \ref{fig:sync_patterns} will not form when selecting a different update-strategy. They introduced the terms of synchronous and asynchronous updates and define synchronous to be as agents being updated in unison and asynchronous where one agent is updated and the others are held constant. Only the synchronous updates are able to reproduce the results. Although the authors differentiated between the two strategies, their description still lacks precision and detail, something we will provide in this paper. Although they didn't publish their work in the field of ABS, it has general implications for ABS as well which can be generalized in the main message of our paper as emphasised in the introduction. We will show that there are more than two update-strategies and will give results of simulating this discrete game using all of them. As will be shown later, the patterns emerge indeed only when selecting a specific update-strategy.

\subsection{2.3 A continuous game: Heroes \& Cowards}
As an example for a continuous game we use the \textit{Heroes \& Cowards} game introduced by \cite{wilensky_introduction_2015}. In this game one starts with a crowd of agents where each agent is positioned randomly in a continuous 2D-space which is bounded by borders on all sides. Each of the agents then selects randomly one friend and one enemy (except itself) and decides with a given probability whether the agent acts in the role of a hero or a coward - friend, enemy and role don't change after the initial set-up. In each step the agent will move a small distance towards a target point. If the agent is in the role of a hero this target point will be the half-way distance between the agents friend and enemy - the agent tries to protect the friend from the enemy. If the agent is acting like a coward it will try to hide behind the friend also the half-way distance between the agents friend and enemy, just in the opposite direction. Note that this simulation is determined by the random starting positions, random friend and enemy selection, random role selection and number of agents. Note also that during the simulation-stepping no randomness is incurred and given the initial random set-up, the simulation-model is completely deterministic. As will be shown later the results of simulating this model are invariant under different update-strategies.

\begin{figure}
	\centering
	\includegraphics[width=.4\textwidth, angle=0]{./fig/heros_and_cowards.png}
	\caption{A conceptual diagram of the \textit{Heroes \& Cowards} game. Hero (green) and coward (red) have the same agents as friend and enemy but act different: the hero tries to move in between the friend and enemy whereas the coward tries to hide behind its friend.}
	\label{fig:heros_and_cowards}
\end{figure}

\subsection{2.4 Related Research}
\cite{lysenko_framework_2008} give an approach for ABS on GPUs which is a very different approach to updating and iterating agents in ABS. They discuss execution order at length, highlight the problem of inducing a specific execution-order in a model which is problematic for parallel execution and give solutions how to circumvent these shortcomings. Although we haven't mapped our ideas to GPUs we explicitly include an approach for data-parallelism which, we hypothesize, can be utilized to roughly map their approach onto our terminology. 
	
\cite{botta_time_2010} sketch a minimal ABS implementation in Haskell. Their focus is primarily on economic simulations and instead of iterating a simulation with a global time, their focus is on how to synchronize agents which have internal, local transition times. 

\cite{dawson_opening_2014} describe basic inner workings of ABS environments and compare their implementation in C++ to the existing ABS environment AnyLogic which is programmed in Java. They explicitly mention synchronous and asynchronous time-models and compare them in theory but unfortunately couldn't report the results of asynchronous updates due to limited space. They interpret asynchronous time-models to be the ones in which an agent acts at random time intervals and synchronous time-models where agents are updated all in same time intervals.

\cite{yuxuan_agent-based_2016} presents a comprehensive discussion on how to implement an ABS for state-charts in Java and also mentions synchronous and asynchronous time-models. He identifies the asynchronous time-model to be one in which updates are triggered by the exchange of messages and the synchronous ones which trigger changes immediately without the indirection of messages.

\cite{wilensky_introduction_2015} also mention in their book \textit{asynchronous vs. synchronous updates}. They define asynchronous updates when changes made by an agent are seen immediately by the others whereas in synchronous updating the changes are only visible in the next tick. They also look into the notion of \textit{sequential vs. parallel actions} and identify as sequential when only one agent acts at a time and parallel when agents act truly parallel, independent from each other.

\cite{railsback_agent-based_2011} discuss the importance of order of execution of the agents and describe \textit{asynchronous and synchronous updating} as well and follow in their definition exactly the one found in \cite{wilensky_introduction_2015}.

TODO: \cite{page_incentives_1997}

TODO: \cite{polhill_what_2006} is it really necessary?