\section{Background}
\label{sec:background}

\subsection{Software Transactional Memory}
Software Transactional Memory (STM) was introduced by \cite{shavit_software_1995} in 1995 as an alternative to lock-based synchronisation in concurrent programming which, in general, is notoriously difficult to get right. This is because reasoning about the interactions of multiple concurrently running threads and low level operational details of synchronisation primitives is \textit{very hard}. The main problems are:

\begin{itemize}
	\item Race conditions due to forgotten locks;
	\item Deadlocks resulting from inconsistent lock ordering;
	\item Corruption caused by uncaught exceptions;
	\item Lost wake ups induced by omitted notifications.
\end{itemize}

Worse, concurrency does not compose. It is very difficult to write two functions (or methods in an object) acting on concurrent data which can be composed into a larger concurrent behaviour. The reason for it is that one has to know about internal details of locking, which breaks encapsulation and makes composition dependent on knowledge about their implementation. Therefore, as an example it is impossible to compose two  functions where one withdraws some amount of money from an account and the other deposits this amount of money into a different account: one ends up with a temporary state, where the money is in none of either accounts, creating an inconsistency - a potential source for errors because threads can be rescheduled at any time.

STM promises to solve all these problems for a low cost by executing actions \textit{atomically}, where modifications made in such an action are invisible to other threads and changes by other threads are invisible as well until actions are committed - this means that STM actions are atomic and isolated. When an STM action exits, either one of two outcomes happen: if no other thread has modified the same data as the thread running the STM action, then the modifications performed by the action will be committed and become visible to the other threads. If other threads have modified the data then the modifications will be discarded, the action block rolled back and automatically restarted.

STM in Haskell is implemented using optimistic synchronisation, which means that instead of locking access to shared data, each thread keeps a transaction log for each read and write to shared data it makes. When the transaction exits, the thread checks if it had a consistent view to the shared data by verifying whether other threads have written to memory it has read or not. % This might look like a serious overhead but the implementations are very mature by now, being very performant and the benefits outweigh its costs by far.

%In the paper \cite{heindl_modeling_2009} the authors use a model of STM to simulate optimistic and pessimistic STM behaviour under various scenarios using the AnyLogic simulation package. They conclude that optimistic STM may lead to 25\% less retries of transactions
However, STM does not come without issues. The authors of \cite{perfumo_limits_2008} analyse several Haskell STM programs with respect to their transactional behaviour and identified the roll-back rate as one of the key metric, which determines the scalability of an application. Although STM might promise better performance, they also warn of the overhead it introduces, which could be quite substantial in particular for programs which do not perform much work inside transactions as their commit overhead appears to be high.

\subsection{Parallelism, Concurrency and Software Transactional Memory in Haskell}
In our case studies we are using the functional programming language Haskell. The paper of \cite{hudak_history_2007} gives a comprehensive overview over the history of the language, how it developed and its features and is very interesting to read and get accustomed to the background of the language. Note that Haskell is a \textit{lazy} language, which means that expressions are only evaluated when they are actually needed.

\subsubsection{Side Effects}
\label{sub:side_effects}
One of the fundamental strengths of Haskell is its way of dealing with side effects in functions. A function with side effects has observable interactions with some state outside of its explicit scope. This means that the behaviour depends on history and that it loses its referential transparency character. With referential transparency a computation does not depend on its context within the system but will produce the same result when run repeatedly with similar inputs, which makes understanding and debugging much easier. Examples for side effects are (amongst others): modifying a global variable, awaiting an input from the keyboard, reading or writing to a file, opening a connection to a server, drawing random numbers, etc.

The unique feature of Haskell is that it allows to indicate in the \textit{type} of a function that it does have side effects and what kind of effects they are. There are a broad range of different effect types available, to restrict the possible effects a function can have, for example drawing random numbers, sharing read/write state between functions, etc. Depending on the type, only specific operations are available, which is then checked by the compiler. This means that a program which tries to read from a file in a function which only allows drawing random numbers will fail to compile.

In this paper we are only concerned with two effect types: The \texttt{IO} effect context can be seen as completely unrestricted as the main entry point of each Haskell program runs in the \texttt{IO} context which means that this is the most general and powerful one. It allows all kind of input/output (IO) related side effects: reading/writing a file, creating threads, write to the standard output, read from the keyboard, opening network connections, mutable references, etc. Also, the \texttt{IO} context provides functionality for concurrent locks and global shared references. The other effect context we are concerned with is \texttt{STM} and indicates the STM context of a function - we discuss it more in detail below in sections \ref{sub:stm} and \ref{sub:stm_example}. 

A function with a given effect type needs to be executed with a given effect runner which takes all necessary parameters depending on the effect and runs a given function with side effects returning its return value and depending on the effect also an effect related result. Note that we cannot call functions of different effect types from a function with another effect type, which would violate the guarantees. A function without any side effect is called \textit{pure}. Calling a \textit{pure} function is always allowed because it has, by definition, no side effects. 

Although such a type system might seem very restrictive at first, we get a number of benefits by making the type of effects we can use explicit. First, we can restrict the side effects a function can have to a very specific type, which is guaranteed at compile time. This means we can have much stronger guarantees about our program and the absence of potential run time errors. Second, by the use of effect runners, we can execute effectful functions in a very controlled way, by making the effect context explicit in the parameters to the effect runner.

\subsubsection{Parallelism \& Concurrency}
Haskell makes a very clear distinction between parallelism and concurrency. Parallelism is always deterministic and thus pure without side effects because although parallel code can be run concurrently, it does by definition not interact with data of other threads. This can be indicated through types: we can run pure functions in parallel because for them it doesn't matter in which order they are executed, the result will always be the same due to the concept of referential transparency.

Concurrency on the other hand is potentially nondeterministic because of nondeterministic interactions of concurrently running threads through shared data. Although data in functional programming is immutable, Haskell provides primitives which allow to share immutable data between threads. Accessing these primitives is only possible from within an \texttt{IO} or \texttt{STM} context, which means that when we are using concurrency in our program, the types of our functions change from pure to either a \texttt{IO} or \texttt{STM} effect context.

Note that spawning tens of thousands or even millions of threads in Haskell is no problem, because threads in Haskell have a \textit{very} low memory footprint due to being lightweight user space threads, also known as green threads, managed by the Haskell Runtime System, which maps them to physical operating system worker threads \cite{marlow_runtime_2009}.

\subsubsection{Software Transactional Memory}
\label{sub:stm}
The work of \cite{harris_composable_2005, harris_transactional_2006} added STM to Haskell, which was one of the first programming languages to incorporate STM into its main core and added the ability to composable operations. %There exist various implementations of STM in other languages as well (Python, Java, C\#, C/C++, etc) but we argue, that it is in Haskell with its type system and the way how side effects are treated where it truly shines.
In the Haskell implementation, STM actions run within the \texttt{STM} context. This restricts the operations to only STM primitives as shown below, which allows to enforce that \texttt{STM} actions are always repeatable without persistent side effects because such persistent side effects (e.g. writing to a file, launching a missile) are not possible in an \texttt{STM} context. This is also the fundamental difference to \texttt{IO}, where we lose static guarantees because \textit{everything} is possible as there are basically no restrictions because \texttt{IO} can run everything. Thus, the ability to \textit{restart} a block of actions without any visible effects is only possible due to the nature of Haskells type system: by restricting the effects to \texttt{STM} only, prevents uncontrolled effects which cannot be rolled back.

STM comes with a number of primitives to share transactional data. Amongst others the most important ones are:

\begin{itemize}
	\item \texttt{TVar}   A transactional variable which can be read and written arbitrarily;
	\item \texttt{TArray}   A transactional array where each cell is an individual shared data, allowing much finer grained transactions instead of having the whole array in a \texttt{TVar};
	\item \texttt{TChan}   A transactional channel, representing an unbounded FIFO channel;
	\item \texttt{TMVar}   A transactional \textit{synchronising} variable which is either empty or full. To read from an empty or write to a full \texttt{TMVar} will cause the current thread to block and retry its transaction when the \texttt{TMVar} was updated by another thread.
\end{itemize}

% NOTE: too technical
To execute an \texttt{STM} action the function \texttt{atomically :: STM a $\to$ IO a} is provided, which performs a series of \texttt{STM} actions atomically within an \texttt{IO} context. It takes the \texttt{STM} action which returns a polymorphic value of type \texttt{a} and returns an \texttt{IO} action which returns a value of type \texttt{a}.

\subsubsection{STM examples}
\label{sub:stm_example}
We provide two examples to demonstrate the use and semantics of STM. The first example is an implementation of the aforementioned functionality, where money is withdrawn from one account and transferred to another. The implementing function \texttt{transferFunds} takes two \texttt{TVar}, holding the account balances, and the amount to exchange. It executes using \texttt{atomically}, therefore running in the \texttt{IO} context. It uses the two functions \texttt{withdraw} and \texttt{deposit} which do the work of withdrawing some amount from one account and depositing some amount to another. This example demonstrates how easy STM can be used: the implementation looks quite straightforward, simply swapping values, without any locking involved or special handling of concurrency, other than the use of \texttt{atomically}. \\ % need line break otherwise code is too close to text

%\begin{HaskellCode}
\begin{footnotesize}
\begin{verbatim}
transferFunds :: TVar Integer -> TVar Integer -> Integer -> IO ()
transferFunds from to n = atomically $ do
  withdraw from n
  deposit to n
  
withdraw :: TVar Integer -> Integer -> STM ()
withdraw account amount = do
  balance <- readTVar account
  writeTVar (balance - amount)
  
deposit :: TVar Integer -> Integer -> STM ()
deposit account amount = do
  balance <- readTVar account
  writeTVar (balance + amount)
\end{verbatim}
\end{footnotesize}
%\end{HaskellCode}

\medskip % needed otherwise code is too close to text

In the second example we show the retry semantics of STM, by combining the \texttt{STM} context with a \texttt{StateT} context. A \texttt{StateT} context allows to read and write some state, available to the function, which in this example we simply set to be an \texttt{Int} value. The combination of both contexts is reflected in the type of the function, which bedsides taking a transactional variable \texttt{TVar} holding an \texttt{Int}, is \texttt{StateT Int STM Int} which means that the function has access to both the \texttt{StateT} and \texttt{STM} functionality. The first \texttt{Int} indicates that the \texttt{StateT} context allows to read and write an \texttt{Int} value, available to the function; the second \texttt{Int} indicates that the function is also an \texttt{STM} action and will return an \texttt{Int} value. \\ % need line break otherwise code is too close to text

%\begin{HaskellCode}
\begin{footnotesize}
\begin{verbatim}
stmAction :: TVar Int -> StateT Int STM Int 
stmAction v = do
  -- print a debug output and increment the value in StateT 
  Debug.trace "increment!" (modify (+1))
  -- read from the TVar
  n <- lift (readTVar v)
  -- await a condition: content of the TVar >= 42
  if n < 42
    -- condition not met, therefore retry: block this thread
    -- until the TVar v is written by another thread, then
    -- try again
    then lift retry
    -- condition met: return content ot TVar
    else return n
\end{verbatim}
\end{footnotesize}
%\end{HaskellCode}

\medskip % needed otherwise code is too close to text

When \texttt{stmAction} is run, it prints an \texttt{'increment!'} debug message to the console and increments the value in the \texttt{StateT} context. Then it awaits a condition for as long as \texttt{TVar} is less then 42 the action will retry whenever it is run. If the condition is met, it will return the content of the \texttt{TVar}. To run \texttt{stmAction} we need to spawn a thread: \\ % need line break otherwise code is too close to text

%\begin{HaskellCode}
\begin{footnotesize}
\begin{verbatim}
stmThread :: TVar Int -> IO ()
stmThread v = do
  -- the initial state of the StateT effect
  let s = 0
  -- run the state with initial value of s (0)
  let ret = runStateT (stmAction v) s
  -- atomically run the STM action
  (a, s') <- atomically ret
  -- print final result
  putStrLn("final StateT state     = " ++ show s' ++
           ", STM computation result = " ++ show a)
\end{verbatim}
\end{footnotesize}
%\end{HaskellCode}

\medskip % needed otherwise code is too close to text

The thread first runs the \texttt{StateT} context using the effect runner function \texttt{runStateT} which takes the \texttt{stmAction} and the initial value of the effect context. This results in an \texttt{STM} computation, which is executed through \texttt{atomically}. Finally, the result is printed to the console. The value of \texttt{a} is the result of \texttt{stmAction} and \texttt{s'} is the final state of the \texttt{StateT} computation. To actually run this example we need the main thread to update the \texttt{TVar} until the condition is met within \texttt{stmAction}: \\ % need line break otherwise code is too close to text

%\begin{HaskellCode}
\begin{footnotesize}
\begin{verbatim}
main :: IO ()
main = do
  -- create a new TVar with initial value of 0
  v <- newTVarIO 0 
  -- start the stmThread and pass the TVar
  forkIO (stmThread v)
  -- do 42 times...
  forM_ [1..42] (\i -> do
    -- use delay to 'make sure' that a retry is happening for every increment
    threadDelay 10000
    -- write new value to TVar using atomically, will cause the STM
    -- thread to wake up and retry
    atomically (writeTVar v i))
\end{verbatim}
\end{footnotesize}
%\end{HaskellCode}

\medskip % needed otherwise code is too close to text

If we run this program, we will see \texttt{'increment!'} printed 43 times, followed by \texttt{'final StateT state = 1, STM computation result = 42'}. This clearly demonstrates the retry semantics where \texttt{stmAction} is retried 42 times and thus prints \texttt{'increment!'} 43 times to the console. The \texttt{StateT} computation however is always rolled back when a retry is happening. The rollback is easily possible in pure functional programming due to persistent data structures, by simply throwing away the new value and retrying with the old value. This example also demonstrates that any \texttt{IO} actions which happen within an \texttt{STM} action are persistent and can obviously not be rolled back. \texttt{Debug.trace} is an \texttt{IO} action masked as pure by the Haskell implementation, to support debugging of pure functions. If it would not have been masked as pure, the compiler would have not accepted the program, because the \texttt{STM} context does not allow the execution of \texttt{IO} actions.