\section{Introduction}
% setting the scene: what is the problem
When implementing an Agent-Based Simulation (ABS) it is of fundamental importance that the implementation is correct up to some specification and that this specification matches the real world in some way. This process is called verification and validation (V\&V), where \textit{validation} is the process of ensuring that a model or specification is sufficiently accurate for the purpose at hand, whereas \textit{verification} is the process of ensuring that the model design has been transformed into a computer model with sufficient accuracy \cite{robinson_simulation:_2014}. In other words, validation determines if we are we building the \textit{right model} and verification if we are building the \textit{model right} \cite{balci_verification_1998}.

% there is no general validity, an approach is TDD: V&V particularly difficult in ABS
One can argue that ABS should require more rigorous programming standards than other computer simulations \cite{polhill_ghost_2005}. Because researchers in ABS look for an emergent behaviour in the dynamics of the simulation, they are always tempted to look for some surprising behaviour and expect something unexpected from their simulation. 
Also, due to ABS mostly exploratory nature, there exists some amount of uncertainty about the dynamics the simulation will produce before running it. The authors \cite{ormerod_validation_2006} see the current process of building ABS as a discovery process where often models of an ABS lack an analytical solution (in general) which makes verification much harder if there is no such solution. Thus it is often very difficult to judge whether an unexpected outcome can be attributed to the model or has in fact its roots in a subtle programming error \cite{galan_errors_2009}.

In general this implies that we can only \textit{raise the confidence} in the correctness of the simulation: it is not possible to prove that a model is valid, instead one should think of confidence in its validity. Therefore, the process of V\&V is not the proof that a model is correct but the process of trying to prove that the model is incorrect. The more checks one carries out which show that it is not incorrect, the more confidence we can place on the models validity. To tackle such a problem in software, software engineers have developed the concept of test-driven development (TDD).

Test-Driven Development (TDD) was rediscovered in the early 00s by Kent Beck \cite{beck_test_2002} as a way to a more agile approach to software-engineering, where instead of doing each step (requirements, implementation, testing,...) as separated from each other, all of them are combined in shorter cycles. Put shortly, in TDD tests are written for each feature before actually implementing it, then the feature is fully implemented and the tests for it should pass. This cycle is repeated until the implementation of all requirements has finished. Traditionally TDD relies on so-called unit-tests which can be understood as a piece of code which when run isolated, tests some functionality of an implementation. Thus we can say that test-driven development in general and unit-testing together with code-coverage in particular, guarantee the correctness of an implementation to some informal degree, which has been proven to be sufficiently enough through years of practice in the software industry all over the world. 

% the gap 
In this paper our aim is to introduce and discuss property-based testing, a complementary method of testing the implementation of an ABS, which allows to directly express model-specifications and laws in code and test them through \textit{automated} test-data generation. We see it as an addition to TDD where it works in combination with unit-testing to verify and validate a simulation to increase the confidence in its correctness and is a useful tool for expressing regression tests. To our best knowledge property-based testing has never been looked at in the context of ABS and this paper is the first one to do so.

Property-based testing has its origins \cite{claessen_quickcheck_2000,claessen_testing_2002,runciman_smallcheck_2008} in the pure functional programming language Haskell \cite{hudak_history_2007} where it was first conceived and implemented. It has been successfully used for testing Haskell code for years and also been proven to be useful in the industry \cite{hughes_quickcheck_2007}. To make this paper sufficiently self-contained we avoid discussing it from a Haskell perspective and present it more on a conceptual level. 

We claim that property-based testing is a natural fit for ABS and a valuable addition to the already existing testing methods in this field. To substantiate and test our claims, we present two case-studies. First, the agent-based SIR model \cite{macal_agent-based_2010}, which is of explanatory nature, where we show how to express formal model-specifications in property-tests. Second, the SugarScape model \cite{epstein_growing_1996}, which is of exploratory nature, where we show how to express hypotheses in property-tests and how to property-test agent functionality.

%TODO: "Try contextualizing agent-based simulation in the topic and mainstream Internet of Things context because simulation is even more interesting when it deals with cyberphysical systems. To this end, cite TODO and TODO. In my opionion, this would definitively improve tha appeal and freshness of the paper."

Further we claim that our research is not only applicable to theoretical models like the ones mentioned above but has also importance for Internet of Things (IoT), currently a hot topic in the field of Multi-Agent Systems (MAS) and ABS. ABS is conceptually related to IoT due to both roots in MAS: in IoT as well as in ABS \textit{things} interact locally with each other, out of which the whole system behaviour emerges. Thus ABS allows to model and simulate large IoT installations and networks before installing them, acting as a kind of prototype and \textit{validation \& verification} mechanism. As our paper is focused on exactly that topic, we claim that it is highly relevant for IoT as well. TODO: add citations suggested

% structure
The structure of the paper is as follows: First we present related work in Section \ref{sec:related}. Then we give a more in-depth explanation of property-based testing in Section \ref{sec:proptesting}. Next we shortly discuss how to conceptually apply property-based testing to ABS in Section \ref{sec:testingABS}. The heart of the paper are the two case-studies, which we present in Section \ref{sec:case_SIR} and \ref{sec:case_sug}. Finally, we conclude and discuss further research in Section \ref{sec:conclusions}.