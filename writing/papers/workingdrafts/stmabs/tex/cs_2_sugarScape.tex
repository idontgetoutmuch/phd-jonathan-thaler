\section{Case Study 2: Sugarscape (Second Encounter)}
One of the first  Agent-Based Simulation model which rose to some prominence was the Sugarscape model developed by Epstein and Axtell in 1996 \cite{epstein_growing_1996}. Their aim was to \textit{grow} an artificial society by simulation and connect observations in their simulation to phenomenon of real-world societies. The main features of this model are:

\begin{itemize}
	\item Searching, harvesting and consuming of resources.
	\item Wealth and age distributions.
	\item Seasons in the environment and migration of agents.
	\item Pollution of the environment.
	\item Population dynamics under sexual reproduction.
	\item Cultural processes and transmission.
	\item Combat and assimilation.
	\item Bilateral decentralized trading (bartering) between agents with endogenous demand and supply.
	\item Emergent Credit-Networks.
	\item Disease Processes, Transmission and immunology.
\end{itemize}

Because of its essential importance to this field, its complexity, number of features and allowing us to bridge the gap to ACE, we select it as the first of two central models, which will serve as use-case to develop our methods. The idea is to formally specify and then verify the process of bilateral decentralized trading because it is the most complex of the features and connects directly to ACE.

We implemented Chapter II of the book. TODO: shortly explain how agents behave

The model specification requires to shuffle agents before every step. This happens automatically due to race-conditions in concurrency we arrive at an effectively shuffled processing of agents: we can assume that the order of the agents is \textit{effectively} random in every step - with the important difference, that we do not have control over this randomness as we would have when shuffling.

Note that in contrast to the SIR case-study we don't provide an IO implementation because we focus on different thing here. The focus here is on how different data-structures can make a huge impact on the performance.

\subsection{Experiment Design}
We follow \cite{lysenko_framework_2008} and measure the average updates per second of the simulation with a 50x50 environment and an initial population of 500 over 60 seconds. We parametrise the model with the following configuration from chapter II of the book, of the section \textit{Carrying Capacity} (p. 30): movement, harvest, regrow, not dying of age, no seasons, no pollution, no inheritance. give the exact parameters. In this case the authors of the Sugarscape book report that the initial number of agents quickly drops and stabilises, which is in unison with our results as we show in Figure TODO. This behaviour also guarantees that we don't run out of agents and it shows the highly dynamic nature of the model and the ability of our implementation to quickly spawn and terminate threads.

For each experiment we conducted 8 runs on our machine (see Table \ref{tab:machine_specs}) under no additional work-load and report both the average and standard deviation. In the experiments we varied the number of cores when running concurrently - the numbers are always indicated clearly. For varying the number of cores we compiled the executable using \textit{stack} and the \textit{threaded} option and executed it with \textit{stack} using the \textit{+RTS -Nx} option where x is the number of cores between 1 and 4. TODO main measure: steps/sec and retry-ratio

Note that we omit the graphical rendering in the functional approach because it is a serious bottleneck taking up substantial amount of the simulation time. Although visual output is crucial in ABS, it is not what what we are interested here thus we completely omit it and only output the number of agents in the simulation at each step piped into a file, thus omitting slow output to the console. Note that we need to produce \textit{some} output because of Haskells laziness - if we wouldn't output anything from the simulation then the expressions would actually never be fully evaluated thus resulting in ridiculous high number of steps per second but which obviously don't really reflect the true computations done.

\subsection{Naive Approach using TVar and concurrent Environment}
Experiments with varying number of cores. The results are reported in Table \ref{tab:naive_stm_results}.

state: shuffles agents after every step
environment in STM is run as concurrent agent

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c }
               & Cores & Steps            & Ratio          \\ \hline \hline 
    	State  & 1     & 1,693.1 (8.305)  & 28.219 (0.138) \\ \hline \hline
   		STM    & 1     & 1,854.2 (29.519) & 30.904 (0.491) \\ \hline
   		STM    & 2     & 2,129.5 (61.414) & 35.492 (1.023) \\ \hline
   		STM    & 3     & 2,312.5 (71.658) & 38.542 (1.194) \\ \hline
   		STM    & 4     & 2,238.8 (36.307) & 37.312 (0.605) \\ \hline
   	\end{tabular}
  	
  	\caption{Performance on 50x50 grid and 500 initial agents with varying number of cores.}
	\label{tab:naive_results_time}
\end{table}

We also compared the average retry-ratio on varying number of cores.

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c }
        Cores & Commits           & Retries            & Ratio \\ \hline \hline 
    	1     & 498,881 (3,042.4) & 2,407.8 (248.56)   & 0.004 \\ \hline
   		2     & 557,800 (7,503.3) & 592,890 (8,827.9)  & 1.062 \\ \hline
   		3     & 540,700 (7,530.2) & 1,189,100 (19,771) & 2.199 \\ \hline
   		4     & 486,850 (7,927.9) & 1,646,800 (29,939) & 3.382 \\ \hline
   	\end{tabular}
  	
  	\caption{Retries on 50x50 grid and 500 initial agents with varying number of cores.}
	\label{tab:naive_results_retries}
\end{table}

\subsection{Running Environment non-concurrently}
Running concurrently is strictly speaking wrong because could lead to runs where the regrowth happens after the agent harvests which violates the model specifications. 

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c }
        Cores & Steps            & Ratio           \\ \hline \hline 
    	1     & 1,868.8 (19.129) & 31.146 (0.318) \\ \hline
   		2     & 2,121.1 (36.294) & 35.352 (0.604) \\ \hline
   		3     & 2,325 (53.570)   & 38.750 (0.892) \\ \hline
   		4     & 2,245 (40.175)   & 37.417 (0.669) \\ \hline \hline
   	\end{tabular}
  	
  	\caption{Performance on 50x50 grid and 500 initial agents with varying number of cores.}
	\label{tab:naive_results_time}
\end{table}

We also compared the average retry-ratio on varying number of cores.

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c }
        Cores & Commits           & Retries            & Ratio \\ \hline \hline 
    	1     &                   &                    &  \\ \hline
   		2     &                   &                    &  \\ \hline
   		3     &                   &                    &  \\ \hline
   		4     &                   &                    &  \\ \hline
   	\end{tabular}
  	
  	\caption{Retries on 50x50 grid and 500 initial agents with varying number of cores.}
	\label{tab:naive_results_retries}
\end{table}

Seems to have no effect, can omit it and replace the results when running with environment 

\subsection{From TVar to TArray}
Environment runs after all agents.

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c }
        Cores & Steps            & Ratio          \\ \hline \hline 
    	1     & 3,047.8 (11.042) & 50.796 (0.184) \\ \hline
   		2     & 4,127.2 (31.824) & 68.788 (0.530) \\ \hline
   		3     & 4,641.2 (31.459) & 77.354 (0.524) \\ \hline
   		4     & 5,215.5 (29.057) & 86.925 (0.484) \\ \hline \hline
   	\end{tabular}
  	
  	\caption{Performance on 50x50 grid and 500 initial agents with varying number of cores.}
	\label{tab:naive_results_time}
\end{table}

We also compared the average retry-ratio on varying number of cores.

\begin{table}
	\centering
  	\begin{tabular}{ c || c | c | c }
        Cores & Commits           & Retries            & Ratio \\ \hline \hline 
    	1     &                   &                    &  \\ \hline
   		2     &                   &                    &  \\ \hline
   		3     &                   &                    &  \\ \hline
   		4     &                   &                    &  \\ \hline
   	\end{tabular}
  	
  	\caption{Retries on 50x50 grid and 500 initial agents with varying number of cores.}
	\label{tab:naive_results_retries}
\end{table}

TODO: informally (no result table for all cores) test performance with concurrent environment

\subsection{Scaling up Agents}
TODO: using TArray, environment with every cell full resources so agents don't starve to death, 500, 1000, 1500, 2000, on 4 cores

\subsection{Conclusions}
Note that we kept the grid-size constant because we implemented the environment as a single agent which works sequentially on the cells to regrow the sugar. Obviously this doesn't really scale up on parallel hardware and indeed, the performance goes down dramatically as reported in table TODO when we increase the environment to 128x128 with same number of agents. Obviously this is the result of Amdahls law where the environment becomes the limiting factor of the simulation.
Depending on the underlying data-structure used for the environment we have to options. In the case of the State and TVar implementation we build on an indexed array which we can updated in parallel using the existing data-parallel support in Haskell (TODO: explain). In the case of the TArray approach we have no option but to run the update of every cell within its own thread. We leave both for further research as it is out of scope of this paper.

Comparison with imperative approaches: they are running it on 128x128 and on 10 year old single-core machines  \cite{lysenko_framework_2008}
% RePast & 1     & N/A             & 17    \\ \hline \hline
% GPU    & N/A   & N/A             & 2000  \\ \hline \hline
