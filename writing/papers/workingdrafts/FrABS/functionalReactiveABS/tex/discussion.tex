\section{Benefits and Drawbacks}
\subsection{Benefits}

\subsubsection{Continuous Time}
It seems that in our approach we combine the benefits of SD and ABS: we have continuous time-semantics but with individual, heterogenous agents.

\subsubsection{Code close to specification}
When looking at the code of the agent-based implementation in Appendix \ref{app:abs_code} and SD implementation in Appendix \ref{app:sd_code}, both look very much like a specification. By creating this EDSL which allows to express powerful time-semantics it is possible to now create an ABS in a declarative style in Haskell where the agent-implementation looks very much like a model-specification thus being correct by definition.
We claim that this is not only true for models with time-semantics but also with models which lack time-semantics and resemble a more imperative style of behaviour. We can also capture this using monadic programming using the State Monad for which we provide EDSL primitives as well which support all necessary operations in a monadic context.

\subsubsection{Being pure}
Because no part of the simulation runs in the IO monad and we do not use unsafePerformIO we can rule out a serious class of bugs caused by implicit data-dependencies and side-effects which can occur in traditional imperative implementations. Note that we actually use unsafePerformIO when one wants to generate unique agent-ids for new agents which are created during the simulation. This is necessary because in this case we need to guarantee that two invocations will result in two different ids, which would be difficult / impossible when running the simulation in the \textit{parallel} update-strategy. This is not a problem as long as an agent does not rely on the absolute value of an agent-id but just uses it as an opaque identifier for messaging.
Also we can statically guarantee the reproducibility of the simulation. Within the agents there are no side effects possible which could result in differences between same runs (e.g. file access, networking, threading, random-number seeding). Every agent has access to its own random-number generator, allowing randomness to occur in the simulation but the random-generator seed is fixed in the beginning and can never be changed within an agent to come from e.g. the current system time, which would require to run within the IO Monad. This means that after initialising the agents, which \textit{could} run in the IO Monad, the simulation itself runs completely deterministic.
We provide functionality to render the output to a window (using the Gloss library) or writing to a text-file, meaning, parts of the simulation would run in the IO Monad. Here we rely on Yampas \textit{reactimate} function which provides a well-defined way of communicating with the world in such a system. This function provides the $\Delta t$ for the next step, which \textit{could} come from IO Monad but we forbid this and keep the $\Delta t$ always fixed, thus removing another source of non-reproducibility where $\Delta t$ is influenced by sytem dependent non deterministic rendering-performance every step as happens in games or described by \cite{perez_testing_2017} in the context of FRP.

\subsubsection{Robust time handling}
The actual $\Delta t$ is never visible leads to an even more declarative style and supports the EDSL greatly. This also makes it impossible to mess around with time.

\subsubsection{Replications}
We nearly get replications for free without having to worry about side-effects and can even run them in parallel without headaches.

\subsection{Drawbacks}
We identify two main drawbacks.

\subsubsection{Performance}
Performance is currently no where near imperative object-oriented implementations. The reason for this is that we don't have in-place updates of data-structures and make no use of references. This results in lots of copying which is simply not necessary in the imperative languages with implicit effects. Also it is much more difficult to reason about time and space in our approach. Thus we see performance clearly as the main drawback of the functional approach and the only real advantage of the imperative approach over our.

\subsubsection{Steep learning curve}
Our approach is quite advanced in three ways. First it builds on the already quite involved FRP paradigm. Second it forces one to think properly of time-semantics of the model, how to sample it, how small $\Delta t$ should be and whether one needs super-sampling or not and if yes how many samples one should take. Third it requires to think about agent-interaction and update-strategies, whether one should use conversations which forces one to run sequentially or if one can run agents in parallel and use normal messaging which incurs a time-delay which in turn would need to be considered when setting the $\Delta t$.