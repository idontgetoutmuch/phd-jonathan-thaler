%\section{Conclusions and Further Research}
\section{Conclusions}
Our approach is radically different from traditional approaches in the ABS community. First it builds on the already quite involved FRP paradigm. Second, due our hybrid approach, it forces one to think properly of time-semantics of the model, how to sample it, how small $\Delta t$ should be and whether one needs super-sampling or not and if yes how many samples one should take. Third it requires to think about agent-interactions in a new way instead of being just method-calls. Also due to the underlying nature and motivation of FRP and Yampa, agents can be seen as signals which are generated and consumed by a signal function. If an agent does not change, the output signal should be constant and if the agent changes e.g. by sending a message or changing its state, the output signal should change as well. A dead agent then should have no signal at all. The agents in all but the very first step of our approach are completely time-dependent which means they will not act when time does not advance. Thus when running our simulation with $\Delta t = 0$ the dynamics stay constant and won't change.

We have also implemented synchronous interactions, which we termed agent-transactions in an additional step step but which we omitted due to lack of space. Agent-transactions are necessary when an arbitrary number of interactions between two agents without time-lag are required. The use-case for this are price negotiations between multiple agents where the agents need to come to an agreement in the same time-step. In the end, agent-transactions can be seen as a kind of method-call emulation of object-oriented programming with different typing.

Also we have built a full blown library for implementing pure agent-based simulations which implements and combines all the presented techniques including agent-transactions. As examples we implemented a number of well known agent-based models with various complexity, including the seminal and highly complex Sugarscape model \cite{epstein_growing_1996} and Schelling Segregation \cite{schelling_dynamic_1971}. Compared to object-oriented implementations, the pure functional ones are quite concise and highly expressive. This shows that from an engineering point-of-view a pure functional approach to ABS is as well suited as object-oriented techniques \footnote{The code is freely available at \url{https://github.com/thalerjonathan/chimera} and we plan on releasing it on Hackage in the future.}.

Because no part of the simulation runs in the IO Monad and we do not use unsafePerformIO we can rule out a serious class of bugs caused by implicit data-dependencies and side-effects which can occur in traditional imperative implementations. Also we can statically guarantee the reproducibility of the simulation. Within the agents there are no side effects possible which could result in differences between same runs (e.g. file access, networking, threading, random-number re-seeding). Every agent has access to its own random-number generator or the Random Monad, allowing randomness to occur in the simulation but the random-generator seed is fixed in the beginning and can never be changed within an agent to come from e.g. the current system time, which would require to run within the IO Monad. This means that after initialising the agents, which \textit{could} run in the IO Monad, the simulation itself runs completely deterministicly. This is also ensured through fixing the $\Delta t$ and not making it dependent on the performance of e.g. a rendering-loop or other system-dependent sources of non-determinism as described by \cite{perez_testing_2017}. Also by using FRP we gain all the benefits from it and can use research on testing, debugging and exploring FRP systems \cite{perez_testing_2017}, \cite{perez_back_2017}.

\subsection*{Drawbacks}
Unfortunately, the hybrid approach of SD/ABS amplifies the performance issues of agent-based approaches, which requires much more processing power compared to SD, because each agent is modelled individually in contrast to aggregates in SD \cite{macal_agent-based_2010}. With the need to sample the system with high frequency, this issue gets worse. The reason for this is that we don't have in-place updates of data structures and make no use of references. This results in lots of copying which is simply not necessary in the imperative languages with implicit effects. Also it is much more difficult to reason about time and space in our approach. %Although implementing super-sampling could be a remedy, the performance of the agent-based SIR implementation is currently nowhere near imperative object-oriented implementations which we have tried as well using Java and the RePast library. 

Despite the strengths and benefits we get by leveraging on FRP, there are also weakness to it which show up in our approach as well. The authors \cite{sculthorpe_safe_2009} show that the type-system of Yampa is not safe as FRP is sacrificing the safety of FP for sake of expressiveness. Amongst others they showed that well-formed feedback does depend on the programmer and cannot be guaranteed at compile time through the type system. Feedback is an inherent feature of ABS where agents update their state at time t+1 depending on time t. This is only visible in Section \ref{sec:step2_frp} where we use feedback to update the random-number generator (rec/iPre/feedback makes the inherently feedback nature of ABS very explicit) but in more complex ABS models with a more complex state than in the SIR model, feedback is the core feature to keep and update the state of an agent. Also a chain of switches could result in an infinite loop - this cannot be checked at compile time and needs to be carefully designed by the programmer and results sometimes in popping up of operational details (e.g. the need to use $>>> notYet$ in parallel switches for stepping the simulation). 
%Another weakness of the approach is that implementing a more complicated agent-transaction protocol correctly can get very challenging. This might not seem directly evident from the implementation in Step 6 but the problem is that there are lots of operational details which the programmer needs to keep in mind and get right to arrive at a correctly working transaction. It would be nice if we have support from the type-system which enforces a given protocol but this is not possible with our approach so far. Note that beside failing to stick to the protocol it is also possible to implement non-total transactions. Note that making the transition from Yampa to the general MSF approach provided by Dunai and BearRiver does not solve this fundamental problem.

Also having a two layer (arrows and pure functions) language in Yampa \cite{jeffrey_causality_2013} and three a layer (arrows, monadic and pure functions) language in Dunai / BearRiver adds expressivity and power but can make things quite complex already in the simple SIR example. Fortunately with a more complex model the complexity in this context does not increase - in the end it is the price we need to pay for the high expressivity which functions like \textit{occasionally} provide.

TODO: this paragraph is too negative, formulate it a bit different
We started with high hopes for the pure functional approach and hypothesized that it will be truly superior to existing traditional object-oriented approaches but we came to the conclusion that this is not so. The single real benefit is the lack of implicit side-effects and reproducibility guaranteed at compile time. But our research was not in vain as we see it as an intermediary step towards using dependent types together with the pure functional approach. Moving to dependent types would pose a unique benefit over the object-oriented approach and would allow us to express and guarantee properties at compile time which is not possible with imperative approaches. We leave this for further research.

\section{Further Research}
As already mentioned, we see this paper as an intermediary and necessary step towards dependent types for which we first need to understand the potentials and limitations of a non-dependently typed pure functional approach in Haskell. Dependent types is extremely promising in functional programming as they allow us to express stronger guarantees about the correctness of programs and go as far as formulating programs and types as constructive proofs \cite{wadler_propositions_2015} which must be total by definition \cite{thompson_type_1991}, \cite{altenkirch_why_2005}, \cite{altenkirch_pi_sigma:_2010}, \cite{program_homotopy_2013}. So far no research using dependent types in agent-based simulation exists at all and it is not clear whether dependent types make sense in this setting. In our next paper we want to explore this for the first time and ask more specifically how we can add dependent types to our pure functional approach, which conceptual implications this has for ABS and what we gain from doing so. We plan on using Idris \cite{brady_idris_2013}, \cite{brady_type-driven_2017} as the language of choice as it is very close to Haskell with focus on real-world application and running programs as opposed to other languages with dependent types e.g. Agda and Coq which serve primarily as proof assistants.
It would be of immense interest whether we could apply dependent types to the model meta-level or not - this boils down to the question if we can encode our model specification in a dependent type way. This would allow the ABS community for the first time to reason about a proper formalisation of a model. We plan to implement a total and terminating implementation of our approach which would be a formal proof-by-construction that the agent-based approach of the SIR model terminates after a finite number of steps.