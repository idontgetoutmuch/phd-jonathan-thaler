\section{Verification}

TODO: explore ABS testing in pure functional Haskell
- we need to distinguish between two types of testing/verification
	-> 1. testing/verification of models for which we have real-world data or an analytical solution which can act as a ground-truth. examples for such models are the SIR model, stock-market simulations, social simulations of all kind
	-> 2. testing/verification of models which are just exploratory and which are only be inspired by real-world phenomena. examples for such models are Epsteins Sugarscape and Agent\_Zero
	
\subsection{Black Box Verification}
Defined as treating the functionality to test as a black box with inputs and outputs and comparing controlled inputs to expected outputs.

In Black Box Verification one generally feeds input and compares it to expected output. In the case of ABS we have two things to black-box test:
\begin{enumerate}
	\item Isolated Agent Behaviour - test isolated agent behaviour under given inputs using unit- and property-based testing
	\item Interacting Agent Behaviour - test if interaction between agents are correct 
	\item Simulation Dynamics - compare emergent dynamics of the ABS as a whole under given inputs to an analytical solution / real-world dynamics in case there exists some using statistical tests
	\item Hypotheses- test whether hypotheses are valid / invalid using unit- and property-based testing. TODO: how can we formulate hypotheses in unit- and/or property-based tests?
\end{enumerate}

- testing of the final dynamics: how close do they match the analytical solution
- can we express model properties in tests e.g. quickcheck?
- property-testing shines here
- isolated tests: how easy can we test parts of an agent / simulation?

\subsubsection{Finding optimal $\Delta t$}
The selection of the right $\Delta t$ can be quite difficult in FRP because we have to make assumptions about the system a priori. One could just play it safe with a very conservatively selected small $\Delta t <= 0.1$ but the smaller $\Delta t$, the lower the performance as it quickly multiplies the number of steps to calculate. Obviously one wants to select the \textit{optimal} $\Delta t$, which in the case of ABS is the largest possible $\Delta t$ for which we still get the correct simulation dynamics.
To find out the \textit{optimal} $\Delta t$ one can make direct use of the Black Box tests: start with a large $\Delta t = 1.0$ and reduce it by half every time the tests fail until no more tests fail - if for $\Delta t = 1.0$ tests already pass, increasing it may be an option. It is important to note that although isolated agent behaviour tests might result in larger $\Delta t$, in the end when they are run in the aggregate system, one needs to sample the whole system with the smallest $\Delta t$ found amongst all tests. Another option would be to apply super-sampling to just the parts which need a very small $\Delta t$ but this is out of scope of this paper.

\subsubsection{Agents as signals}
Agents \textit{might} behave as signals in FRP which means that their behaviour is completely determined by the passing of time: they only change when time changes thus if they are a signal they should stay constant if time stays constant. This means that they should not change in case one is sampling the system with $\Delta t = 0$. Of course to prove whether this will \textit{always} be the case is strictly speaking impossible with a Black Box verification but we can gain a good level of confidence with them also because we are staying pure. It is only through white box verification that we can really guarantee and prove this property.

\subsubsection{Comparison of dynamics against existing data}
- utilise a statistical test with H0 "ABS and comparison is not the same" and H1 "ABS and comparison is the same"
- how many replications and how do we average?
- which statistical test do we implement? (steward robinson simulation book, chapter 12.4.4)
	-> Normalizsed Mean Squared Error (NMSE)
	-> TODO: implement confidence interval 
	-> TODO: what about chi-squared?
	-> TODO: what about paired-t confidence interval

IMPORTANT: this is not what we are after here in this paper, statistical tests are a science on their own and there actually exists quite a large amount of literature for conducting statistical tests on ABS dynamics: Robinson Book (TODO: find additional literature)	

\subsection{White Box Verification}
White-Box verification is necessary when we need to reason about properties like \textit{forever}, \textit{never}, which cannot be guaranteed from black-box tests. Additional help can be coverage tests with which we can show that all code paths have been covered in our tests.

\subsection{Property-Testing}
TODO: describe what i did using quickcheck 
TODO: implement quickcheck test for combining susceptible and infected

\subsection{White-box Verification}
TODO: describe reasoning about the code

In this section we verify our agent-based implementation of the SIR model. Verification of our implementation should be fairly straight-forward and easy as the model is given in differential equations which gives us a formal specification of the model which we can use directly in our verification process. We will also conduct white-box verification and for one property it will be the only way of ensuring that our model is correct as we cannot guarantee it through black-box verification.

\subsection{Black Box Verification}
\subsubsection{Agent Behaviour}
When conducting black-box testing for the SIR model, we test if the \textit{isolated} behaviour of an agent in all three states Susceptible, Infected and Recovered, corresponds to model specifications. The crucial thing though is that we are dealing with a stochastic system where the agents act \textit{on averages}, which means we need to average our tests as well.

The interface of the agent behaviours are defined below. When running the SF with a given $\Delta t$ one has to feed in the state of all the other agents as input and the agent outputs its state it is after this $\Delta t$.

\begin{minted}{haskell}
data SIRState 
  = Susceptible 
  | Infected 
  | Recovered
  
type SIRAgent = SF [SIRState] SIRState

susceptibleAgent :: RandomGen g => g -> SIRAgent
infectedAgent :: RandomGen g => g -> SIRAgent
recoveredAgent :: SIRAgent
\end{minted}


\paragraph{Susceptible Behaviour}
A susceptible agent \textit{may} become infected, depending on the number of infected agents in relation to non-infected the susceptible agent has contact to. To make this property testable we run a susceptible agent for 1.0 time-unit (note that we are sampling the system with small $\Delta t$ e.g. 0.1) and then check if it is infected - that is it returns infected as its current state. Obviously we need to pay attention to the fact that we are dealing with a stochastic system thus we can only talk about averages and thus it does not suffice to only run a single agent but we are repeating this for e.g. $N = 10.000$ agents (all with different RNGs). We then need a formula for the required fraction of the N agents which should have become infected on average. Per 1.0 time-unit, a susceptible agent makes \textit{on average} contact with $\beta$ other agents where in the case of a contact with an infected agent the susceptible agent becomes infected with a given probability $\gamma$. In this description there is another probability hidden, which is the probability of making contact with an infected agent which is simply the ratio of number of infected agents to number not infected agents. The formula for the target fraction of agents which become infected is then: $\beta * \gamma * \frac{number of infected}{number of non-infected}$. To check whether this test has passed we compare the required amount of agents which on average should become infected to the one from our tests (simply count the agents which got infected and divide by N) and if the value lies within some small $\epsilon$ then we accept the test as passed.

Obviously the input to the susceptible agents which we can vary is the set of agents with which the susceptible agents make contact with. To save us from constructing all possible edge-cases and combinations and testing them with unit-tests we use QuickCheck which creates them randomly for us and reduces them also to all relevant edge-cases. This is an example for how to use property-based testing in ABS where QuickCheck can be of immense help generating random test-data to cover all cases.

TODO: derive the target-fraction formula from the differential equations
TODO: can we encode this somehow on a type level using dependent types? then we don't need to test this property any more

\paragraph{Infected Behaviour}
An infected agent \textit{will always} recover after a finite time, which is \textit{on average} after $\delta$ time-units. Note that this property involves stochastics too, so to test this property we run a large number of infected agents e.g. $N = 10.000$ (all with different RNGs) until they recover, record the time of each agents recovery and then average over all recovery times. To check whether this test has passed we compare the average recovery times to $\delta$ and if they lie within some small $\epsilon$ then we accept the test as passed.
We use QuickCheck in this case as well to generate the set of other agents as input for the infected agents. Strictly speaking this would not be necessary as an infected agent never makes contact with other agents and simply ignores them - we could as well just feed in an empty list. We opted for using QuickCheck for the following reasons:

\begin{itemize}
	\item We wanted to stick to the interface specification of the agent-implementation as close as possible which asks to pass the states of all agents as input.
	\item We shouldn't make any assumptions about the actual implementation and if it REALLY ignores the other agents, so we strictly stick to the interface which requires us to input the states of all the other agents.
	\item The set of other agents is ignored when determining whether the test has failed or not which indicates by construction that the behaviour of an infected agent does not depend on other agents.
	\item We are not just running a single replication over 10.000 agents but 100 of them which should give black-box verification more strength.
\end{itemize}

TODO: derive the average formula from the differential equations
TODO: can we encode this somehow on a type level using dependent types? then we don't need to test this property any more

\paragraph{Recovered Behaviour}
A recovered agent will stay in the recovered state \textit{forever}. Obviously we cannot write a black-box test that truly verifies that because it had to run in fact forever. In this case we need to resort to White Box Verification (see below).

Because we use multiple replications in combination with QuickCheck obviously results in longer test-runs (about 5 minutes on my machine)
In our implementation we utilized the FRP paradigm. It seems that functional programming and FRP allow extremely easy testing of individual agent behaviour because FP and FRP compose extremely well which in turn means that there are no global dependencies as e.g. in OOP where we have to be very careful to clean up the system after each test - this is not an issue at all in our \textit{pure} approach to ABS.

\subsubsection{Simulation Dynamics}
We won't go into the details of comparing the dynamics of an ABS to an analytical solution, that has been done already by \cite{macal_agent-based_2010}. What is important is to note that population-size matters: different population-size results in slightly different dynamics in SD => need same population size in ABS (probably...?). Note that it is utterly difficult to compare the dynamics of an ABS to the one of a SD approach as ABS dynamics are stochastic which explore a much wider spectrum of dynamics e.g. it could be the case, that the infected agent recovers without having infected any other agent, which would lead to an extreme mismatch to the SD approach but is absolutely a valid dynamic in the case of an ABS. The question is then rather if and how far those two are \textit{really} comparable as it seems that the ABS is a more powerful system which presents many more paths through the dynamics.
TODO: i really want to solve this for the SIR approach
	-> confidence intervals?
	-> NMSE?
	-> does it even make sense?

\subsubsection{Finding optimal $\Delta t$}
Obviously the \textit{optimal} $\Delta t$ of the SIR model depends heavily on the model parameters: contact rate $\beta$ and illness duration $\delta$. We fixed them in our tests to be $\beta = 5$ and $\delta = 15$. By using the isolated behaviour tests we found an optimal $\Delta t = 0.125$ for the susceptible behaviour and $\Delta t = 0.25$ for the infected behaviour. TODO: dynamics comparison?

\subsubsection{Agents as signals}
Our SIR agents \textit{are} signals due to the underlying continuous nature of the analytical SIR model and to some extent we can guarantee this through black box testing. For this we write tests for each individual behaviour as previously but instead of checking whether agents got infected or have recovered we assume that they stay constant: they will output always the same state when sampling the system with $\Delta t = 0$. The tests are conceptual the complementary tests of the previous behaviour tests so in conjunction with them we can assume to some extent that agents are signals. To prove it, we need to look into white box verification as we cannot make guarantees about properties which should hold \textit{forever} in a computational setting.

\subsection{White Box Verification}
In the case of the SIR model we have the following invariants: 
\begin{itemize}
	\item A susceptible agent will \textit{never} make the transition to recovered.
	\item An infected agent will \textit{never} make the transition to susceptible.
	\item A recovered agent will \textit{forever} stay recovered.
\end{itemize}

All these invariants can be guaranteed when reasoning about the code. An additional help will be then coverage testing with which we can show that an infected agent never returns susceptible, and a susceptible agent never returned infected given all of their functionality was covered which has to imply that it can never occur!

Lets start with looking at the recovered behaviour as it is the simplest one. We then continue with the infected behaviour and end with the susceptible behaviour as it is the most complex one.

\paragraph{Recovered Behaviour}
The implementation of the recovered behaviour is as follows:

\begin{minted}{haskell}
recoveredAgent :: SIRAgent
recoveredAgent = arr (const Recovered)
\end{minted}

Just by looking at the type we can guarantee the following:
\begin{itemize}
	\item it is pure, no side-effects of any kind can occur
	\item no stochasticity possible because no RNG is fed in / we don't run in the random monad
\end{itemize}

The implementation is as concise as it can get and we can reason that it is indeed a correct implementation of the recovered specification: we lift the constant function which returns the Recovered state into an arrow. Per definition and by looking at the implementation, the constant function ignores its input and returns always the same value. This is exactly the behaviour which we need for the recovered agent. Thus we can reason that the recovered agent will return Recovered \textit{forever} which means our implementation is indeed correct.

\paragraph{Infected Behaviour}
\begin{minted}{haskell}
infectedAgent :: RandomGen g 
              => g 
              -> Double
              -> SIRAgent
infectedAgent g illnessDuration = 
    switch 
      infected 
      (const recoveredAgent)
  where
    infected :: SF [SIRState] (SIRState, Event ())
    infected = proc _ -> do
      recEvt <- occasionally g illnessDuration () -< ()
      let a = event Infected (const Recovered) recEvt
      returnA -< (a, recEvt)
\end{minted}

By looking at the types we can reason that there \textit{may} be some stochasticity involved (the function may choose to ignore the RNG) and that we are again pure. TODO: not finished yet

\paragraph{Susceptible Behaviour}
\begin{minted}{haskell}
susceptibleAgent :: RandomGen g 
                 => g 
                 -> Double
                 -> Double
                 -> Double 
                 -> SIRAgent
susceptibleAgent g contactRate infectivity illnessDuration = 
    switch
      (susceptible g) 
      (const (infectedAgent g illnessDuration))
  where
    susceptible :: RandomGen g => g -> SF [SIRState] (SIRState, Event ())
    susceptible g = proc as -> do
      makeContact <- occasionally g (1 / contactRate) () -< ()

      -- NOTE: strangely if we are not splitting all if-then-else into
      -- separate but only a single one, then it seems not to work,
      -- dunno why
      if isEvent makeContact
        then (do
          a <- drawRandomElemSF g -< as
          case a of
            Just Infected -> do
              i <- randomBoolSF g infectivity -< ()
              if i
                then returnA -< (Infected, Event ())
                else returnA -< (Susceptible, NoEvent)
            _       -> returnA -< (Susceptible, NoEvent))
        else returnA -< (Susceptible, NoEvent)
\end{minted}

TODO: not finished yet

\subsection{Interacting Agent Behaviour}
TODO: haven't look into this yet