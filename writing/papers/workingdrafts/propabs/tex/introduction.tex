\section{Introduction}
% what is the problem
When implementing an agent-based simulation (ABS) it is of utmost importance that the implementation is correct up to a specification, which is the model. To ensure that an implementation matches a specification, one uses verification, which ensures that \textit{"we are building the model right"} (TODO: cite). With the established approaches in the field of ABS, which are primarily the object-oriented programming languages Java, Python and C++, it is very difficult, or might even be impossible to \textit{formally} prove that an implementation is correct up to a specification. Also one can say in general that formal proofs of correctness are highly complex and take a lot of effort and are almost always beyond the scope of a project and just not feasible. Still, not checking the correctness of the implementation in \textit{some} way would be highly irresponsible and thus software engineers have developed the concept of unit-testing and test-driven development (todo: cite). Put shortly, in test-driven development one implements unit-tests for each feature to implement before actually implementing the feature. Then the features is implemented and the tests for it should pass. This cycle is repeated until the implementation of all requirements has finished. Of course it is important to cover the whole functionality with tests to be sure that all cases are checked which can be supported by code coverage tools to ensure that all code-paths have been tested.
Thus we can say that test-driven development in general and unit-testing together with code-coverage in particular, allow to guarantee the correctness of an implementation to some informal degree which has been proven to be sufficiently enough through years of practice in the software industry all over the world. Also a fundamental strength of such tests is that programmers gain much more confidence when making changes to code - without such tests all bets are off and there is no reliable way to know whether the changes have broken something or not.

% related works
The work of \cite{collier_test-driven_2013} discusses how to apply the test-driven development approach to ABS, using unit-testing to check the correctness of the implementation up to a certain level. The paper \cite{asta_investigation_2014} discusses a similar approach to DES in the AnyLogic software toolkit which also supports ABS and thus we claim can be applied to ABS as well. %We experienced when doing the literature review of this paper that while there exists quite some work on validating an ABS, there doesn't exist much work on verification which discusses the problem from an implementation perspective with program code with these two papers being the only exception.

The paper \cite{nguyen_testing_2011} is a survey of testing in multi-agent systems (MAS). Although MAS is a different discipline than ABS, the latter one has derived many technical concepts from the former one thus testing concepts applied to MAS might be also applicable to ABS. The paper distinguisheds between unit tests which tests units that make up an agent, agent tests which test the combined functionality of units that make up an agent, integration tests which test the interaction of agents within an environment and observe emergent behaviour, system test which test the MAS as a system running at the target environment and acceptance test in which stakeholders verify that the software meets their goal. The paper enumerates existing research and shows that some research is working on generating automated test input for agent level tests.

The paper \cite{tiryaki_sunit:_2007} discusses Test Driven Development in MAS and puts much emphasis on proposing agile processes to develop MAS software to handle complexity and continuously changing nature of requirements. The authors develop the SUNIT testing framework to implement unit-testing in an MAS environment.

% the gap & what this paper adds
In this paper we discuss a complementary method of testing the implementation of an ABS, called \textit{property-based} testing, which allows to directly express model-specifications in code and test them through \textit{automated} test-generation. Property-based testing has its origins \cite{claessen_quickcheck:_2000, claessen_testing_2002, runciman_smallcheck_2008} in the pure functional programming language Haskell \cite{hudak_history_2007} where it was first conceived and implemented and thus we discuss it from that perspective. It has been successfully used for testing Haskell code for years an also been proven valuable and successful in the industry \cite{hughes_quickcheck_2007}, thus we investigate its potential for ABS. To to our best knowledge property-based testing has not been discussed in the field of ABS yet and we hypothesise that adding it to the already existing testing methods in the field of ABS is of substantial value. To substantiate and test our claims, we present two models as case-studies. First, the agent-based SIR model \cite{macal_agent-based_2010}, which is of explanatory nature, where we show how to express formal model-specifications in property-tests. Second, the SugarScape model \cite{epstein_growing_1996}, which is exploratory nature, where we show how to express hypotheses in property-tests.

% aim & contribution
The aim and contribution of this paper is the investigation of the potential of pure functional property-based testing for ABS using Haskell as programming language. Further we will show that by simply using a pure functional programming language removes a large class of run-time errors and allows much stronger guarantees of correctness already at compile time, making the implementation to \textit{very likely} be correct.

% structure
The structure of the paper is as follows. First we discuss the background in which we conceptually introduce property-based testing and pure functional programming in Haskell to make this paper sufficiently self-contained. Then we shortly present existing research on \textit{how} to implement ABS in Haskell. Then we present both case-studies in Section \ref{sec:case_SIR} and Section \ref{sec:case_sug}. Finally we conclude in Section \ref{sec:conclusions} and give further research in Section \ref{sec:further}. 