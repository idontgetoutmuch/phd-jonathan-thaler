\section{Pure Functional ABS}
TODO: introduce the general concepts of pure functional ABS and what the benefits and drawbacks are in the context of debugging and correctness, using my IFL paper

We argue that due to its fundamental different nature, the functional programming paradigm can overcome some fundamental problems of the established object-oriented approach to ABS. Note that we don't claim that it will solve all the problems and that the Gintis failure wouldn't have happened but we argue that it makes making mistakes much harder, resulting in simulations which are more likely to be correct.

We have investigated the concepts of \textbf{\textit{how}} to do agent-based simulation using the functional programming paradigm, as in the language Haskell, which is described in the paper in Appendix \ref{app:pfe}. The approach we developed is based on Functional Reactive Programming which allows to express discrete- and continuous-time systems in functional programming. Following the conclusions of the paper, we got the following benefits, supporting directly our initial hypothesis and our claims above, giving good reasons \textbf{\textit{why}} to do ABS in a functional way:

\begin{enumerate}
	\item Run-Time robustness by compile-time guarantees - by expressing stronger guarantees already at compile-time we can restrict the classes of bugs which occur at run-time by a substantial amount due to Haskell's strong and static type system.  This implies the lack of dynamic types and dynamic casts \footnote{Note that there exist casts between different numerical types but they are all safe and can never lead to errors at run-time.} which removes a substantial source of bugs.  Note that we can still have run-time bugs in Haskell when our functions are partial.
	\item Purity - By being explicit and polymorphic in the types about side-effects and the ability to handle side-effects explicitly in a controlled way allows to rule out non-deterministic side-effects which guarantees reproducibility due to guaranteed same initial conditions and deterministic computation. Also by being explicit about side-effects e.g. Random-Numbers and State makes it easier to verify and test.
	\item Explicit Data-Flow and Immutable Data - All data must be explicitly passed to functions thus we can rule out implicit data-dependencies because we are excluding IO. This makes reasoning of data-dependencies and data-flow much easier as compared to traditional object-oriented approaches which utilize pointers or references.
	\item Declarative - describing \textit{what} a system is, instead of \textit{how} (imperative) it works. In this way it should be easier to reason about a system and its (expected) behaviour because it is more natural to reason about the behaviour of a system instead of thinking of abstract operational details.
	\item Concurrency and parallelism - due to its pure and 'stateless' nature, functional programming is extremely well suited for massively large-scale applications as it allows adding parallelism without any side-effects and provides very powerful and convenient facilities for concurrent programming. We have explored this more in-depth in Chapter \ref{chap:stm}.
\end{enumerate}

In general, Types guide us in program construction by restricting the operations we can perform on the data. This means that by choosing types this reveals already a lot of our program and data and prevents us from making mistakes e.g. interpreting some binary data as text instead of a number. In strongly statically typed languages the types can do this already at compile-time which allows to rule out certain bugs already at compile-time. In general, we can say that for all bugs which can be ruled out at compile-time, we don't need to write property- or unit-tests, because those bugs cannot - per definition - occur at run-time, so it won't make sense to test their absence at run-time. Also, as Dijkstra famously put it: "Testing shows the presence, not the absence of bugs" - thus by induction we can say that compile-time guarantees save us from a potentially infinite amount of testing.

In general it is well established, that pure functional programming as in Haskell, allows to express much stronger guarantees about the correctness of a program \textit{already at compile-time}. This is in fundamental contrast to imperative object-oriented languages like Java or Python where only primitive guarantees about types - mostly relationships between type-hierarchies - can be expressed at compile-time which directly implies that one needs to perform much more testing (user testing or unit-testing) at \textit{run-time} to check whether the model is sufficiently correct. Thus guaranteeing properties already at compile-time frees us from writing unit-tests which cover these cases or test them at run time because they are \textit{guaranteed to be correct under all circumstances, for all inputs}.

In this regards we see pure functional programming as truly superior to the traditional object oriented approaches: they lead to implementations of models which are more likely correct because we can express more guarantees already at compile-time which directly leads to less bugs which directly increases the probability of the software being a correct implementation of the model. Having established this was only the first step in our paper in Appendix \ref{app:pfe}. 

Although pure functional ABS as in Haskell allows us to leverage on the concepts of functional and its benefits (and drawbacks) we still rely heavily on (property-based) testing to ensure correctness of a simulation because our approach still can have run-time bugs. Thus, the next step, which follows directly, is towards even stronger guarantees at compile-time, by using dependent types. 


\subsection{Implementing}
TODO: my IFL paper
TODO: Back To the Future: Time Travel in FRP \cite{perez_back_2017}

\subsection{Debugging}
TODO: haskell-titan
TODO: Testing and Debugging Functional Reactive Programming \cite{perez_testing_2017}

General there are the following basic verification \& validation requirements to ABS \cite{robinson_simulation:_2014}, which all can be addressed in our \textit{pure} functional approach as described in the paper in Appendix \ref{app:pfe}:

\begin{itemize}
	%\item Modelling progress of time - achieved using functional reactive programming (FRP)
	%\item Modelling variability - achieved using FRP
	\item Fixing random number streams to allow simulations to be repeated under same conditions - ensured by \textit{pure} functional programming and Random Monads
	\item Rely only on past - guaranteed with \textit{Arrowized} FRP
	\item Bugs due to implicitly mutable state - reduced using pure functional programming
	\item Ruling out external sources of non-determinism / randomness - ensured by \textit{pure} functional programming
	\item Deterministic time-delta - ensured by \textit{pure} functional programming
	\item Repeated runs lead to same dynamics - ensured by \textit{pure} functional programming
\end{itemize}

\subsection{Property-Based ABS Testing}
TODO: general approach to property-based testing in ABS

Although (pure) functional programming allows us to have stronger guarantees about the behaviour and absence of bugs of the simulation already at compile-time, we still need to test all the properties of our simulation which we cannot guarantee at compile-time.

We found property-based testing particularly well suited for ABS. Although it is now available in a wide range of programming languages and paradigms, propert-based testing has its origins in Haskell \cite{claessen_quickcheck:_2000, claessen_testing_2002} and we argue that for that reason it really shines in pure functional programming. Property-based testing allows to formulate \textit{functional specifications} in code which then the property-testing library (e.g. QuickCheck \cite{claessen_quickcheck:_2000}) tries to falsify by automatically generating random test-data covering as much cases as possible. When an input is found for which the property fails, the library then reduces it to the most simple one. It is clear to see that this kind of testing is especially suited to ABS, because we can formulate specifications, meaning we describe \textit{what} to test instead of \textit{how} to test (again the declarative nature of functional programming shines through). Also the deductive nature of falsification in property-based testing suits very well the constructive nature of ABS.

Generally we need to distinguish between two types of testing/verification: 1. testing/verification of models for which we have real-world data or an analytical solution which can act as a ground-truth - examples for such models are the SIR model, stock-market simulations, social simulations of all kind and 2. testing/verification of models which are just exploratory and which are only be inspired by real-world phenomena - examples for such models are Epsteins Sugarscape and Agent\_Zero.

\subsubsection{Black-Box Verification}
In black-box Verification one generally feeds input and compares it to expected output. In the case of ABS we have the following examples of black-box test:
\begin{enumerate}
	\item Isolated Agent Behaviour - test isolated agent behaviour under given inputs using and property-based testing.
	\item Interacting Agent Behaviour - test if interaction between agents are correct .
	\item Simulation Dynamics - compare emergent dynamics of the ABS as a whole under given inputs to an analytical solution or real-world dynamics in case there exists some using statistical tests.
	\item Hypotheses- test whether hypotheses are valid or invalid using and property-based testing. % TODO: how can we formulate hypotheses in unit- and/or property-based tests?
\end{enumerate}

%- testing of the final dynamics: how close do they match the analytical solution
%- can we express model properties in tests e.g. quickcheck?
%- property-testing shines here
%- isolated tests: how easy can we test parts of an agent / simulation?

Using black-box verification and property-based testing we can apply for the following use cases for testing ABS in FRP:

\paragraph{Finding optimal $\Delta t$}
The selection of the right $\Delta t$ can be quite difficult in FRP because we have to make assumptions about the system a priori. One could just play it safe with a very conservative, small $\Delta t < 0.1$ but the smaller $\Delta t$, the lower the performance as it multiplies the number of steps to calculate. Obviously one wants to select the \textit{optimal} $\Delta t$, which in the case of ABS is the largest possible $\Delta t$ for which we still get the correct simulation dynamics.
To find out the \textit{optimal} $\Delta t$ one can make direct use of the black-box tests: start with a large $\Delta t = 1.0$ and reduce it by half every time the tests fail until no more tests fail - if for $\Delta t = 1.0$ tests already pass, increasing it may be an option. It is important to note that although isolated agent behaviour tests might result in larger $\Delta t$, in the end when they are run in the aggregate system, one needs to sample the whole system with the smallest $\Delta t$ found amongst all tests. Another option would be to apply super-sampling to just the parts which need a very small $\Delta t$ but this is out of scope of this paper.

\paragraph{Agents as signals}
Agents \textit{might} behave as signals in FRP which means that their behaviour is completely determined by the passing of time: they only change when time changes thus if they are a signal they should stay constant if time stays constant. This means that they should not change in case one is sampling the system with $\Delta t = 0$. Of course to prove whether this will \textit{always} be the case is strictly speaking impossible with a black-box verification but we can gain a good level of confidence with them also because we are staying pure. It is only through white-box verification that we can really guarantee and prove this property.

\subsubsection{White-Box Verification}
White-Box verification is necessary when we need to reason about properties like \textit{forever}, \textit{never}, which cannot be guaranteed from black-box tests. Additional help can be coverage tests with which we can show that all code paths have been covered in our tests.

TODO: List of Common Bugs and Programming Practices to avoid them \cite{vipindeep_list_2005}

We have discussed in this section \textit{how} to approach an ABS implementation from a pure functional perspective using Haskell where we have also briefly touched on \textit{why} one should do so and what the benefits and drawbacks are. In the next two sections we will expand on the \textit{why} by presenting two case-studies which show the benefits of using Haskell in regards of testing and increasing the confidence in the correctness of the implementation.