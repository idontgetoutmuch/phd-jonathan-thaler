\section{A formal ABS model}
The challenges one faces when implementing an ABS plain, without support from a library are manifold. In the paper (TODO: cite my own paper on update-strategies) the authors discuss already the fundamental things to consider in a programming language agnostic way. Here we will give a concise overview of what must be done when implementing an ABS. Generally one faces the following challenges:

\begin{itemize}
	\item Agent Representation - how do we represent an agent?
	\item Agent-Agent Interaction - how can agents interact with other agents?
	\item Environment representation - how can we represent an environment? Also an environment must have the ability to update itself e.g. regrow some resources.
	\item Agent-Environment interaction - how can agents interact (read / write) with the environment they are situated in?
	\item Agent Updating - how is the set of agents organised, how are they updated and how is it managed (deleting, adding during simulation)?
\end{itemize}

\subsection{Agent Representation}
An agent can be seen as a tuple $<id, s, m, e, b>$.
\begin{itemize}
	\item \textbf{id} - the unique identifier of the agent
	\item \textbf{s} - the generic state of the agent
	\item \textbf{m} - the set of messages the agent understands
	\item \textbf{e} - the \textit{type} of the environment-cells the agent may act upon
	\item \textbf{b} - the behaviour of the agent
\end{itemize}

The id is simply represented as an Integer and must be unique for all currently existing agents in the system as it is used for message-delivery. A stronger requirement would be that the id of an agent is unique for the whole simulation-run and will never be reused - this would support replications and operations requiring unique agent-ids.

Each agent may have a generic state comprised of any data-type, most likely to be a structure.
\begin{lstlisting}[]
data SIRSState = Susceptible | Infected | Recovered
data SIRSAgentState = SIRSAgentState {
    sirsState :: SIRSState,
    sirsCoord :: SIRSCoord,
    sirsTime :: Double
} 
\end{lstlisting}

It is possible that the agent does not rely on any state s, then this will be represented by the unit type (). One wonders if this makes sense and asks how agents can then be distinguished between each other. In functional programming this is easily possible using currying and closures where one encapsulate initial state in the behaviour (see below), which allows to give each agent an individual initial state.

The behaviour of the agent is a signal-function which maps an AgentIn-Signal to an AgentOut-Signal. It has the following signature: 
\begin{lstlisting}[]
type AgentBehaviour s m e = SF (AgentIn s m e) (AgentOut s m e)
\end{lstlisting}

AgentIn provides the necessary data to the agent-behaviour: its id, incoming messages, the current state s, the environment (made out of the cells ec), its position in the environment and a random-number generator. 

AgentOut allows the agent to communicate changes out of the behaviour: kill itself, create new agents, sending messages, state s, environment (made ouf of the cells ec), environment-position and random-number generator. 

The agent needs to know the generic type of the cells the environment is made of to be able to act upon the environment. Note that at the moment we only implemented a discrete 2d environment and provide only access and manipulation to the cells in a 2d discrete fashion. In the case of a continuous n-dimensional environment this approach needs to be thoroughly revised. It is important to understand that it is the \textit{type} of the cells and not the environment itself.

\subsection{Agent-Agent Interaction}
Agents communicate with each other through messages (see below) and thus need to have an agreed set of messages they understand. This is usually implemented as an ADT.
\begin{lstlisting}[]
data SIRSMsg = Contact SIRSState
\end{lstlisting}

\subsection{Environment representation}
TODO: update, we have now also 2d-continuous AND networks!

So far we only implemented a 2d-discrete environment. It can be understood to be a tuple of $<b, d, n, w, cs>$.
\begin{itemize}
	\item \textbf{b} - the optional behaviour of the environment
	\item \textbf{d} - the dimensions of the environment: its maximum boundary extending from (0,0)
	\item \textbf{n} - the neighbourhood of the environment (Neumann, Moore)
	\item \textbf{w} - the wrapping-type of the environment (clipping, horizontal, vertical, both)
	\item \textbf{cs} - the cells of the environment of type c
\end{itemize}

We represent the environment-behaviour as a signal-function as well but one which maps an environment to itself. It has the following signature:
\begin{lstlisting}[]
type EnvironmentBehaviour c = SF (Environment c) (Environment c)
\end{lstlisting}
This is a regular SF thus having also the time of the simulation available and is called after all agents are updated. Note that the environment cannot send messages to agents because it is not an agent itself. An example of an environment behaviour would be to regrow some good on each cell according to some rate per time-unit (inspired by SugarScape regrowing of Sugar).

The cells are represented as a 2-dimensional array with indices from (0,0) to limit and a cell of type c at every position. Note that the cell-type c is the same environment-cell type ec of the agent.

Each agent has a copy of the environment passed in through the AgentIn and can change it by passing a changed version of the environment out through AgentOut.

\subsection{Agent-Environment interaction}

\subsection{Agent Updating}
need to be updated for pro-activity. also need to run the behaviour regularly because they.
important in our approach: a single behaviour function which means we merge both pro-activity (time-depenent behaviour) and message-receiving behaviour (exception are conversations)
