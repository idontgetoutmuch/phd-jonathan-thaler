\section{Update-Strategies}
In this section we will present all the update-strategies which are available in ABM/S in a general form, discuss abstract details independent from programming languages, give philosophical meaning and interpretation of them and advices for selecting them for which model.

\begin{table}[H]
	\center
	\begin{tabular}{ c | c | c | c  }
		\textit{Name} & \textit{Time-Flow} & \textit{Iteration-Order} & \textit{Deterministic} \\
		\hhline{=|=|=|=}
	    \textbf{Seq} & Global & Sequential & Yes \\
	    \hline
	    \textbf{Par} & Global & Parallel & Yes \\
	    \hline
	    \textbf{Con} & Global & Concurrent & No \\
	    \hline
	    \textbf{Act} & Local & Actor & No \\
	\end{tabular}
	\caption{List of all general update-strategies in ABM/S.}
\end{table}

\subsection{Seq}
\textbf{Description:} This strategy has a global time-flow and in each time-step iterates through all the agents and updates one Agent after another. Messages sent and changes to the environment made by Agents are visible immediately. More formally, we assume that, given the updates are done in order of the index $i = [1..n]$, then Agents $a_{n>i}$ see the changes to environment and messages sent to them by Agent $a_i$. Note that there is no source of randomness and non-determinism thus rendering this strategy to be completely deterministic in each step. 

\textbf{Time-Updates:} The most straight-forward approach is to keep the time constant for each agent in one iteration. This though may seem non-logic as the actions of preceding Agents are visible to later ones but time has not changed since then. Thus if the model semantics require that time changes with every Agent we could advance for every agent by fraction of dt: agent-time = t + (ai * dt/n) where t is the current simulation time, ai the agents index, dt the amount of time the simulation will be advanced by and n the number of agents. In the end the new current time will be then tnext = tcurr + dt. Other possibilities of advancing is agent-time = t + ai * dt. in the end the new current time will be then tnext = tcurr + n * dt

\textbf{Extensions}: If the sequential iteration from 1..n imposes an advantage over the Agents further ahead or behind in the queue (e.g. if it is of benefit when making choices earlier than others in auctions or later when more information is available) then one could use random-walk iteration where in each time-step the agents are shuffled before iterated. Note that although this would introduce randomness in the model the source is a random-number generator thus reproduce-able.


\subsection{Par}
\textbf{Description:} This strategy has a global time-flow and in each time-step iterates through all the agents and updates all Agents in parallel. Messages sent and changes to the environment made by Agents are visible in the next global step. We can think about this strategy that all Agents make their moves at the same time. 

\textbf{Environment:} If one wants to change the environment in a way that it would be visible to other Agents this is regarded as a systematic error in this strategy. First it is not logical because all actions are meant to happen at the same time and also it would implicitly induce an ordering thus violating the \textit{happens at the same time} idea. Thus we require different semantics for accessing the environment in this strategy. We introduce thus a \textit{global} environment which is made up of the set of \textit{local} environments. Each local environment is owned by an Agent thus there are as many local environments as there are Agents. The semantics are then as follows: in each step all Agents can \textit{read} the global environment and \textit{read/write} their local environment. The changes to a local environment are only visible \textit{after} the local step and can be fed back into the global environment after the parallel processing of the Agents.

\textbf{Time-Updates:} Time really stays constant in this case for all Agents in one step as all updates happen really at the same \textit{virtual} time. It would make no sense to advance the time between Agents as all actions are meant to happen at the same time, without imposing any ordering amongst them.

\textbf{Semantics:} It does not make a difference if the Agents are really computed in parallel or just sequentially, due to the semantics of changes, this has the same effect. In this case it will make no difference how we iterate over the agents (sequentially, randomly), the outcome \textit{has to be} the same - it is event-ordering invariant as all events/updates happen \textit{virtually} at the \textit{same time}. Thus if one needs to have the semantics of writes on the whole (global) environment in ones model, then this strategy is not the right one and one should resort to one of the other strategies.

		
\subsection{Con}
\textbf{Description:} This strategy has a global time-flow and in each time-step iterates through all the agents and updates all Agents in parallel but all messages sent and changes to the environment are immediately visible. Thus this strategy can be understood as a mix of Seq and Par: all Agents run at the same time with actions becoming immediately visible.

\textbf{Semantics:} It is important to realize that, when running Agents in parallel which are able to see actions by others immediately, this is the very definition of concurrency: parallel execution with mutual read/write access to shared data. Of course this shared data-access needs to be synchronized which in turn will introduce event-orderings in the execution of the Agents. Thus at this point we have a source of inherent non-determinism: although we would ignore any hardware-model of concurrency at some point we need arbitration to decide which Agent gets access first to a shared resource thus arriving at non-deterministic solutions - this will become much clearer in the results-section. This has the very important influence that repeated runs with the same configuration of the Agents and the Model may lead to different results each time.


\subsection{Act}
\textbf{Description:} This strategy has no global time-flow but all the Agents run concurrently in parallel, with their own local time-flow. The messages and changes to the environment are visible as soon as the data arrive at the local Agents - this can be immediately when running locally on a multi-processor or with a significant delay when running in a cluster over a network. Obviously this is also a non-deterministic strategy and repeated runs with the same Agent and Model-configuration may (and will) lead to different results.

\textbf{Locality of Information:} It is of most importance to note that information and thus also time in this strategy is always local to an Agent as each Agent progresses in its own speed through the simulation. Thus in this case one needs to explicitly \textit{observe} an Agent when one wants to e.g. visualize it. This observation is then only valid for this current point in time, local to the observer but not to the Agent itself, which may have changed immediately after the observation. This implies that we need to sample our Agents with observations when wanting to visualize them, which would inherently lead to well known sampling issues. A solution would be to invert the problem and create an Observer-Agent which is known to all Agents where each Agent sends a \textit{'I have changed'} message with the necessary information to the observer if it has changed its internal state. This also does not guarantee that the observations will really reflect the actual state the Agent is in but is a remedy against the notorious sampling. 

\textbf{Semantics:} This is the most general one of all the strategies as it can emulate all the others by introducing the necessary synchronization mechanisms and Agents. Also this concept was proposed by C. Hewitt in 1973 in his work \cite{hewitt_universal_1973} where upon I. Grief in \cite{grief_semantics_1975} and W. Clinger in \cite{clinger_foundations_1981} developed semantics of different kinds. These works were very influential in the development of the Agent-Term and concept and can be regarded as foundational basics for ABM/S.