\section{Update-Strategies}
In this section we present the four general update-strategies which are possible in ABS. We give the list of all properties presented in the previous section, give a short description of the strategy and discuss their semantics and variations. We will discuss all details programming-language agnostic, give semantic meanings and interpretations of them and the implications selecting update-strategies for a model.

\subsection{Sequential Strategy}
\textbf{Iteration-Order:} Sequential \\
\textbf{Global Synchronization:} Yes \\
\textbf{Thread of Execution:} Shared \\
\textbf{Message-Handling:} Immediate or Queued \\
\textbf{Visibility of Changes:}	In-Iteration \\
\textbf{Repeatability:}	Deterministic 
	
\paragraph{Description:} This strategy has a globally synchronized time-flow and in each time-step iterates through all the agents and updates one Agent after another. Messages sent and changes to the environment made by Agents are visible immediately. 

\paragraph{Semantics:} There is no source of randomness and non-determinism thus rendering this strategy to be completely deterministic in each step. Messages can be processed either immediately or queued depending on the semantics of the model. If the model requires to process the messages immediately the model must be free of potential recursions.

\paragraph{Variation:} If the sequential iteration from Agent [1..n] imposes an advantage over the Agents further ahead or behind in the queue (e.g. if it is of benefit when making choices earlier than others in auctions or later when more information is available) then one could use random-walk iteration where in each time-step the agents are shuffled before iterated. Note that although this would introduce randomness in the model the source is a random-number generator thus still deterministic. \\
Using this strategy it is very easy to create the illusion of a local-time for each Agent by adding a random-offset to the global time for every Agent. \\
If one wants to have a very specific ordering, e.g. 'better performing' Agents first, then this can be easily implemented too by exposing some sorting-criterion and sorting the list of Agents after each Iteration.

\subsection{Parallel Strategy}
\textbf{Iteration-Order:} Parallel \\
\textbf{Global Synchronization:} Yes \\
\textbf{Thread of Execution:} Separate (or Shared) \\
\textbf{Message-Handling:} Queued \\
\textbf{Visibility of Changes:}	Post-Iteration \\
\textbf{Repeatability:}	Deterministic 

\paragraph{Description:} This strategy has a globally synchronized time-flow and in each time-step iterates through all the agents and updates all Agents in parallel. Messages sent and changes to the environment made by Agents are visible in the next global step. We can think about this strategy that all Agents make their moves at the same time. 

\paragraph{Semantics:} If one wants to change the environment in a way that it would be visible to other Agents this is regarded as a systematic error in this strategy. First it is not logical because all actions are meant to happen at the same time and also it would implicitly induce an ordering thus violating the \textit{happens at the same time} idea. Thus we require different semantics for accessing the environment in this strategy. We introduce thus a \textit{global} environment which is made up of the set of \textit{local} environments. Each local environment is owned by an Agent thus there are as many local environments as there are Agents. The semantics are then as follows: in each step all Agents can \textit{read} the global environment and \textit{read/write} their local environment. The changes to a local environment are only visible \textit{after} the local step and can be fed back into the global environment after the parallel processing of the Agents. \\
It does not make a difference if the Agents are really computed in parallel or just sequentially, due to the isolation of actions, this has the same effect. Also it will make no difference if we iterate over the agents sequentially or randomly, the outcome \textit{has to be} the same: the strategy is event-ordering invariant as all events/updates happen \textit{virtually} at the \textit{same time}. Thus if one needs to have the semantics of writes on the whole (global) environment in ones model, then this strategy is not the right one and one should resort to one of the other strategies. A workaround would be to implement the global environment as an Agent with which the non-environment Agents can communicate via messages thus we introduce an ordering but which is then sorted in a controlled order by an Agent, something which is not possible in the case of a passive, non-agent environment.

\paragraph{Variation:} Using this strategy it is very easy to create the illusion of a local-time for each agent by adding a random-offset to the global time for every Agent.

\subsection{Concurrent Strategy}
\textbf{Iteration-Order:} Parallel \\
\textbf{Global Synchronization:} Yes \\
\textbf{Thread of Execution:} Separate \\
\textbf{Message-Handling:} Queued \\
\textbf{Visibility of Changes:}	In-Iteration \\
\textbf{Repeatability:}	Non-Deterministic 

\paragraph{Description:} This strategy has a globally synchronized time-flow and in each time-step iterates through all the agents and updates all Agents in parallel but all messages sent and changes to the environment are immediately visible. Thus this strategy can be understood as a more general form of the Parallel Strategy: all Agents run at the same time but with actions becoming visible immediately.

\paragraph{Semantics:} It is important to realize that, when running Agents in parallel which are able to see actions by others immediately, this is the very definition of concurrency: parallel execution with mutual read/write access to shared data. Of course this shared data-access needs to be synchronized which in turn will introduce event-orderings in the execution of the Agents. Thus at this point we have a source of inherent non-determinism: although when one ignores any hardware-model of concurrency, at some point we need arbitration to decide which Agent gets access first to a shared resource thus arriving at non-deterministic solutions. This has the very important influence that repeated runs with the same configuration of the Agents and the Model may lead to different results.

\paragraph{Variation:} Using this strategy it is very easy to create the illusion of a local-time for each agent by adding a random-offset to the global time for every Agent.



\subsection{Actor Strategy}
\textbf{Iteration-Order:} Parallel \\
\textbf{Global Synchronization:} No \\
\textbf{Thread of Execution:} Separate \\
\textbf{Message-Handling:} Queued \\
\textbf{Visibility of Changes:}	In-Iteration \\
\textbf{Repeatability:}	Non-Deterministic 

\paragraph{Description:} This strategy has no globally synchronized time-flow but all the Agents run concurrently in parallel, with their own local time-flow. The messages and changes to the environment are visible as soon as the data arrive at the local Agents - this can be immediately when running locally on a multi-processor or with a significant delay when running in a cluster over a network. Obviously this is also a non-deterministic strategy and repeated runs with the same Agent and Model-configuration may (and will) lead to different results.

\paragraph{Semantics:} It is of most importance to note that information and thus also time in this strategy is always local to an Agent as each Agent progresses in its own speed through the simulation. Thus in this case one needs to explicitly \textit{observe} an Agent when one wants to e.g. visualize it. This observation is then only valid for this current point in time, local to the observer but not to the Agent itself, which may have changed immediately after the observation. This implies that we need to sample our Agents with observations when wanting to visualize them, which would inherently lead to well known sampling issues. A solution would be to invert the problem and create an Observer-Agent which is known to all Agents where each Agent sends a \textit{'I have changed'} message with the necessary information to the observer if it has changed its internal state. This also does not guarantee that the observations will really reflect the actual state the Agent is in but is a remedy against the notorious sampling. \\
This is the most general one of all the strategies as it can emulate all the others by introducing the necessary synchronization mechanisms and Agents. Also this concept was proposed by C. Hewitt in 1973 in his work \cite{hewitt_universal_1973} for which I. Grief in \cite{grief_semantics_1975} and W. Clinger in \cite{clinger_foundations_1981} developed semantics of different kinds. These works were very influential in the development of the concepts of Agents and and can be regarded as foundational basics for ABS.

\paragraph{Variation:} It is important to understand that this strategy is the most general one as it allows to simulate all other strategies using synchronization.