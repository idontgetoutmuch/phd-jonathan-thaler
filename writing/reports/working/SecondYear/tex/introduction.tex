\chapter{Introduction}
\label{chap:intro}
In the first half of the Ph.D. we have investigated \textit{how} to do agent-based simulation (ABS) in functional programming. This step was necessary because there didn't exist any research or implementation we could build ours on. Also it served to develop a deeper understanding of functional programming and its application to ABS.

In this process, it became apparent that there are a few unique benefits to the established object-oriented approaches which can be subsumed under the common category of \textit{increasing the correctness of the simulation}. This insight didn't come as a surprise as this is what the functional programming paradigm is known for, stated also in the hypothesis we started with: \textit{Functional programming will allow us to write ABS which is more likely to be correct}. %Note that, strictly speaking, a simulation is either correct or not but we cannot decide this generally for software unless we are willing to pour in an extreme amount of formalisms and tests, so when we say 'increasing the correctness' or 'more likely to be correct' we mean that we can guarantee less bugs and less sources of potential bugs.

We commit the next 6 months of the Ph.D. to explore this insight in a more rigorous way and push it to new levels using dependent types (see Chapter \ref{chap:dependent_types}). We hypothesise that this will allow us to write simulations which are \textit{very} likely to be correct and allow a much deeper level of formal and informal reasoning, something not possible with the established object-oriented approaches of the field yet. Because correctness is of paramount importance in scientific computing, our research is a valuable contribution to the field and can be regarded as high impact work.

\medskip

In the next section \ref{sect:argument} we develop the central argument for our research by putting the research we conducted so far into perspective with the established approach in the field. Also we introduce concepts which will outline the research for the next 6 months. Then we shortly discuss what we are \textit{not} doing (Section \ref{sect:what_not}) and give a short overview of the (intended) contributions (Section \ref{sect:contrib}) of this research. 

\medskip

In Chapter \ref{chap:stm} we present a new technique, we developed recently, which allows the scaling our approach of functional reactive ABS, as described in the paper in Appendix \ref{app:pfe}, to massively large-scale. In the following chapters we then give an in-depth introduction to the concepts used in the research of the following year, namely Verification \& Validation in Chapter \ref{chap:v_and_v} and Dependent Types in Chapter \ref{chap:dependent_types}. We also believe that although our research is conducted in the field of ABS, part of it is transferable to simulation in general and possibly other fields, closely related to ABS. We discuss this shortly in Chapter \ref{chap:generalising}. We also have updated the chapters on Aims \& Objectives \ref{chap:aimsObj}, Work to Date \ref{chap:work_to_date} and Future Work Plan \ref{chap:future}.

\section{The functional argument}
\label{sect:argument}
The established approach to implement ABS falls into three categories:
\begin{enumerate}
	\item Programming from scratch using object-oriented languages where Java and Python are the most popular ones.
	\item Programming using a 3rd party ABS library using object-oriented languages where RePast and DesmoJ, both in Java, are the most popular one.
	\item Using a high-level ABS tool-kit for non-programmers, which allow customization through programming if necessary. By far the most popular one is NetLogo with an imperative programming approach followed by AnyLogic with an object-oriented Java approach.
\end{enumerate}

In general one can say that these approaches, especially the 3rd one, support fast prototyping of simulations which allow quick iteration times to explore the dynamics of a model. Unfortunately, all of them suffer the same problems when it comes to verifying and guaranteeing the correctness of the simulation.

The established way to test software in established object-oriented approaches is writing unit-tests which cover all possible cases. This is possible in approach 1 and 2 but very hard or even impossible when using an ABS tool-kit, as in 3, which is why this approach basically employs manual testing. In general writing those tests or conducting manual tests is necessary because one cannot guarantee the correct working at compile-time which means testing ultimately tests the correct behaviour of code at run-time. The reason why this is not possible is due to the very different type-systems and paradigm of those approaches. Java has a strong but very dynamic type-system whereas Python is completely dynamic not requiring the programmer to put types on data or variables at all. This means that due to type-errors and data-dependencies run-time errors can occur which origins might be difficult to track down.

It is no coincidence that JavaScript, the most widely used language for programming client-side web-applications, originally a completely dynamically typed language like Python, got additions for type-checking developed by the industry through TypeScript. This is an indicator that the industry acknowledges types as something important as they allow to rule out certain classes of bugs at run-time and express guarantees already at compile-time. We expect similar things to happen with Python as it is popularity is surging and more and more people become aware of that problem. Summarizing, due to the highly dynamic nature of the type-system and imperative nature, run-time errors and bugs are possible both in Python and Java which absence must be guaranteed by exhaustive testing. 

This is supported by a talk \cite{sweeney_next_2006}, in which Tim Sweeney, CEO of Epic Games, discusses the use of main-stream imperative object-oriented programming languages (C++) in the context of Game Programming. Although the fields of games and ABS seem to be very different, in the end they have also very important similarities: both are simulations which perform numerical computations and update objects in a loop either concurrently or sequential \cite{gregory_game_2018}. Sweeney reports that reliability suffers from dynamic failure in such languages e.g. random memory overwrites, memory leaks, accessing arrays out-of-bounds, dereferencing null pointers, integer overflow, accessing uninitialized variables. He reports that 50\% of all bugs in the Game Engine Middleware Unreal can be traced back to such problems and presents dependent types as a potential rescue to those problems. Further he also mentions the necessity to parallelise computations and run game code concurrently, for which he proposed a functional approach.

The problem of correctness in agent-based simulations became more apparent in the work of Ionescu et al \cite{ionescu_dependently-typed_2012} which tried to replicate the work of Gintis \cite{gintis_emergence_2006}. In his work Gintis claimed to have found a mechanism in bilateral decentralized exchange which resulted in walrasian general equilibrium without the neo-classical approach of a tatonement process through a central auctioneer. This was a major break-through for economics as the theory of walrasian general equilibrium is non-constructive as it only postulates the properties of the equilibrium \cite{colell_microeconomic_1995} but does not explain the process and dynamics through which this equilibrium can be reached or constructed - Gintis seemed to have found just this process. Ionescu et al. \cite{ionescu_dependently-typed_2012} failed and were only able to solve the problem by directly contacting Gintis which provided the code - the definitive formal reference. It was found that there was a bug in the code which led to the "revolutionary" results which were seriously damaged through this error. They also reported ambiguity between the informal model description in Gintis paper and the actual implementation.

\subsection{Functional programming to the rescue}
We argue that due to its fundamental different nature, the functional programming paradigm can overcome some fundamental problems of the established object-oriented approach to ABS. Note that we don't claim that it will solve all the problems and that the Gintis failure wouldn't have happened but we argue that it makes making mistakes much harder, resulting in simulations which are more likely to be correct.

We have investigated the concepts of \textbf{\textit{how}} to do agent-based simulation using the functional programming paradigm, as in the language Haskell, which is described in the paper in Appendix \ref{app:pfe}. The approach we developed is based on Functional Reactive Programming which allows to express discrete- and continuous-time systems in functional programming. Following the conclusions of the paper, we got the following benefits, supporting directly our initial hypothesis and our claims above, giving good reasons \textbf{\textit{why}} to do ABS in a functional way:

\begin{enumerate}
	\item Run-Time robustness by compile-time guarantees - by expressing stronger guarantees already at compile-time we can restrict the classes of bugs which occur at run-time by a substantial amount due to Haskell's strong and static type system.  This implies the lack of dynamic types and dynamic casts \footnote{Note that there exist casts between different numerical types but they are all safe and can never lead to errors at run-time.} which removes a substantial source of bugs.  Note that we can still have run-time bugs in Haskell when our functions are partial.
	\item Purity - By being explicit and polymorphic in the types about side-effects and the ability to handle side-effects explicitly in a controlled way allows to rule out non-deterministic side-effects which guarantees reproducibility due to guaranteed same initial conditions and deterministic computation. Also by being explicit about side-effects e.g. Random-Numbers and State makes it easier to verify and test.
	\item Explicit Data-Flow and Immutable Data - All data must be explicitly passed to functions thus we can rule out implicit data-dependencies because we are excluding IO. This makes reasoning of data-dependencies and data-flow much easier as compared to traditional object-oriented approaches which utilize pointers or references.
	\item Declarative - describing \textit{what} a system is, instead of \textit{how} (imperative) it works. In this way it is should be easier to reason about a system and its (expected) behaviour because it is more natural to reason about the behaviour of a system instead of thinking of abstract operational details.
	\item Concurrency and parallelism - due to its pure and 'stateless' nature, functional programming is extremely well suited for massively large-scale applications as it allows adding parallelism without any side-effects and provides very powerful and convenient facilities for concurrent programming. We have explored this more in-depth in Chapter \ref{chap:stm}.
\end{enumerate}

%\paragraph{Drawbacks} Following the conclusions of the paper, we also found drawbacks.

%The most fundamental one is that agent-agent and agent-environment interactions work very different because method calls and mutable data are not available. We had to invent new techniques for these kind of interactions which makes functional agent-based simulation conceptually more difficult to understand and implement models with. Despite these difficulties, it also makes those interactions more expressive and explicit and separates them into different categories which are conceptually different but are almost always implemented the same way in object-oriented approaches.

%Another drawback is performance. So far, performance is not comparable to object-oriented approaches, but that was not the main focus of the research. Also pure functional programming as in Haskell, can exploit parallelism nearly for free due to its explicit data-flow, lack of side-effects and immutable data. This should make speeding up of simulations very easy, and if it is just running multiple replications in parallel. We leave this for further research as investigating this is worth a Ph.D. on its own.

\subsection{Towards Correct-By-Construction}
In general, Types guide us in program construction by restricting the operations we can perform on the data. This means that by choosing types this reveals already a lot of our program and data and prevents us from making mistakes e.g. interpreting some binary data as text instead of a number. In strongly statically typed languages the types can do this already at compile-time which allows to rule out certain bugs already at compile-time. In general, we can say that for all bugs which can be ruled out at compile-time, we don't need to write property- or unit-tests, because those bugs cannot - per definition - occur at run-time, so it won't make sense to test their absence at run-time. Also, as Dijkstra famously put it: "Testing shows the presence, not the absence of bugs" - thus by induction we can say that compile-time guarantees save us from a potentially infinite amount of testing.

In general it is well established, that pure functional programming as in Haskell, allows to express much stronger guarantees about the correctness of a program \textit{already at compile-time}. This is in fundamental contrast to imperative object-oriented languages like Java or Python where only primitive guarantees about types - mostly relationships between type-hierarchies - can be expressed at compile-time which directly implies that one needs to perform much more testing (user testing or unit-testing) at \textit{run-time} to check whether the model is sufficiently correct. Thus guaranteeing properties already at compile-time frees us from writing unit-tests which cover these cases or test them at run time because they are \textit{guaranteed to be correct under all circumstances, for all inputs}. In this regards we see pure functional programming as truly superior to the traditional object oriented approaches: they lead to implementations of models which are more likely correct because we can express more guarantees already at compile-time which directly leads to less bugs which directly increases the probability of the software being a correct implementation of the model. Having established this was only the first step in our paper in Appendix \ref{app:pfe}. 

TODO: explain dependent types non-technical, so far only a person who understands dependent types knows what I am speaking of
Although pure functional ABS as in Haskell allows us to leverage on the concepts of functional and its benefits (and drawbacks) we still rely heavily on (property-based) testing to ensure correctness of a simulation because our approach still can have run-time bugs. Thus, the next step, which follows directly, is towards even stronger guarantees at compile-time, by using dependent types. Generally speaking, dependent types allow to push compile-time guarantees to a new level where we can express nearly arbitrary complex guarantees at compile-time because we can \textit{compute types at compile-time}. This means that types are first-class citizen of the language and go as far as being formal proofs of the correctness of an implementation, allowing to narrow the gap between specification and implementation substantially. We hypothesise that the use of dependent types allows us to push the judgement of the correctness of a simulation to new, unprecedented level, not possible with the established object-oriented approaches so far. This has the direct consequence that the development process is very different and can reduce the amount of testing (both unit-testing and manual testing) substantially. Because one is implementing a simulation which is (as much as possible) correct-by-construction, the correctness (of parts) can be guaranteed statically.

 %"Will gladly sacrifice 10\% of our performance for 10\% higher productivity"

Summarizing, we expect the following benefits from adding dependent types to ABS:

\begin{enumerate}
	\item Narrowing the gap between the model specification and its implementation reduces the potential for conceptual errors in model-to-code translation.
	\item Less number of tests required due to guarantees being expressed already at compile time.
	\item Higher confidence in correctness due to formal guarantees in code.
\end{enumerate}

\section{What Not}
\label{sect:what_not}
Because our research focuses on new implementation techniques and paradigms in agent-based simulation, there is always the question of "Why would you do that, what is wrong with the established way?". This means new techniques and paradigms always have to justify themselves in terms of benefits and drawbacks and our research is no exception to that. The way we approach this is not on a low technical level but on very broad conceptual levels which have been already established for object-oriented and functional programming paradigms in general. Thus we will \textit{not} compare object-oriented to functional implementations of a same model and go into lengthy debates over Lines Of Code, maintainability, extensibility, readability,... because many of those properties are highly subjective and depend very much on experience. In short: we want to avoid discussions over "which programming language is better" under all circumstances because they lead nowhere (just take a look in any technical forum / Reddit / Youtube and you will see the emotions going high like in religious debates). This also means that we are \textit{not} comparing the general approach of pure functional programming in the instance of Haskell and object-oriented programming in the instance of Java and Python to implement ABS.

We claim from experience, that one has to pick the \textit{right} programming language for the \textit{right} task e.g. for web-development one would probably never pick Assembly and for embedded systems programming probably not Haskell. The reason for that is, that in web-development we prefer the higher abstraction which Assembly wouldn't provide because it is extremely close to hardware. This property in turn would be required in embedded systems programming which in turn Haskell is lacking. So when we pick a language we need to know its strengths which directly influences how we solve the problems at hand, thus it might make sense programming a web-application in Assembly if we need speed under all circumstances or use Haskell for implementing embedded programs when we need stronger guarantees about correctness.

Thus our research is to find out what the \textit{right} task for functional programming and dependent types is in agent-based simulation - we believe it is correctness. So despite challenging the metaphor that \textit{agents map naturally to objects}, we still think object-oriented programming is great for implementing ABS because we think it is the \textit{easiest} way to go for teaching and low-impact models, not used in far reaching policy decisions because for those, correctness is not the primary objective.

\section{Contributions}
\label{sect:contrib}
Although I am just half-way through the Ph.D. I anticipate and project the contributions of it:

\begin{enumerate}
	\item This research is the first to \textit{systematically} investigate the application of the functional programming paradigm, as in Haskell, to Agent-Based Simulation, identifying its benefits and drawbacks.
	\item This research is the first to apply \textit{dependent types} to Agent-Based Simulation to investigate its usefulness for increasing the correctness of a simulation.
	\item The developed methods allow to implement Agent-Based Simulation which are guaranteed to be reproducible, have less sources of bugs, are easier to verify and thus more likely to be correct which is of paramount importance in high-impact scientific computing. 
	\item By showing how to employ STM we arrive at a solution which allows massively large-scale ABS but without the low level difficulties of concurrent programming, making it easier and quicker to develop working and correct concurrent ABS models.
\end{enumerate}