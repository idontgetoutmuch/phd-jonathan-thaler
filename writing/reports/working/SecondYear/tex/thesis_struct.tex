\chapter{Thesis Structure}
\label{app:thesis_struct}

This chapter tries to develop a first draft of the structure outline and the main argument of the thesis which i plan on start writing in April 2019.

line of argument
1. established methods need extensive unit-testing for establishing correctness of software, which only increases the likelihood of correctness and doesnt guarantee it because they are inherent dynamic, testing run-time behaviour, because of the different type system.
2. functional programming as in haskell has a strong static type system which allows to shift much much more guarantees towards static, compile-time, making many run-time tests obsolete and can guarantee a few things already at compile-time which makes tests to cover that completely obsolete
3. dependent types can push these guarantees even further and theoretically should allow to express guarantees at compile-time to an arbitrary complex level which in theory should allow us to abandon run-time testing of bugs altogether. This does not mean that we don't need any tests anymore, as will be outlined in the chapter on Verification \& Validation \ref{chap:v_and_v}.
4. with shifting more towards compile-time guarantees we automatically gain more confidence into the correctness of our simulation and reduce the implementation overhead of writing tests for those cases. Also some properties are simply not testable with run-time tests e.g. that some property holds forever - this is only possible to guarantee by looking at the code directly (where functional programming shines) or expressing it through compile-time guarantees. 
5. correct by construction: narrowing the gap between model specification and implementation 
6. Impedance Mismatch: ABS is constructive / generative in nature but the nature of the test-driven development process is deductive. is this a problem? Think of it more deeply

\section{Introduction}
defining the scope
contributions

\section{Part I: General Concepts}
- abs defined
- define established ABS implementation techniques: object-oriented \& test-driven

- event vs time-driven
Independent of the programming paradigm, there exist fundamentally two approaches implementing agent-based simulation: time- and event-driven. In the time-driven approach, the simulation is stepped in fixed $\Delta t$ and all agents are executed at each time-step - they act virtually in lock-step at the same time. The approach is inspired by the theory of continuous system dynamics (TODO: cite).
In the event-driven approach, the system is advanced through events, generated by the agents, and the global system state changes by jumping from event to event, where the state is held constant in between. The approach is inspired by discrete event simulation (DES) (TODO: citation) which is formalized in the DEVS formalism \cite{zeigler_theory_2000}.


\section{Part II: Pure functional ABS}
effects and purity defined
short overview of impure functional programming in IO like avika: in the end the same as imperative programming, not what we want here
artiterating paper,

concepts of time- and event-driven approach in haskell (see robinson book and pidd book)

pure functional epidemics paper
additional research on event-driven approach in haskell: unscheduling events in functional style easy: rollback to previous state is easy but memory costly. look into that in the thesis. clarify easy rolling back of system: can capture the whole state at a given point which allows reverting the system to a state in case of cancelling of an event
applicability of UML and peers Framework to pure functional ABS 
add section on recursive ABS
parallelise using cloud haskell?

agent-interactions
this is the central problem of the FP approach: basically the agent-interactions define the level of abstractions over the agents. unfortunately we have to say that this is easier and more elegant in OOP. Still by using a strong type system we can have advantages which the OOP doesnt have.
1) data-flow: for continuous ABS systems where data takes 1 dt to appear at the target agent and does not persist e.g. the target agent can check it or not but the data received in the current step will be gone in the next. Use-case: implementing continuous time-dependent ABS e.g. SIR model
2) events: an agent can send to an arbitrary other agent an event which happens at a given time in the future: when the event happens this means the target agent is executed with the information about the receiving event. Use-Case: implementing discrete event simulation ABS e.g. a bank, very useful when the model is specified in terms of events and not in a continuous fashion
3) transactions: method-call emulation, which takes no time at all and can involve an arbitrary but finite number of steps between agents. Use-case: trading between agents where they must to come to terms within the same time-step but where the negotiation process takes multiple steps between the agents. exist in both event-driven and time-driven

Verification:
have written about it already in the report on SIR verification: incorporate QuickCheck. need to do a lot more work there. maybe can get it done in context of the 4th paper (towards pure functional ABS)

\section{Part III: Dependent types in ABS}
3rd paper

Test-Driven (deductive) vs. Type-Driven (constructive) approach: in established oo (and to an extent, pure functional ABS because cannot make as strong guarantees) the approach is test-driven, in dependent types it is type-driven

\section{Part IV: Philosophical Aspects}
ABS as a constructive / generative science, follows poperian approach of falsification: we try to construct a model which explains a real-world (empirical) phenomenon - if validation shows that the generated dynamics match the ones of the real-world sufficiently enough, we say that we have found \textit{a} hypothesis (the model) which emergent properties explains the real-world phenomenon sufficiently enough. This is not a proof but only one possible explanation which holds for now and might be falsified in the future.

Note that we must speak of falsification and constructiveness on two different levels:
- validation level: do the results of the conceptual model match the real-world phenomenon? the conceptual model is the hypothesis which says that its mechanics are sufficient to generate / construct the real-world phenomenon. At this level we are not interested in the implementation level anymore - the implemented model \textit{is} (seen as) the conceptual model, and one only compares its output to the real-world. If the dynamics match, then we got a valid hypothesis which works for now. If the dynamics do NOT match, then the hypothesis (the model) is falsified and one needs to adjust / change the hypothesis (model). The validation will happen by tests, there is no other way, we have no formal specification of the real-world, we can only observe empirically the phenomena, so we run tests which try to falsify the outputs of the model: assuming it will generate phenomena of the real-world and test if it does.
- implementation \& verficiation level: in this step we are matching the code to the conceptual model. Here we are not only restricted to a test-driven approach because we have a more or less formal description of the conceptual model which we directly encode in our programming language. If the language allows to express model specifications already at compile-time then this means that the implementation narrows the gap between model specification and implementation which means it does not need to be tested at run-time because it is guaranteed for all inputs for all time. 


The constructiveness of ABS and impendance mismatch: ABS methodology is constructive but the established implementation approach not too much, creating an impedance mismatch. this is especially visible in the test-driven development dependent types constructive nature could close this mismatch.

\section{Conclusions}