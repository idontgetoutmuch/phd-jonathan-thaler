\subsection{Pure Functional Programming}
In his 1977 ACM Turing Award Lecture, John Backus \footnote{One of the giants of Computer Science, a main contributor to Fortran - an imperative programming language.} fundamentally critizied imperative programming for its deep flaws and proposed a functional style of programming to overcome the limitations of imperative programming \cite{backus_can_1978}. The main criticism is its use of \textit{state-transition with complex states} and the inherent semantics of state-manipulation. In the end an imperative program consists of a number of assign-statements resulting in side-effects on global mutable state which makes reasoning about programs nearly impossible. Backus proposes the so called \textit{applicative} computing, which he termes \textit{functional programming} which has its foundations in the Lambda Calculus \cite{church_calculi_1941}. The main idea behind it is that programming follows a declarative rather than an imperative style of programming: instead of describing \textit{how} something is computed, one describes \textit{what} is computed. This concept abandons variables, side-effects and (global) mutable state and resorts to the simple core of function application, variable substitution and binding of the Lambda Calculus. Although possible and an important step to understand the very foundations, one does not do functional programming in the Lambda Calculus \cite{michaelson_introduction_2011}, as one does not do imperative programming in a Turing Machine.
In our thesis we selected Haskell as our functional programming language. \footnote{Although we did a bit of research using Scala (a mixed paradigm functional language) in ABS (see Appendix \ref{app:frABS}), we deliberately ignored other functional languages as it is completely out-of-scope of this thesis to do an in-depth comparison of functional languages for their suitability to implement ABS.}. The paper of \cite{hudak_history_2007} gives a comprehensive overview over the history of the language, how it developed and its features and is very interesting to read and get accustomed to the background of the language. A widely used introduction to programming in Haskell is \cite{hutton_programming_2016}. The main points why we decided to go for Haskell are

\begin{itemize}
	\item Pure, Lazy Evaluation, Higher-Order Functions and Static Typing - these are the most important points for the decision as they form the very foundation for composition, correctness, reasoning and verification. 
	\item Real-World applications - the strength of Haskell has been proven through a vast amount of highly diverse real-world applications \footnote{\url{https://wiki.haskell.org/Applications_and_libraries}} \cite{hudak_history_2007} and is applicable to a number of real-world problems \cite{osullivan_real_2008}.
	\item Modern - Haskell is constantly evolving through its community and adapting to keep up with the fast changing field of computer science e.g. parallelism \& concurrency.
	\item In-house knowledge - the School of Computer Science of the University of Nottingham has a large amount of in-house knowledge in Haskell which can be put to use and leveraged in my thesis.
\end{itemize}

It seems that we are on the right track with pure functional programming in answering the questions in the motivation as it promises to solve all the issues raised in these questions. We will now investigate whether this is really the case by looking into relevant literature.

The main conclusion of the classical paper \cite{hughes_why_1989} is that \textit{modularity} is the key to successful programming and can be achieved best using higher-order functions and lazy evaluation provided in functional languages like Haskell. The author argues that the ability to divide problems into sub-problems depends on the ability to glue the sub-problems together which depends strongly on the programming-language. He shows that laziness and higher-order functions are in combination a highly powerful glue and identifies this as the reason why functional languages are superior to structure programming. Another property of lazy evaluation is that it allows to describe infinite data-structures, which are computed as currently needed. This makes functions possible which produce an infinite stream which is consumed by another function - the decision of \textit{how many} is decoupled from \textit{how to}.

In the paper \cite{wadler_essence_1992} Wadler describes Monads as the essence of functional programming (in Haskell). Originally inspired by monads from category-theory (see below) through the paper of Moggi \cite{moggi_computational_1989}, Wadler realized that monads can be used to structure functional programs \cite{wadler_comprehending_1990}. A pure functional language like Haskell needs some way to perform impure (side-effects) computations otherwise it has no relevance for solving real-world problems like GUI-programming, graphics, concurrency,... . This is where monads come in, because ultimately they can be seen as a way to make effectful computations explicit \footnote{This is seen as one of the main impacts of Haskell had on the mainstream programming \cite{hudak_history_2007}}. 
In \cite{wadler_essence_1992} Wadler shows how to factor out the error handling in a parser into monads which prevents code to be cluttered by cross-cutting concerns not relevant to the original problem. Other examples Wadler gives are the propagating of mutable state, (debugging) text-output during execution, non-deterministic choice. Further applications of monads are given in \cite{wadler_essence_1992}, \cite{wadler_monads_1995}, \cite{wadler_how_1997} where they are used for array updating, interpreting of a language formed by expressions in algebraic data-types, filters, parsers, exceptions, IO, emulating an imperative-style of programming. This seems to be exactly the way to go, tackling the problems mentioned in the introduction: making data-flow explicit, allowing to factor out cross-cutting concerns and encapsulate side-effects in types thus making them explicit.
It may seem that one runs into efficiency-problems in a pure functional programming language when using algorithms which are implemented in imperative languages through mutable data which allows in-place update of memory. The seminal work of \cite{okasaki_purely_1999} showed that when approaching this problem from a functional mind-set this does not necessarily be the case. The author presents functional data structures which are asymptotically as efficient as the best imperative implementations and discusses the estimation of the complexity of lazy programs.

The concept of monads was further generalized by Hughes in the concept of arrows \cite{hughes_generalising_2000}. The main difference between Monads and Arrows are that where monadic computations are parameterized only over their output-type, Arrows computations are parametrised both over their input- and output-type thus making Arrows more general. In \cite{hughes_programming_2005} Hughes gives an example for the usage for Arrows in the field of circuit simulation. Streams are used to advance the simulation in discrete steps to calculate values of circuits thus the implementation is a form of \textit{discrete event simulation} - which is in the direction we are heading already with ABS. As will be shown below, the concept of arrows is essential for Functional Reactive Programming a potential way to do ABS in pure functional programming.

One of the most compelling example to utilize pure functional programming is the reporting of \cite{hudak_haskell_1994} where in a prototyping contest of DARPA the Haskell prototype was by far the shortest with 85 lines of code (LoC) as compared to the C++ solution with 1105 LoC. The remarkable thing is that the Jury mistook the Haskell code as specification because its approach was to implement a small embedded domain specific language (EDSL) to solve the problem - this is a perfect proof how close an EDSL can get to a specification. When implementing an EDSL one develops and programs primitives e.g. types and functions in a host language (embed) in a way that they can be combined. The combination of these primitives then looks like a language specific to a given domain. The ease of development of EDSLs in pure functional programming is also a proof of the superior extensibility and composability of pure functional languages over object-orientation and is definitely one of its major strength. The classic paper \cite{henderson_functional_1982} gives a wonderful way of constructing an EDSL to denotationally construct a picture reminiscent of the works of Escher.
A major strength of developing an EDSL is that one can reason about and do formal verification. A nice introduction how to do reasoning in Haskell is given in \cite{hutton_tutorial_1999}.
The testing-library QuickCheck \cite{claessen_quickcheck:_2000}, \cite{claessen_testing_2002} defines an EDSL which allows to formulate a specification in the QuickCheck- EDSL and domain-EDSL and test the code against this specification - testing code happens by writing formal specifications which is the very heart of verification. 
It seems that in EDSL we have found a way to tackle the problem of verification and close the gap between specification and implementation at least conceptually - whether this is really possible will be subject of the research conducted in the thesis.

\subsubsection{Pure Functional Programming in ABS}
The amount of research on using the pure functional paradigm using Haskell in the field of ABS has been moderate so far. Most of the papers look into how agents can be specified using the belief-desire-intention paradigm \cite{de_jong_suitability_2014}, \cite{sulzmann_specifying_2007}, \cite{jankovic_functional_2007}. A library for Discrete Event Simulation (DES) and System Dynamics (SD) in Haskell called \textit{Aivika 3} is described in \cite{sorokin_aivika_2015}. It comes with very basic features for ABS but only allows to specify simple state-based agents with timed transitions.
\cite{jankovic_functional_2007} which discuss using functional programming for DES mention the paradigm of functional reactive programming (FRP) to be very suitable to DES. \cite{schneider_towards_2012} and \cite{vendrov_frabjous:_2014} present a domain-specific language for developing functional reactive agent-based simulations. This language called FRABJOUS is human readable and easily understandable by domain-experts. It is not directly implemented in FRP/Haskell but is compiled to Yampa code - a FRP library for Haskell - which they claim is also readable. It seems that FRP is a promising approach to ABS in Haskell, an important hint we will follow in the section below.

Tim Sweeney, CTO of Epic Games gave an invited talk in which he talked about programming languages in the development of game-engines and scripting of game-logic \cite{sweeney_next_2006}. Although the fields of games and ABS seem to be very different, in the end they have also very important similarities: both are simulations which perform numerical computations and update objects in a loop either concurrently or sequential \footnote{Gregory \cite{gregory_game_2018} defines computer-games as \textit{soft real-time interactive agent-based computer simulations}}. In games these objects are called \textit{game-objects} and in ABS they are called \textit{agents} but they are conceptually the same thing. The two main points Sweeney made were that dependent types could solve most of the run-time failures and that parallelism is the future for performance improvement in games. He distinguishes between pure functional algorithms which can be parallelized easily in a pure functional language and updating game-objects concurrently using software transactional memory (STM).

The thesis of \cite{bezirgiannis_improving_2013} constructs two frameworks: an agent-modelling framework and a DES framework, both written in Haskell. They put special emphasis on parallel and concurrency in their work. The author develops two programs with strong emphasis on parallelism: HLogo which is a clone of the NetLogo agent-modelling framework and HDES, a framework for discrete event simulation.

Although probably the most important selling point of a pure functional language is its ease of parallelizing code due to lack of side-effects \cite{peyton_jones_concurrent_1996}, \cite{osullivan_real_2008}, \cite{jones_tutorial_2009}, \cite{marlow_parallel_2013} we don't go into this direction in our thesis and consider this just to be a by-product which luckily just falls out of the language itself \footnote{We did some research of implementing concurrent agents with STM as proposed by \cite{sweeney_next_2006} and \cite{bezirgiannis_improving_2013} in our research on programming paradigms as can be seen in Appendix \ref{app:paradigms}. We think that STM is probably the single major feature which is \textit{only} possible in a pure functional language because only in a pure functional language with explicit side-effects it is possible to \textit{compose} concurrency.}.

%TODO: this seems all to be focused on MAS
%\url{http://haskell-distributed.github.io/wiki.html} looks good but too big and not well suited for simulations
%\url{https://code.google.com/archive/p/haskellactor/} makes heavy use of IORef and running in IO-Monad, something we deliberately want to avoid to keep the ability to reason about the program.
%TODO: \url{https://github.com/fizruk/free-agent} look into

\subsubsection{Functional Reactive Programming}
So far we have considered only quite low-level approaches to structuring and composing functional programming: higher-order functions, laziness, monads and arrows. What we need is a programming paradigm built into pure functional programming which we can leverage to implement ABS. As already mentioned above, functional reactive programming (FRP) seems to be a highly promising approach. It is rather a lucky coincidence that Henrik Nilsson, one of the major contributor to the library Yampa, an implementation of FRP, is situated at the School of Computer Science of the University of Nottingham.

FRP is a paradigm for programming hybrid systems which combine continuous and discrete components. Time is explicitly modelled: there is a continuous and synchronous time flow. There have been many attempts to implement FRP in libraries which each has its benefits and deficits. The very first functional reactive language was Fran, a domain specific language for graphics and animation. At Yale FAL, Frob, Fvision and Fruit were developed. The ideas of them all have then culminated in Yampa, the most recent FRP library \cite{nilsson_functional_2002}. The essence of FRP with Yampa is that one describes the system in terms of signal functions in a declarative manner using the EDSL of Yampa. During execution the top level signal functions will then be evaluated and return new signal functions which act as continuations. A major design goal for FRP is to free the programmer from 'presentation' details by providing the ability to think in terms of 'modeling'. It is common that an FRP program is concise enough to also serve as a specification for the problem it solves \cite{wan_functional_2000}.

Yampa has been used in multiple agent-based applications: \cite{hudak_arrows_2003} uses Yampa for implementing a robot-simulation, \cite{courtney_yampa_2003} implement the classical Space Invaders game using Yampa, \cite{nilsson_declarative_2014} implements a Pong-clone, the thesis of \cite{meisinger_game-engine-architektur_2010} shows how Yampa can be used for implementing a Game-Engine, \cite{mun_hon_functional_2005} implemented a 3D first-person shooter game with the style of Quake 3 in Yampa. Note that although all these applications don't focus explicitly on agents all of them inherently deal with kinds of agents which share properties of classical agents: game-entities, robots,... Other fields in which Yampa was successfully used were programming of synthesizers, network routers, computer music development and has been successfully combined with monads \cite{perez_functional_2016}.

This leads to the conclusion that Yampa is mature, stable and suitable to be used in functional ABS. This and the reason that we have the in-house knowledge lets us focus on Yampa. Also it is out-of-scope to do a in-depth comparison of the many existing FRP libraries.

\subsubsection{Dependent Types}
As already pointed out by Sweeney in \cite{sweeney_next_2006}, dependent types could remove an important class of run-time errors which in the end means that using them allows to push correctness even further because type-invariants are statically checked at compile time. As correctness and verification is our major concern, dependent types seem to be attractive. The papers of \cite{norell_dependently_2009}, \cite{bove_brief_2009} and \cite{bove_dependent_2009} give a good introduction of what dependent types are and how to program with them in Agda, a dependently typed pure functional programming language, closely related to Haskell. For now this approach seems to be too early to follow as we haven't yet laid the basic groundwork: an non-dependently typed pure functional implementation of ABS in Haskell.
%The delicate point is, that programming in Agda becomes a proof-assistant: a proof is then a constructed programm. The work of \cite{ionescu_dependently-typed_2012} which was mentioned in the introduction uses dependent types for proving fundamental theorems in economics. 

%ADOM: Agent Domain of Monads: https://www.haskell.org/communities/11-2006/html/report.html

\subsubsection{A word on LISP}
Being the oldest functional programming language and the 2nd oldest high-level programming language ever created, at one point we considered using LISP in our research due to its immensely powerful feature of homoiconicity. The idea was to investigate if this could be made useful for ABS and bring it to a new level. We abandoned this quickly as it would have led to a total different approach. Besides, it would have definitely not solved the issues the questions raised in the introduction because of its imperative nature. Still there exists a paper \cite{kawabe_nepi2programming_2000} which implements a MAS in LISP.