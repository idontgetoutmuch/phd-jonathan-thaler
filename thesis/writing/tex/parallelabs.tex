\chapter*{Parallel ABS}
\label{ch:parallel_abs}
Functional programming as in Haskell is well known and accepted as a remedy against the problems of imperative programming in implementing parallel software TODO: cite ?. The reason for it is clear: immutable data and explicit control of side-effects removes a large class of bugs due to data-conflicts, data-races, and blablabla TODO: we are claiming things here, which we need to clearly back up, also data-races ARE possible in Haskell! A fundamental benefit and strength of Haskell is, that it clearly distinguishes between parallelism and concurrency \cite{jones_tackling_2002} and it is very important for us to do so as well:

\begin{itemize}
	\item \textbf{Parallelism} - In parallelism, code runs in parallel without interfering with other code through shared data (references, mutexes, semaphores,...). An example is the function \textit{map :: (a $\rightarrow$ b) $\rightarrow$ [a] $\rightarrow$ [b]}, which maps each element of type \textit{a} to \textit{b} using the function \textit{(a $\rightarrow$ b)}. It is a pure function and thus no sharing of data either through some monadic context or through the function \textit{(a $\rightarrow$ b)} is possible. This allows to run it in parallel: each function evaluation \textit{(a $\rightarrow$ b)} could potentially be executed at the same time, if we had enough CPU cures. Whether it runs actually in parallel or not, has no influence on the outcome, it is not subject to any non-deterministic influences. Thus we identify parallelism with pure and deterministic execution of data-transformations (data-parallelism).
	
	\item \textbf{Concurrency} - In concurrency, code runs in parallel but can potentially interfere with other code through shared data (references, mutexes, semaphores, ...). An example are two threads, running in parallel, which share data through \textit{IORefs}. In concurrency there is no option: code has to run in parallel through the use of threads but now the outcome of the program very much depends on the ordering in which the threads are scheduled. This gives rise to very different access patterns to the shared data, with the potential for race conditions, dirty reads and so on... Ordering suddenly becomes important and the challenge of implementing concurrent programs, is to write the program in a way that despite of these non-deterministic influences it is still a correctly working program. Thus we identify concurrency with impure and non-deterministic execution of imperative-style (ordered) monadic command execution.
\end{itemize}

In this chapter we investigate the application of both parallelism and concurrency to our pure functional ABS approach. In general, we want to test if the benefits of parallel and concurrent programming in Haskell are transferable to pure functional ABS. In particular we are interested in speeding up the existing implementations by aiming at \textit{running agents in parallel}. Note that we use the term \textit{parallel} to identify both \textit{parallelism} and \textit{concurrency} and we distinguish between them whenever necessary with their respective terms.

A warning about the costs of parallelism and concurrency: mindlessly trying to apply any can actually result in loss of performance as a problem can only be sped up in so far as we can partition it and running it in parallel might be more costly than running it in parallel. Although we give a few use-cases, we do \textit{not} provide a \textit{general} solution on how to partition ABS implementations for parallel execution - although running every agent concurrently is a good direction, in general this always depends on the model and on the implementation. As D. Knuth famously put it: \textit{"Premature optimisation is the root of all evil"}, thus, when we see adding parallelism as one way of optimising a problem, we need hard facts instead of wild guesses. Thus, performance measurements have to come first, then one can investigate where and why the performance is lost. Only if this is properly understood one can decide whether parallelism or concurrency is applicable - or none at all because the problem is actually completely sequential.

\input{./tex/parallelabs/parallelism.tex}

\input{./tex/parallelabs/concurrent.tex}

\input{./tex/parallelabs/discussion.tex}