\section{Case study I: \\ Testing the SIR model specification}
\label{sec:case_SIR}
As first use-case we discuss property-based testing for the \textit{explanatory} agent-based SIR model as introduced in Chapter \ref{sec:sir_model}. We aim at connecting the agent-based implementation to the SD specification, by formalising it into properties within a property-test. The SD specification can be given through the differential equations shown in Chapter \ref{sec:sir_model}, which we repeat here:

\begin{equation}
\begin{split}
\frac{\mathrm d S}{\mathrm d t} = -infectionRate \\
\frac{\mathrm d I}{\mathrm d t} = infectionRate - recoveryRate \\
\frac{\mathrm d R}{\mathrm d t} = recoveryRate 
\end{split}
\quad
\begin{split}
infectionRate = \frac{I \beta S \gamma}{N} \\
recoveryRate = \frac{I}{\delta} 
\end{split}
\end{equation}
\label{eq:sir_delta_rates}

Solving these equations is done by integrating over time. In the SD terminology, the integrals are called \textit{Stocks} and the values over which is integrated over time are called \textit{Flows}. At $t = 0$ a single agent is infected because if there wouldn't be any infected agents, the system would immediately reach equilibrium - this is also the formal definition of the steady state of the system: as soon as $I(t) = 0$ the system won't change any more.

\begin{align}
S(t) &= N - I(0) + \int_0^t -infectionRate\, \mathrm{d}t \\
I(0) &= 1 \\
I(t) &= \int_0^t infectionRate - recoveryRate\, \mathrm{d}t \\
R(t) &= \int_0^t recoveryRate\, \mathrm{d}t
\end{align}

\subsection{Deriving the properties}
The key to encode these specifications into a property is to understand that the stocks of \textit{S}, \textit{I} and \textit{R} change \textit{per time-unit} by the given rates. This means that if we run an SD simulation for 1 time-unit, the differences between the S, I and R stocks are the values specified in equations \ref{eq:sir_delta_rates}. %This property has to hold for \textit{any} initial value for S, I and R.

Translating this into a property of our ABS implementation is analogous. We count the number of initially S, I and R agents and run the simulation for 1 time-unit to get new S, I and R numbers. The differences should \textit{average} at the values specified in equations \ref{eq:sir_delta_rates} as well. This property has to hold for \textit{any} agent population. Note that due to ABS stochastic nature it is not enough to run only one replication of the simulation for 1 time-unit but we actually need multiple replications ($> 100$) to get statistically robust results. We then use two-tailed t-tests to compare the expected averages to the actual averages. If all 3 tests pass the whole property-test passes.

\subsection{Implementing a property-test}
We start by defining the type of our property, which takes a list of \textit{SIRStates} and returns a \textit{Bool}.

\begin{HaskellCode}
prop_sd_rates :: [SIRState] -> Bool
\end{HaskellCode}

Properties in QuickCheck are required to return \textit{Bool} to indicate success or failure - the arguments required for the function are then randomly generated and provided by QuickCheck. For QuickCheck to be able to generate random values of \textit{SIRState} we need to implement an instance of the \textit{Arbitrary} typeclass for \textit{SIRState}. This is straight forward: we \textit{uniformly} pick one out of the 3 possible values.

\begin{HaskellCode}
instance Arbitrary SIRState where
  -- arbitrary :: Gen SIRState
  -- Uniformly pick one of the 3 elements.
  arbitrary = elements [Susceptible, Infected, Recovered]
\end{HaskellCode}

If we want to have a different distribution of the Susceptible, Infected and Recovered states we can also provide a different \textit{Arbitrary} implementation:

\begin{HaskellCode}
instance Arbitrary SIRState where
  -- arbitrary :: Gen SIRState
  -- Susceptible are picked 3 times, Infected 2 times more often than Recovered
  arbitrary = frequency [ (3, return Susceptible)
                        , (2, return Infected)
                        , (1, return Recovered) ]
\end{HaskellCode}

Because we are running replications, we need random seeds to create random-number generators for each replication. We don't make them an argument to the property-test because we don't want to let QuickCheck handle them for us. The reason for that is that if we make it a parameter to the function, QuickCheck tries to vary it as well, meaning that we have less variance and test-cases over the initial population. Thus we generate the seeds manually but relying on QuickChecks random functionality.

\begin{HaskellCode}
prop_sd_rates :: [SIRState] -> Gen Bool
prop_sd_rates as = do
    -- Draw a list of replications random Ints over the full Int range to  
    -- reach maximum variance (reduce probability of drawing identical seeds)
    seeds <- vectorOf replications (choose (minBound, maxBound))
    return (prop_sd_ratesAux seeds)
  where
    prop_sd_ratesAux :: [Int] -> Bool
    prop_sd_ratesAux seeds = allTTestsPass -- see below
\end{HaskellCode}

Next we encode the SD specification as explained above into code.

% NOTE: we omited fromIntegral to make it more readable
\begin{HaskellCode}
-- initial values of S,I and R and total number of agents N
s0 = length (filter (==Susceptible) as)
i0 = length (filter (==Infected) as)
r0 = length (filter (==Recovered) as)
n  = s0 + i0 + r0

-- explicit re-naming
beta  = contactRate
gamma = infectivity
delta = illnessDuration

-- infection-rate
ir = if n == 0 then 0 else (i0 * beta * s0 * gamma) / n
-- recovery-rate 
rr = i0 / delta

-- S value after 1 time-unit 
s = s0 - ir
-- I value after 1 time-unit
i = i0 + (ir - rr)
-- R value after 1 time-unit
r = r0 + rr
\end{HaskellCode}

Then we run replications (100) of the simulation to get lists of new S, I and R values.

\begin{HaskellCode}
-- run for 1 time-unit
dur = 1.0
-- small dt: decreasing this value reduces t-test failures!
dt = 0.01
-- generate random-number generator for each replication
rngs = map mkStdGen seeds
-- compute simulated values for s, i and r
(ss, is, rs) = unzip (map (last . runSIR dur dt as beta gamma delta) rngs)
\end{HaskellCode}

Finally we run two-tailed t-tests with confidence of 0.99 ($\alpha = 0.01$) for all 3 lists of the new S,I and R values.

\begin{HaskellCode}
confidence = 0.99
sTest = tTestSamples TwoTail s (1 - confidence) ss
iTest = tTestSamples TwoTail i (1 - confidence) is
rTest = tTestSamples TwoTail r (1 - confidence) rs

-- property-test passes if all 3 t-tests pass
allTTestsPass = sTest && iTest && rTest
\end{HaskellCode}

\subsection{Results}
When testing the property with QuickCheck, by default 100 random test-cases will be generated and \textit{all} have to pass so that the whole property-test passes. Unfortunately, the whole property-test fails - not all random-test cases go through. When looking at the samples of failed t-tests and plotting them in a histogram, it shows clearly that the values exhibit strong outliers and skewed / fat tailed histograms. This means that they are not normally distributed, which is a base assumption and a necessity for t-tests. 

To see how many random test-cases fail out of the 100, we return always True for every random test-case and print a debug output in case a t-test fails. This leads to all tests running through with a t-test failing in roughly 5 out of 100 random test-cases. When we configure QuickCheck to perform 1.000 random test-cases we arrive at roughly 50 failed tests. %Although this is not a scientific measure, this hints that in this model roughly 5\% of all random test-cases fail.

This fact reveals the fundamental difference between SD and ABS: due to ABS' stochastic nature, an ABS cannot match an SD exactly because it is much richer in its dynamics. This enables ABS to explore and reveal paths which are not possible in deterministic SD. In the case of the SIR model, such an alternative path would be the immediate recovery of the single infected agent at the beginning without infecting any other agent. This is not possible in the SD case: in case there is 1 infected agent, the whole epidemic will unfold.

The difficulty of comparing dynamics between SD and ABS and the impracticality to compare them \textit{exactly} was shown by \cite{macal_agent-based_2010} in the case of the SIR model, where the author shows that it is bimodal. The authors \cite{figueredo_comparing_2014} approach the problem of comparing ABS to SD more generally and propose different techniques of how to approach the problem.

We will not go further into this problem as it is beyond the scope of this thesis but our tests reveal that very fact that we can come quite close but can't match exactly - the confidence parameter allows us to specify the "tightness" of our tests and guarantees us at least that we come close up to some limit.

%Unfortunately, not all tests were running through, depending on the dt value for the simulation and the confidence (alpha) value for the t-test. The sensitivity to both is obvious: a small dt avoids undersampling as already shown in the chapter (TODO time-driven) and it is clear that lowering the alpha value for a t-test which aims at accepting H0 leads to a test which is more likely to accept it. Still, if we select the parameters quite conservatively to dt = 0.01 and confidence = 0.01 about 5\% of 1000 tests fail.

\subsection{Discussion}
By using QuickCheck, we showed how to connect the ABS implementation to the SD specification by deriving a property, based on the SD specification. This property is directly expressed in code and tested by generating random test-cases where the random data is a random agent population. 

Although our initial idea of matching the ABS implementation to the SD specifications has not worked out in an exact way, we still showed a way of formalizing and expressing these relations in code and testing them using QuickCheck. Due to the "softness" of the tests through the confidence parameter, we can show that this specification comes close to the original SD implementation but does not match it exactly and is indeed richer in its dynamics as \cite{macal_agent-based_2010, figueredo_comparing_2014} have already shown. 

Our approach might work out better for a different model, which has a better behaved underlying specification than the bimodal SIR. Also we could use such a test to derive an optimally small $\Delta t$, which is not subject to undersampling as discussed in Chapter \ref{sub:timedriven_results}. The optimal $\Delta t$ is the lowest for which all (or sufficiently enough) tests go through. % It can be found by starting out with 1.0 and always half it until sufficiently enough tests go through.

%\subsection{TODO: Stateful testing of event-driven SIR}