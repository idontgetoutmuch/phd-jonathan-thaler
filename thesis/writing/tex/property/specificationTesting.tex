\chapter{Testing the SIR model specification}
\label{ch:prop_sirspec}

In the previous chapters we have established the correctness of our event- and time-driven implementation up to our informal specification, we derived from the formal SD specification from Chapter \ref{sec:sir_model}. What we are lacking is a verification whether the implementations also match the formal SD specification or not. In the process of verification, we need to make sure it is correct up to some specification. We aim at connecting the agent-based implementation to the SD specification, by formalising it into properties within a property-test. The SD specification can be given through the differential equations shown in Chapter \ref{sec:sir_model}, which we repeat here:

\begin{equation}
\begin{split}
\frac{\mathrm d S}{\mathrm d t} = -infectionRate \\
\frac{\mathrm d I}{\mathrm d t} = infectionRate - recoveryRate \\
\frac{\mathrm d R}{\mathrm d t} = recoveryRate 
\end{split}
\quad
\begin{split}
infectionRate = \frac{I \beta S \gamma}{N} \\
recoveryRate = \frac{I}{\delta} 
\end{split}
\end{equation}
\label{eq:sir_delta_rates}

Solving these equations is done by integrating over time. In the SD terminology, the integrals are called \textit{Stocks} and the values over which is integrated over time are called \textit{Flows}. At $t = 0$ a single agent is infected because if there wouldn't be any infected agents, the system would immediately reach equilibrium - this is also the formal definition of the steady state of the system: as soon as $I(t) = 0$ the system won't change any more.

\begin{align}
S(t) &= N - I(0) + \int_0^t -infectionRate\, \mathrm{d}t \\
I(0) &= 1 \\
I(t) &= \int_0^t infectionRate - recoveryRate\, \mathrm{d}t \\
R(t) &= \int_0^t recoveryRate\, \mathrm{d}t
\end{align}

\section{Deriving a property}
The goal is now to derive a property which connects those equations with our implementation. We have to be careful and realise a fundamental difference between the SD and ABS implementations: SD is deterministic and continuous, ABS is stochastic and discrete. Thus we cannot compare single runs but we can only compare averages: stated informally, the property we want to implement is that the ABS dynamics matches the SD ones \textit{on average}, independent of the finite population size, model parameters $\beta$ (contact rate), $\gamma$ (infectivity) and $\delta$ (illness duration) and duration of the simulation. To be able to compare averages, we run 100 replications of the ABS simulation with same parameters except a different random-number generator in each replication and collect the output of the final steps. We then run a two-sided T-Test on the replication values with the expected values from an SD simulation.

\begin{HaskellCode}
compareSDToABS :: Int     -- ^ Initial number of susceptibles
               -> Int     -- ^ Initial number of infected
               -> Int     -- ^ Initial number of recovered
               -> [Int]   -- ^ Final number of susceptibles in replications
               -> [Int]   -- ^ Final number of infected in replications
               -> [Int]   -- ^ Final number of recovered in replications
               -> Int     -- ^ beta (contact rate)
               -> Double  -- ^ gamma (infectivity)
               -> Double  -- ^ delta (illness duration)
               -> Time    -- ^ duration of simulation
               -> Bool
compareSDToABS s0 r0 i0
               ss is rs
               beta gamma delta t = sTest && iTest && rTest
  where
    -- run SD simulation to get expected averages
    (s, i, r) = simulateSD s0 i0 r0 beta gamma delta t
    
    confidence = 0.95
    sTest = tTestSamples TwoTail s (1 - confidence) ss
    iTest = tTestSamples TwoTail i (1 - confidence) is
    rTest = tTestSamples TwoTail r (1 - confidence) rs
\end{HaskellCode}

The implementation of \textit{simulateSD} is discussed in-depth in Appendix \ref{app:sdSimulation}. We are very well aware that comparing the output against an SD simulation is dangerous: after all, why should be trust the SD implementation? As outlined in the Appendix \ref{app:sdSimulation}, great care has been taken to ensure the correctness: the formulas from the SIR specification are directly encoded in code, allowed by Yampas arrowized FRP which guarantees that at least that translation step is correct - we then only rely on a small enough sampling rate and the correctness of the Yampa library. The former one is very well in our reach and we pick a sufficiently small samply rate; the latter one is beyond our reach but we expect the library to me mature enough to be correct for our purposes.

\section{Implementing the test}
Implementing a property-test is straight-forward. Here we give the implementation for the time-driven SIR implementation, the implementation for the event-driven SIR implementation is exactly the same with the exception of \textit{genTimeSIRRepls}. We again make use of the \textit{checkCoverage} feature of QuickCheck to get statistical robust results and expect that in 75\% of all test-cases the SD and ABS dynamics match \textit{on average} - we discuss below why we chose to use a 75\% coverage. QuickCheck will run as many tests as necessary to reach a statistically robust result which either allows to reject or accept this hypothesis.

\begin{HaskellCode}
prop_sir_time_spec :: Positive Int    -- ^ beta, contact rate
                   -> Propability     -- ^ gamma, infectivity, within (0,1) range
                   -> Positive Double -- ^ delta, illness duration
                   -> TimeRange       -- ^ time to run within (0, 50) range
                   -> [SIRState]      -- ^ population
                   -> Property
prop_sir_time_spec 
    (Positive cor) (P inf) (Positive ild) (T t) as = checkCoverage (do
  -- get initial agent numbers
  let (s0,i0,r0) = aggregateSIRStates as
  -- run 100 replications of time-driven SIR implementation
  (ss, is, rs) <- unzip3 <$> genTimeSIRRepls 100 as cor inf ild t
  let prop = compareSDToABS s0 i0 r0 ss is rs cor inf ild t
  return $ cover 75 prop "SIR time-driven passes t-test with simulated SD" True
\end{HaskellCode}

\section{Running the test}
When running the tests for the time- and event-driven implementation, QuickCheck reports the following:

\begin{verbatim}
+++ OK, passed 400 tests 
    (85.2% SIR time-driven passes t-test with simulated SD).

+++ OK, passed 3200 tests 
    (74.84% SIR event-driven passes t-test with simulated SD).
\end{verbatim}

The results clearly show that in both cases we reach the expected 75\% of coverage: the distributions of the time- and event-driven implementations match the simulated SD dynamics to at least 75\%, in case of time-driven this is even substantially higher. Still, this result raises a few questions:

\begin{enumerate}
	\item Why does the performance of the time-driven implementation surpasses the event-driven one by more than 10\%?
	
	\item Why are we not reaching a far higher coverage beyond 90\% and why have we chosen 75\% in the first place? After all our initial assumption was that the time- and event-driven implementations are simply agent-based implementations of the SD model and thus their dynamics should generate the same distributions as the SD ones.	
\end{enumerate}

First of all, the results are a very strong indication that although both implementation techniques try to implement the same underlying model, they generate different distributions and are thus not \textit{statistically} equal. This was already established in Chapter \ref{ch:sir_invariants}, where we have compared the distributions of both simulations and found that although we reach 90\% similarity this means that they are still different in some cases. The results of this property-test reflect that as well and we argue that this is also the reason why we see different performance of each when compared to SD. 

An explanation why the time-driven approach seems to be closer to the SD dynamics is that in the event-driven approach we are dealing with discrete events, jumping from time to time instead of moving forward in time continuously as it happens conceptually in the time-driven approach. Time is also continuous in SD, thus it seems intuitively clear that a time-driven approach is closer to the SD implementation than the event-driven one - it seems valid to call our time-driven approach a continuous agent-based simulation approach. The implication is that depending on our intention, picking a time-driven or an event-driven implementation can and will make a statistical difference. If one is transferring an SD to an ABS model, one might consider to follow the time-driven approach as it seems to come much closer to the SD dynamics than the event-driven approach.

\medskip

The reason that we are not reaching a coverage level up to and beyond 90\% is rooted in the fundamental difference between SD and ABS: due to ABS' stochastic nature, its dynamics cannot match an SD exactly because it generates a \textit{distribution} whereas the SD is deterministic. This enables ABS to explore and reveal paths which are not possible in deterministic SD. In the case of the SIR model, such an alternative path would be the immediate recovery of the single infected agent at the beginning without infecting any other agent. This is not possible in the SD case: in case there is 1 infected agent, the whole epidemic will unfold.

The difficulty of comparing dynamics between SD and ABS and the impracticality to compare them \textit{exactly} was shown by \cite{macal_agent-based_2010} in the case of the SIR model, where the authors showed that it generates a bimodal distribution. Further, the authors report that a 70\% envelope contains both the results of the SD and ABS implementation which is the reason why we chose a a 75\% coverage as our initial guess, which has turned out to work well and is in accordance with the results of \cite{macal_agent-based_2010}. %Indeed, that is also supported by our observations. When looking at the samples of failed t-tests by plotting them in a histogram, it shows clearly that the values exhibit strong outliers, arriving at a skewed / fat tailed / bimodal histogram. 

\medskip

The question which remains is whether it actually even makes sense to compare the approaches to SD or even amongst each other - after all they can be seen as fundamentally different approaches. We can argue that they are qualitatively equal as \cite{figueredo_comparing_2014} has already emphasised in a different study on comparing ABS and SD: although dynamics of ABS models are statistically different from SD ones, they look similar. The main difference is that ABS can contribute additional insight through revealing extra patterns due to its stochasticity, something not possible with SD. Thus in the end we simply have to accept that the respective coverage ratios are the closest we can get and that this is also the closest we can get in terms of validating our implementations against the original SD specification.

%% THESE ARE NOTES TAKEN DURING TESTING, DON'T REMOVE, THEY EXPLAIN HOW WE ARRIVE AT THESE RESULTS
%---------------------------------------------------------------------------------------------------------------------------
%ON AVERAGE CONTACT RATE
%NOTE: it seems that with random parameters and normal population but t = 1.0 we reach a coverage around 27\% for EVENT-driven
%NOTE: it seems that with random parameters and normal population AND random time 0-10 we reach a coverage around 38\% for EVENT-driven
%
%FIXED CONTACT RATE
%NOTE: it seems that with random parameters and normal population but t = 1.0 we reach a coverage around 38\% for EVENT-driven
%NOTE: it seems that with random parameters and normal population AND random time 0-10 we reach a coverage around 48\% for EVENT-driven
%
%TIME-DRIVEN
%NOTE: it seems that with random parameters and normal population but t = 1.0 we reach a coverage around 70\% for TIME-driven
%NOTE: it seems that with random parameters and normal population AND random time 0-10 we reach a coverage up to 85\% for TIME-driven
%---------------------------------------------------------------------------------------------------------------------------
%NOTE: it seems that fixed contact rate works better than average contact rate in event-driven => macal was right after all...
%with t between 0 and 50 we reach 73\%
%---------------------------------------------------------------------------------------------------------------------------
% NO LONGER TRUE
%The event-driven approach clearly fails to reach a similar percentage: the differences between the the dynamics generated by the event-driven and the SD seem to be statistically significant. This result is consistent with the one from Chapter \ref{ch:sir_invariants}, where showed that the distribution of the dynamics generated by the event- and time-driven approach vary from each other considerably, it would have been surprising if they both show a similar performance when compared with the SD approach. 
%In our implementation we follow the idea as presented in \cite{macal_agent-based_2010}. Their specification states that in each time-step of 1 time-unit the susceptible make contact with a fixed number (contact rate) of other agents. This is a valid ABS model but it deviates to come closer to the SD as it fixes the number of contacts instead of making contact \textit{on average}. In SD and the time-driven approach, these are all averages and thus we are drawing from the exponential distribution in the time-driven case. This is not the case in our event-drive implementation, following \cite{macal_agent-based_2010}. If we change this behaviour to incorporate the exponential distribution we get a higher match to the SD dynamics of 37\% which is still a far cry form the time-driven approach but it at least indicates that this is a viable option to push the results further towards the SD dynamics. 

\section{Discussion}
After having shown in previous chapters, that individual agent behaviour is correct up to some specification, in this chapter we focused on validating the dynamics of the simulation with the original SD specification.

By using QuickCheck, we showed how to connect both ABS implementations to the SD specification by deriving a property, based on the SD specification. This property is directly expressed in code and tested through generating random test-cases with random agent populations and random model parameters. 

Although our initial idea of matching the ABS implementation to the SD specifications has not worked out in an exact way, we still showed a way of formalizing and expressing these relations in code and testing them using QuickCheck. The results showed that the ABS implementation comes close to the original SD specification but does not match it exactly - it is indeed richer in its dynamics as \cite{macal_agent-based_2010, figueredo_comparing_2014} have already shown. Our approach might work out better for a different model, which has a better behaved underlying specification than the bimodal SIR.