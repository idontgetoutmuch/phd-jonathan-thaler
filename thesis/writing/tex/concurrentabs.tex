\chapter{Concurrent ABS}
\label{ch:concurrent_abs}
Functional programming as in Haskell is well known and accepted as a remedy against the problems of imperative programming in implementing parallel software TODO: cite ?. The reason for it is clear: immutable data and explicit control of side-effects removes a large class of bugs due to data-conflicts, data-races, and blablabla TODO: we are claiming things here, which we need to clearly back up, also data-races ARE possible in Haskell! A fundamental benefit and strength of Haskell is, that it clearly distinguishes between parallelism and concurrency \cite{jones_tackling_2002} and it is very important for us to do so as well:

\begin{itemize}
	\item \textbf{Parallelism} - In parallelism, code runs in parallel without interfering with other code through shared data (references, mutexes, semaphores,...). An example is the function \textit{map :: (a $\rightarrow$ b) $\rightarrow$ [a] $\rightarrow$ [b]}, which maps each element of type \textit{a} to \textit{b} using the function \textit{(a $\rightarrow$ b)}. It is a pure function and thus no sharing of data either through some monadic context or through the function \textit{(a $\rightarrow$ b)} is possible. This allows to run it in parallel: each function evaluation \textit{(a $\rightarrow$ b)} could potentially be executed at the same time, if we had enough CPU cures. Whether it runs actually in parallel or not, has no influence on the outcome, it is not subject to any non-deterministic influences. Thus we identify parallelism with pure and deterministic execution of data-transformations (data-parallelism).
	
	\item \textbf{Concurrency} - In concurrency, code runs in parallel but can potentially interfere with other code through shared data (references, mutexes, semaphores, ...). An example are two threads, running in parallel, which share data through \textit{IORefs}. In concurrency there is no option: code has to run in parallel through the use of threads but now the outcome of the program very much depends on the ordering in which the threads are scheduled. This gives rise to very different access patterns to the shared data, with the potential for race conditions, dirty reads and so on... The challenge of implementing concurrent programs, is to write the program in a way that despite of these non-deterministic influences it is still a correctly working program. Thus we identify concurrency with impure and non-deterministic execution of imperative-style monadic command execution.
\end{itemize}

There is obvious potential for adding (data-)parallelism to ABS e.g. using data-parallel data-structures for the environment so cells can be updated in parallel, in time-driven ABS agents can be updated in parallel using parMap because they all act conceptually at the same time as shown already in Yampa \footnote{\url{https://www.reddit.com/r/haskell/comments/2jbl78/from_60_frames_per_second_to_500_in_haskell/}}. Despite the potential for parallelism, in this chapter we focus on concurrency only and refer to the book \cite{marlow_parallel_2013} for an in-depth discussions of the mechanism for parallelism in Haskell. The reason for focusing on concurrency and leaving parallelism out is simple: the Ph.D. doesn't provide enough time to explore both in equal depth and the application of STM to implement concurrent ABS looks very much more interesting and challenging probably because it is also a complete novelty.

\medskip

More specifically, in this chapter, we look into using Software Transactional Memory (STM) for implementing concurrent ABS. The benefits of STM is that it allows to overcome the problems of lock-based approaches. Although STM exists in other languages as well, Haskell was one of the first to natively build it into its core. Further, it has the unique benefit that it can guarantee the lack of persistent side-effects at compile time, allowing unproblematic retries of transactions, something of fundamental importance in STM. This makes the use of STM in Haskell very compelling.

The paper \cite{discolo_lock_2006} gives a good indication how difficult and complex constructing a correct concurrent program is and shows how much easier, concise and less error-prone an STM implementation is over traditional locking with mutexes and semaphores. Further it shows that STM consistently outperforms the lock-based implementation. We follow this work and compare the performance of lock-based and STM implementations and hypothesise that the reduced complexity and increased performance will be directly applicable to ABS as well.

We present two case studies using the already introduced SIR (Chapter \ref{sec:sir_model}) and Sugarscape (Chapter \ref{sec:sugarscape}) models, where we compare the performance of lock-based and STM implementations in two different well known Agent-Based Models, where we investigate both the scaling performance under increasing number of CPUs and the scaling performance under increasing number of agents. We show that the STM implementations consistently outperform the lock-based ones and scale much better to increasing number of CPUs both on local machines and on Amazon Cloud Services.

\input{./tex/concurrentabs/stm.tex}

\input{./tex/concurrentabs/stmabs.tex}

\input{./tex/concurrentabs/discussion.tex}