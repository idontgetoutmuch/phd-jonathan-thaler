\section{Discussion}
Our FRP based approach is different from traditional approaches in the ABS community. First it builds on the already quite powerful FRP paradigm. Second, due to our continuous time approach, it forces one to think properly of time-semantics of the model and what the correct $\Delta t$ should be. Third, it requires one to think about agent interactions in a new way instead of being just method calls.

\subsection{Static guarantees}
Because no part of the simulation runs in the \textit{IO} Monad and we do not use \textit{unsafePerformIO} we can rule out a serious class of bugs caused by implicit data-dependencies and side effects, which can occur in traditional imperative implementations.

Our approach can guarantee reproducibility already at compile time, which means that repeated runs of the simulation with the same initial conditions will always result in the same dynamics, something highly desirable in simulation in general. Although we allow side effects within agents, we restrict them to only the \textit{Rand} Monad in a controlled, deterministic way and never use the \textit{IO} Monad, which guarantees the absence of non-deterministic side effects within the agents and other parts of the simulation. This proves that this implementation is indeed \textit{pure} computation. This can only be achieved through purity, which guarantees the absence of implicit side effects, which allows to rule out non-deterministic influences at compile time through the strong static type system, something not possible with traditional object-oriented approaches.

Determinism is also ensured by fixing the $\Delta t$ and not making it dependent on the performance of e.g. a rendering-loop or other system-dependent sources of non-determinism as described by \cite{perez_testing_2017}. Also by using FRP we gain all the benefits from it and can use research on testing, debugging and exploring FRP systems \cite{perez_back_2017,perez_testing_2017}.

Also we show how to implement the \textit{parallel} update strategy \cite{thaler_art_2017} in a way that the correct semantics are enforced and guaranteed already at compile time through the types. This is not possible in traditional imperative implementations and poses another unique benefit over the use of functional programming in ABS.

The result of using FRP allows expressing continuous time-semantics in a very clear, compositional and declarative way, abstracting away the low-level details of time-stepping and progress of time within an agent.

Using pure functional programming, we can enforce the correct semantics of agent execution through types where we demonstrate that this allows us to have both, sequential monadic behaviour, and agents acting \textit{conceptually} at the same time in lock-step, something not possible using traditional object-oriented approaches.

\subsection{Drawbacks}
Despite the strengths and benefits we get by leveraging on FRP, there are errors that are not raised at compile time, e.g. we can still have infinite loops and run-time errors. This was for example investigated in \cite{sculthorpe_safe_2009} where the authors use dependent types to avoid some run-time errors in FRP. We suggest that one could go further and develop a domain specific type system for FRP that makes the FRP based ABS more predictable and that would support further mathematical analysis of its properties. Furthermore, moving to dependent types would pose a unique benefit over the traditional object-oriented approach and should allow us to express and guarantee even more properties at compile time. We leave this for further research.

In our pure functional approach, agent identity is not as clear as in traditional object-oriented programming, where there is a quite clear concept of object-identity through the encapsulation of data and methods. Signal functions don't offer this strong identity and one needs to build additional identity mechanisms on top e.g. when sending messages to specific agents as will be shown in the next chapter.

We can conclude that the main difficulty of a pure functional approach evolves around the communication and interaction between agents, which is a direct consequence of the issue with agent identity. Agent interaction is straight-forward in object-oriented programming, where it is achieved using method calls mutating the internal state of the agent, but that comes at the cost of a new class of bugs due to implicit data flow. In pure functional programming these data flows are explicit but our current approach of feeding back the states of all agents as inputs is not very general. We address this problem in the next chapter.

\subsection{Performance}
Currently, the performance of this approach does not come close to imperative implementations. We compared the performance of the time-driven SIR as presented in Section \ref{sec:adding_env} to an implementation in Java using the ABS library RePast \cite{north_complex_2013}. We ran the simulation until $t = 100$ on a 51x51 (2,601 agents) with $\Delta t = 0.1$ (unknown in RePast) and averaged 8 runs. The performance results make the lack of speed of our approach quite clear: the pure functional approach needs around 72.5 seconds whereas the Java RePast version just 10.8 seconds on our machine to arrive at $t = 100$. It must be mentioned, that RePast does implement an event-driven approach to ABS, which can be much more performant \cite{meyer_event-driven_2014} than a time-driven one, so the comparison is not completely valid.

As a remedy, we compared a time-driven SIR implementation we did in Java to the pure functional implementations of Chapter \ref{sec:timedriven_firststep} without the \textit{Rand} Monad and the environment. In the Java implementations we tried to follow conceptually similar approaches to the pure functional implementations but obviously that is not possible for every aspect. For example, we are not using any reactive programming library but we follow a similar time-sampling approach. We run for 150 time-steps with 1,000 susceptible and 1 infected agent, $\beta = 5$, $\gamma = 0.05$, $\delta = 15$ and $\delta t = 0.01$. Further, we fixed the random-number generators to guarantee identical dynamics in every run and averaged 8 runs. The time-driven Java implementation averages at a performance of 0.5 seconds, compared to 27.6 seconds in Haskell. The implementation of \ref{sec:adding_env} with the same configuration using a 10x10 environment with no neighbourhood restrictions averages at 19 seconds.

We expect a substantial performance improvement when switching to an event-driven approach \cite{meyer_event-driven_2014} in the next Chapter \ref{sec:eventdriven_basics}. Further, the performance issue will be addressed more in-depth in the chapters on parallelism (Chapter \ref{ch:parallelism_ABS}) and concurrency (Chapter \ref{ch:concurrent_abs}).