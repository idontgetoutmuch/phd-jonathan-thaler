\section{Parallelism in ABS}
The promise of parallelism in Haskell is compelling: speeding up the execution but retaining all static compile-time guarantees about determinism. In other words, using parallelism could give us a substantial performance improvement without sacrificing the static guarantees of reproducible outputs from repeated runs with initial conditions.

Generally, parallelism can be applied whenever the execution of code is order-independent, that is referential transparent, and has no implicit or explicit side-effects. Without going into too much technical detail, in this section we outline the parallelism techniques available in Haskell and briefly discuss how they can be used in ABS in general. We also discuss if and how parallelism can be added to our previously discussed use-cases of Chapters \ref{sec:timedriven_firststep}, \ref{sec:adding_env} and Sugarscape TODO and report the performance improvements where applicable.

\subsection{Parallelism in Haskell}
We follow the book \cite{marlow_parallel_2013}, which can be seen as the main source for parallelism and concurrency in Haskell and refer to it for an in-depth discussions of parallel Haskell.

\paragraph{Evaluation parallelism}
Put short, evaluation parallelism allows to build functions which run in parallel e.g. a parallel version of \textit{map}, which is called \textit{parMap}. This is achieved using the \textit{Eval Monad} which is run using a parallel evaluation strategy, arriving at a pure value - the evaluation of the \textit{Eval Monad} itself is pure and does not require the IO (this is exactly what we expect from parallelism: to be deterministic). Obviously this gives huge potential for speeding up programs because maps are omnipresent in a lot of functional code. Not only parmap! explain a little bit more in detail without going into too much technical stuff.

Very important: "In the previous two chapters, we looked at the Eval monad and Strategies, which work in conjunction with lazy evaluation to express parallelism. A Strategy consumes a lazy data structure and evaluates parts of it in parallel. This model has some advantages: it allows the decoupling of the algorithm from the parallelism, and it allows parallel evaluation strategies to be built compositionally. But Strategies and Eval are not always the most convenient or effective way to express parallelism. We might not want to build a lazy data structure, for example. Lazy evaluation brings the nice modularity properties that we get with Strategies, but on the flip side, lazy evaluation can make it tricky to understand and diagnose performance."
Its laziness which allows that.

%https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/ch02.html
%https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/ch03.html

\paragraph{Data-flow parallelism}
Par Monad: how does it work? can express data-flow networks where tasks are forked and then results are synchronised. all this happens deterministically by building on the same mechanics the Eval monad is using thus technically speaking they are equivalent. 

%https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/ch04.html

\paragraph{Data-structure parallelism}
An environment could be organised and accessed through such a data-structure, which could potentially lead to big speed ups. Agents could locally read the data-structure data-parallel and the simulation kernel could feed the output of the agents data-parallel back into this structure.

%https://learning.oreilly.com/library/view/parallel-and-concurrent/9781449335939/ch05.html

general solution we opt for is  to run agents in parallel in our approaches. in other abs models we could apply data-structure parallelism and/or data-flow parallelism with huge Performance potential but thats always highly model dependent thus we dont go in depth here

\subsection{Use-Cases}

\subsubsection{Non-Monadic SIR}
Although \textit{parMap} can be applied in all cases where a map us used, we are particularly interested in running agents in parallel. With \textit{parMap} this should become possible in our non-monadic SIR implementation built on Yampa from Chapter \ref{sec:timedriven_firststep}. Even thought the Eval Monad is used under the hood and Yampa is non-monadic, it is still applicable because running the monad is pure, resulting in a pure result - \textit{parMap} is a pure function. TODO: how can we apply this?

Inspired by the work of \cite{perez_60_2014}, which shows the potential of speeding up real-world Haskell programs using Yampa We conducted a comparison of an implementation which makes use of evaluation parallelism to run agents in parallel.

OK, rephrase: compare performance of non-parallel implementation WITH threaded an -N option to non-parallel implementation without threaded and / or N1 to make sure that no performance improvement happens automatically by using threaded e.g. GCs or something else...
I observed the behaviour in the following code: https://github.com/thalerjonathan/phd/tree/master/public/purefunctionalepidemics/code/SIR_Yampa

I analysed a bit more using the threadscope tool. I ran the same program twice with different ghc-options:
1. -O2 -Wall -Werror -eventlog 
2. -O2 -Wall -Werror -eventlog -threaded -with-rtsopts=-N

When looking at the event logs with threadscope it becomes appartent, that parallel garbage collection is the cause of the CPU usage above 100%:
-  In the single-threaded case 0 sparks are created and everything runs indeed only on one core. There are two Garbage Collectors (Gen0 and Gen1) but nothing runs in parallel (Par collections are 0 for both).
- In the multi-threaded case also 0 sparks are created but now 8 cores are used: all 'running' activity happens on only 1 core as expected but garbage collection happens on all 8 cores: the diagrams and the number of Par collections clearly indicates that. The time spent on parallel GC work is 10.76% (0 is completely serial and 100% is completely parallel).

Now when we compare the timing between both runs we see the following: 
- single-threaded: 11.68s total, 7.35s mutator, 4.34s GC,
- multi-threaded: 10.70s total, 7.03s mutator, 3.68s GC

This adds up: the ~ 10\% of parallel GC work done in multi-threaded are also the ~ 10\% it is faster over the single-threaded one. Of course I only did a single run in each case but I think the analysis is still valid and the point was made: when running a Haskell program which does not use any parallel features, running it with the -threaded option can lead to an increase in performance due to parallel GC.

% https://www.reddit.com/r/haskell/comments/2jbl78/from_60_frames_per_second_to_500_in_haskell/\\

TODO: should be applicable to the par monad as well? 

\subsubsection{Monadic SIR}
Unfortunately \textit{parMap} is not applicable to the monadic SIR version of Chapter \ref{sec:adding_env} because of the use of mapM, which cannot be replaced due to its inherent sequential nature: mapM runs monadic actions which have side-effects thus ordering matters. Even if the implementation in that chapter behaves as if the agents are run in parallel, technically they are run sequentially because of the need for the Random Monad effect. This leaves us basically without any options of parallelism for the monadic SIR model, we will come back to this use-case in the concurrency section, where we will show that by using concurrency it is possible to achieve a substantial speed up of orders of magnitude.

TODO: can't we run with the Par monad? in the end its just a data-flow graph! see the update-strategies. Should be possible, only problem is how to deal with rand then? we use split. the marlow book says: don't do repeated calls to runPar. we can because we implemented the agent-running loop  by our selves. so we can use Eval and Par

TODO: following idea: instead of updating the environment, we simply build a new one, no need to update because we update all of them anyway, so very expensive. Also simply split RNGs for every agent, then we can run them in parallel 


NOTE: running the agents in parallel with par doesn't work because we use mapM and are thus monadic, which involves sequencing. so this is really out of the window here. Also we cannot put a Par in a transformer stack because the library doesn't support it, what actually makes sense. But we can do the following: we can run an agents MSF only within the Par monad which gives agents the ability to spawn data-flow parallel computations - random-number streams are handled like in the non-monadic version. Note that this is only possible with the MSFs of dunai and not the SF because the latter one adds already the a ReaderT DTime which makes it impossible already. 
What is actually possible would be to write a combined monad for Par and ReaderT because the latter one is a read-only value and could thus potentially run in parallel - we leave this for further research. There exists also a combination of the Par with the Rand monad, so if the time-driven approach is not needed then this could be used to give the agents the ability to both draw random numbers AND do deterministic data-parallel computations. The agents can then be run in parallel through the par monad.


\subsubsection{Sugarscape}
The same case as in the monadic SIR: running the agents with evaluation or data-flow parallelism is not possible in a monadic context  \textit{in general}. We have shortly discussed how it could be achieved in specific circumstances where then agents are running in the Par monad only, but this is highly model specific and for the Sugarscape this approach does not work. 

There is though one tiny thing we could optimise.

use parmap for updating Pollution/regrow resources. still agents can't be run in parallel because of monadic effects, we show in the concurrent section how we can use concurrency to achieve a substantial speed up using STM.

compare Environment parallelism between sequential and concurrent sugarscape: should see alarger speedup in conc bcs the sequential percentage is larger there

unfortunately its a Map datastructure, so we cannot operate in parallel e.g. map. but we can compute pollution because it uses map

\input{./tex/parallelabs/parallelism/parallelruns.tex}

\input{./tex/parallelabs/parallelism/reflection.tex}