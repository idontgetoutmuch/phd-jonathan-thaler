\section{Discussion}
In this chapter we briefly explored how to apply parallelism to our pure functional ABS approach and ran case studies on our existing models to get a rough estimate of what performance increase we can expect. In general, we aimed at running agents in parallel, employing both techniques of evaluation and data-flow parallelism. Because of the quite sequential nature of the agent behaviour itself, there is much less potential for parallelism \textit{within} an agent, thus the idea was to run them all in parallel. This should create enough workload as an agent is an obvious unit of partitioning which can indeed be run in parallel under given circumstances.

Although we showed how to apply the techniques, unfortunately the case studies showed that performance improvement was only possible in the case of the non-monadic SIR as introduced in Chapter \ref{sec:timedriven_firststep}. The speed up stemmed from the fact that the agents ran indeed in parallel as our original goal was, thus resulting in a significant speed up factor of over 4. 

Unfortunately all attempts in parallelising the monadic SIR and Sugarscape implementations failed, which was expected. As soon as we switch to monadic agents, evaluation parallelism is out of the window, as agents can't be run in parallel any more because side effects require to impose a sequential ordering (which is exactly what the idea behind a Monad is).

We further showed how to apply parallelism \textit{within} a SIR agent and for updating the environment of the Sugarscape in parallel using the \textit{Par} Monad. It didn't show any speed up as well but this was not the primary objective: we rather explored conceptually to demonstrate how it can be used - other models might benefit massively from such an approach as they might contain much more potential for data-flow parallelism.

We didn't discuss data parallelism on large array structure or parallelism on GPU as they are used in massively large numerical computation. These techniques achieve tremendous speed ups but are not applicable to ABS in general but only in very model specific cases where e.g. each agent needs to crunch through arrays of numbers to perform numerical computations. We refer to \cite{marlow_parallel_2013} for a more in-depth discussion of both topics in Haskell and leave the application to pure functional ABS for further research.

Concluding, we see a direct consequence of the fact that types reflect the semantics of our model: when our agents are pure they can be run in parallel and independent from each other but if they are monadic, then they are not applicable to parallelism. In the next chapter, we show how to approach this problem and come up with a solution where we can run monadic agents in parallel. This is only possible within a concurrent context, where we utilise Software Transactional Memory, which means we have to sacrifice determinism in our solution. Still, by favouring Software Transactional Memory using the \textit{STM} Monad instead of resorting to \textit{IO} we get the guarantee that the the only source of non-determinism is due to the concurrency of \textit{STM} \textit{and nothing else}. Further, we will show that an additional benefit of using \textit{STM} over \textit{IO} is that the \textit{STM} approach reaches a considerable higher speed up compared to a lock-based approach based on \textit{IO}. 