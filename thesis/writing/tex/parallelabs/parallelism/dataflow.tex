\section{Data-flow parallelism}
When relying on a lazy data structure to apply parallelism is not an option, evaluation strategies as presented before are not applicable. Further, although lazy evaluation brings compositional parallelism, it makes it hard to reason about performance. Data-flow parallelism offers an alternative over evaluation strategies, where the programmer can give more details but gains more control: data dependencies are made explicit and reliance on lazy evaluation is avoided \cite{marlow_monad_2011}.
Data-flow parallelism is implemented through the \textit{Par} Monad, which provides combinators for expressing data-flows: in this Monad it is possible to \textit{fork} parallel tasks which communicate with each other through shared locations, so called \textit{IVar}s. Internally these tasks are scheduled by a work-stealing scheduler, which distributes the work evenly on available processors at runtime. \textit{IVars} behave like futures or promises: they are initially empty and can be written once. Reading from an empty \textit{IVar} will cause the calling task (or main thread) to wait until it is filled. An example is a parallel evaluation of two fibonacci numbers:

\begin{HaskellCode}
runPar (do
  i <- new             -- create new IVar
  j <- new             -- create new IVar
  fork (put i (fib n)) -- fork new task compute fib n and put result into IVar i
  fork (put j (fib m)) -- fork new task compute fib m and put result into IVar j
  a <- get i           -- wait for the result from IVar i and collect it
  b <- get j           -- wait for the result from IVar j and collect it
  return (a,b)         -- return the sum
\end{HaskellCode}

Note that data-flow parallelism makes it possible to express parallel evaluation of a list or a tuple as with evaluation strategies. The difference though is, that it does avoid lazy evaluation. More importantly, putting a value into an \textit{IVar} requires the type of the value to have an instance of the \textit{NFData} typeclass. This simply means that a value of this type can be fully evaluated, not just to WHNF but to evaluate the full expression to the value it represents.

\subsection{Data-flow parallelism in ABS}
The \textit{Par} Monad seems to be a very suitable mechanism to enable agents to express data-flow parallelism within their behaviour. This is only possible with the monadic ABS approach as in the SIR implementation of Chapter \ref{sec:adding_env} and the Sugarscape of Chapter \ref{sec:eventdriven_implementation}. An important fact is that if the \textit{Par} Monad is used, it has to be the outermost monad because it cannot be a transformer. This is emphasised by the fact that there exists no \textit{ParT} transformer instance, like for other Monads. Making the \textit{Par} Monad a transformer would have the semantics of running the \textit{bind} in parallel. It is quite clear that this simply makes no sense: \textit{bind} is a function for composing / sequencing monadic actions, which in general involves side-effects of some kind. Side-effects inherently impose some sequencing where evaluation of different sequences has different meanings in general - thus the sequential nature of \textit{bind}. Therefore, running monadic code in parallel is simply not possible in general due to side-effects \footnote{Besides, it would be not very clear what we are running in parallel within the \textit{bind} operator as there is nothing to parallelise in general e.g. no structure over which we can parallelise in general.} and thus there is no (meaningful) way to put the \textit{Par} Monad into a transformer stack.