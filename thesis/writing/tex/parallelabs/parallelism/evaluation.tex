\section{Evaluation Parallelism}
Evaluation parallelism introduces so called strategies to evaluate lazy data-structures in parallel. Examples are strategies to evaluate a list, or tuples in parallel where for each element a spark is created. The fundamental concept Haskell uses to achieve evaluation parallelism is its own non-strictness nature. Non-strictness means that expressions are not eagerly evaluated when defined, like in imperative programming languages but only evaluated when their result is actually needed. This is implemented internally using thunks, which are pointers to expressions. When the value of an expression is needed, this thunk is accessed and the expression is reduced until the next constructor or lambda is encountered. This is called Weak Head Normal Form (WHNF) evaluation because it only reduces the "head" of the expression, which could consist of sub expressions. This indirection, the separation of data creation from consumption / evaluation, indeed enables evaluation parallelism and Haskell provides two additional functions to support this:

\begin{itemize}
	\item \textit{par :: a $\rightarrow$ b $\rightarrow$ b} Returns the second argument \textit{b} but evaluates the first argument \textit{a} in parallel. It is used when the result of evaluating \textit{a} is required later.
	
	\item \textit{seq :: a $\rightarrow$ b $\rightarrow$ b} - Returns the second argument \textit{b} but is strict in its first argument, which means it forces its evaluation to WHNF. It is used when the result of evaluating \textit{a} is required now.
\end{itemize}

Internally, evaluation parallelism is handled through so called \textit{sparks}, which are basically thunks which get evaluated in parallel. The Haskell runtime system manages sparks and distributes them to threads where they get executed. Due to their extremely light-weight nature, it is no problem to create tens of thousands of sparks. One has to bear in mind that even though evaluating in parallel through sparks is extremely cheap, it still has some overhead. Thus, the work-load of each element in a list might be too low for a spark, then one can distribute chunks of a list onto a single spark.
It is important to understand, that all this works without side-effects - the strategy combinators are all pure functions building on \textit{par} and \textit{seq}. This allows us to add parallelism to an algorithm by applying a parallel evaluation strategy to its result which e.g. is a lazy list - again this is possible through non-strictness, which separates the construction of data from its consumption.

\subsection{Evaluation Parallelism In ABS}
Using compositional parallelism is exactly what we use to aim at adding evaluation parallelism for agent execution in the non-monadic SIR example \ref{sec:timedriven_firststep}. We know that the whole simulation is a completely pure computation because Yampa is non-monadic, thus it is guaranteed that there are no side-effects - thus agents are run conceptually in parallel e.g. using map. Now we should be able to add parallelism without needing to re-implement \textit{dpSwitch} which is the function which runs the agents in parallel (Also re-implementing switch functions would not get us very far because of WHNF evaluation it is the wrong end to start parallel evaluation: probably only the arguments would be evaluated but not the agent behaviour.)

The solution is to add evaluation parallelism in the agent-output collection phase: where the recursive switch into the \textit{stepSimulation} function happens. There we use a evaluation strategy to evaluate the outputs of all agents in parallel. The agents will then be evaluated in parallel due to compositional parallelism, when we force the output of each in parallel. We give more details in the short case-study \ref{parallel_nonmonadic_sir} below.

TODO: can we apply it to monadic SIR ? hypothesis is that yes we can apply it but we wont see any performance improvement because the sequential monadic code forces evaluation
TODO: we can use it to e.g map over a lazy data structure representing the environment - we show in the case-study if this is applicable to the sugarscape
