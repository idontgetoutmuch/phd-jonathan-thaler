\chapter{Property-Based Testing in ABS}
\label{ch:property}

Exploring ways in which pure functional ABS can be of benefit to verification \& validation and increasing correctness of an ABS implementation. 

\section{Verification in ABS}
General there are the following basic verification \& validation requirements to ABS \cite{robinson_simulation:_2014}, which all can be addressed in our \textit{pure} functional approach as described in the paper in Appendix \ref{app:pfe}:

\begin{itemize}
	%\item Modelling progress of time - achieved using functional reactive programming (FRP)
	%\item Modelling variability - achieved using FRP
	\item Fixing random number streams to allow simulations to be repeated under same conditions - ensured by \textit{pure} functional programming and Random Monads
	\item Rely only on past - guaranteed with \textit{Arrowized} FRP
	\item Bugs due to implicitly mutable state - reduced using pure functional programming
	\item Ruling out external sources of non-determinism / randomness - ensured by \textit{pure} functional programming
	\item Deterministic time-delta - ensured by \textit{pure} functional programming
	\item Repeated runs lead to same dynamics - ensured by \textit{pure} functional programming
\end{itemize}

\begin{enumerate}
	\item Run-Time robustness by compile-time guarantees - by expressing stronger guarantees already at compile-time we can restrict the classes of bugs which occur at run-time by a substantial amount due to Haskell's strong and static type system.  This implies the lack of dynamic types and dynamic casts \footnote{Note that there exist casts between different numerical types but they are all safe and can never lead to errors at run-time.} which removes a substantial source of bugs.  Note that we can still have run-time bugs in Haskell when our functions are partial.
	\item Purity - By being explicit and polymorphic in the types about side-effects and the ability to handle side-effects explicitly in a controlled way allows to rule out non-deterministic side-effects which guarantees reproducibility due to guaranteed same initial conditions and deterministic computation. Also by being explicit about side-effects e.g. Random-Numbers and State makes it easier to verify and test.
	\item Explicit Data-Flow and Immutable Data - All data must be explicitly passed to functions thus we can rule out implicit data-dependencies because we are excluding IO. This makes reasoning of data-dependencies and data-flow much easier as compared to traditional object-oriented approaches which utilize pointers or references.
	\item Declarative - describing \textit{what} a system is, instead of \textit{how} (imperative) it works. In this way it should be easier to reason about a system and its (expected) behaviour because it is more natural to reason about the behaviour of a system instead of thinking of abstract operational details.
	\item Concurrency and parallelism - due to its pure and 'stateless' nature, functional programming is extremely well suited for massively large-scale applications as it allows adding parallelism without any side-effects and provides very powerful and convenient facilities for concurrent programming. The paper of (TODO: cite my own paper on STM) explores the use Haskell for concurrent and parallel ABS in a deeper way.
\end{enumerate}

TODO: haskell-titan
TODO: Testing and Debugging Functional Reactive Programming \cite{perez_testing_2017}

Static type system eliminates a large number run-time bugs.

TODO: can we apply equational reasoning? Can we (informally) reason about various properties e.g. termination?

Follow unit-testing of the whole simulation as prototyped for towards paper.

in this we explore something new: property-based testing in ABS

\section{Property-Based Testing}
Follow property-based testing as prototyped for towards paper. Also discuss property-based testing as explored in the SIR (time-driven) and Sugarscape (event-driven) case.

\section{SIR: Explanatory Model Testing}
\paragraph{Finding optimal $\Delta t$}
The selection of the right $\Delta t$ can be quite difficult in FRP because we have to make assumptions about the system a priori. One could just play it safe with a very conservative, small $\Delta t < 0.1$ but the smaller $\Delta t$, the lower the performance as it multiplies the number of steps to calculate. Obviously one wants to select the \textit{optimal} $\Delta t$, which in the case of ABS is the largest possible $\Delta t$ for which we still get the correct simulation dynamics.
To find out the \textit{optimal} $\Delta t$ one can make direct use of the black-box tests: start with a large $\Delta t = 1.0$ and reduce it by half every time the tests fail until no more tests fail - if for $\Delta t = 1.0$ tests already pass, increasing it may be an option. It is important to note that although isolated agent behaviour tests might result in larger $\Delta t$, in the end when they are run in the aggregate system, one needs to sample the whole system with the smallest $\Delta t$ found amongst all tests. Another option would be to apply super-sampling to just the parts which need a very small $\Delta t$ but this is out of scope of this paper.

\paragraph{Agents as signals}
Agents \textit{might} behave as signals in FRP which means that their behaviour is completely determined by the passing of time: they only change when time changes thus if they are a signal they should stay constant if time stays constant. This means that they should not change in case one is sampling the system with $\Delta t = 0$. Of course to prove whether this will \textit{always} be the case is strictly speaking impossible with a black-box verification but we can gain a good level of confidence with them also because we are staying pure. It is only through white-box verification that we can really guarantee and prove this property.

\paragraph{Black-Box Verification}
The interface of the agent behaviours are defined below. When running the SF with a given $\Delta t$ one has to feed in the state of all the other agents as input and the agent outputs its state it is after this $\Delta t$.

\begin{HaskellCode}
data SIRState 
  = Susceptible 
  | Infected 
  | Recovered
  
type SIRAgent = SF [SIRState] SIRState

susceptibleAgent :: RandomGen g => g -> SIRAgent
infectedAgent :: RandomGen g => g -> SIRAgent
recoveredAgent :: SIRAgent
\end{HaskellCode}

\paragraph{Finding optimal $\Delta t$}
Obviously the \textit{optimal} $\Delta t$ of the SIR model depends heavily on the model parameters: contact rate $\beta$ and illness duration $\delta$. We fixed them in our tests to be $\beta = 5$ and $\delta = 15$. By using the isolated behaviour tests we found an optimal $\Delta t = 0.125$ for the susceptible behaviour and $\Delta t = 0.25$ for the infected behaviour. %TODO: dynamics comparison?

\paragraph{Agents as signals}
Our SIR agents \textit{are} signals due to the underlying continuous nature of the analytical SIR model and to some extent we can guarantee this through black-box testing. For this we write tests for each individual behaviour as previously but instead of checking whether agents got infected or have recovered we assume that they stay constant: they will output always the same state when sampling the system with $\Delta t = 0$. The tests are conceptual the complementary tests of the previous behaviour tests so in conjunction with them we can assume to some extent that agents are signals. To prove it, we need to look into white-box verification as we cannot make guarantees about properties which should hold \textit{forever} in a computational setting.

\paragraph{Recovered Behaviour}
The implementation of the recovered behaviour is as follows:

\begin{HaskellCode}
recoveredAgent :: SIRAgent
recoveredAgent = arr (const Recovered)
\end{HaskellCode}

Just by looking at the type we can guarantee the following:
\begin{itemize}
	\item it is pure, no side-effects of any kind can occur
	\item no stochasticity possible because no RNG is fed in / we don't run in the random monad
\end{itemize}

The implementation is as concise as it can get and we can reason that it is indeed a correct implementation of the recovered specification: we lift the constant function which returns the Recovered state into an arrow. Per definition and by looking at the implementation, the constant function ignores its input and returns always the same value. This is exactly the behaviour which we need for the recovered agent. Thus we can reason that the recovered agent will return Recovered \textit{forever} which means our implementation is indeed correct.

Because we use multiple replications in combination with QuickCheck obviously results in longer test-runs (about 5 minutes on my machine) In our implementation we utilized the FRP paradigm. It seems that functional programming and FRP allow extremely easy testing of individual agent behaviour because FP and FRP compose extremely well which in turn means that there are no global dependencies as e.g. in OOP where we have to be very careful to clean up the system after each test - this is not an issue at all in our \textit{pure} approach to ABS.

\paragraph{Simulation Dynamics}
We won't go into the details of comparing the dynamics of an ABS to an analytical solution, that has been done already by \cite{macal_agent-based_2010}. What is important is to note that population-size matters: different population-size results in slightly different dynamics in SD => need same population size in ABS (probably...?). Note that it is utterly difficult to compare the dynamics of an ABS to the one of a SD approach as ABS dynamics are stochastic which explore a much wider spectrum of dynamics e.g. it could be the case, that the infected agent recovers without having infected any other agent, which would lead to an extreme mismatch to the SD approach but is absolutely a valid dynamic in the case of an ABS. The question is then rather if and how far those two are \textit{really} comparable as it seems that the ABS is a more powerful system which presents many more paths through the dynamics.
%TODO: i really want to solve this for the SIR approach
%	-> confidence intervals?
%	-> NMSE?
%	-> does it even make sense?

\paragraph{White-Box Verification}
%TODO: the implementation below has a SEVERE bug, all stochastic functions are correlated because they use the same RNG. this leads to different distributions of the dynamics, which can be shown using the test-code which generates the dynamics. The random monad version seems to perform much better where the mean is very close to the SD solution.

In the case of the SIR model we have the following invariants: 
\begin{itemize}
	\item A susceptible agent will \textit{never} make the transition to recovered.
	\item An infected agent will \textit{never} make the transition to susceptible.
	\item A recovered agent will \textit{forever} stay recovered.
\end{itemize}

All these invariants can be guaranteed when reasoning about the code. An additional help will be then coverage testing with which we can show that an infected agent never returns susceptible, and a susceptible agent never returned infected given all of their functionality was covered which has to imply that it can never occur!

%Lets start with looking at the recovered behaviour as it is the simplest one. We then continue with the infected behaviour and end with the susceptible behaviour as it is the most complex one.

We will only look at the recovered behaviour as it is the simplest one. We leave the susceptible and infected behaviours for further research / the final thesis because the conceptual idea becomes clear from looking at the recovered agent.

\section{Sugarsape: Explanatory Model Testing}
We implemented a number of tests for agent functions which just cover the part of an agents behaviour: checks whether an agent has died of age or starved to death, the metabolism, immunisation step, check if an agent is a potential borrower or fertile, lookout, trading transaction. What all these functions have in common is that they are not pure computations like utility functions but require an agent-continuation which means they have access to the agent state, environment and random-number stream. This allows testing to capture the \textit{complete} system state in one location, which allows the checking of much more invariants than in approaches which have implicit side-effects.

We implement custom data-generators for the agents and let QuickCheck generate the random data and us running the agent with the provided data, checking for the properties. An example for such a property is that an agent has starved to death in case its sugar (or spice) level has dropped to 0. The corresponding property-test generates a random agent state and also a random sugar level which we set in the agent state. We then run the function which returns True in case the agent has starved to death. We can then check that this flag is true only if the initial random sugar level was less then or equal 0.

What is particularly powerful is that one has complete control and insight over the changed state before and after e.g. a function was called on an agent: thus it is very easy to check if the function just tested has changed the agent-state itself or the environment: the new environment is returned after running the agent and can be checked for equality of the initial one - if the environments are not the same, one simply lets the test fail. This behaviour is very hard to emulate in OOP because one can not exclude side-effect at compile time, which means that some implicit data-change might slip away unnoticed. In FP we get this for free.

\subsection{Agent-Interactions}
PropABS future research http://www.well-typed.com/blog/2019/01/qsm-in-depth/ with quickcheck-state-machine

\section{Discussion}
There is a strong relation between property-based tests and dependent types: in property-based testing we express specifications / properties / laws in code and test their invariance at run-time by random sampling the space. In dependent-types it is possible to express such properties already statically in types. This is the subject of the next part of the thesis which tries to move towards dependent types in ABS.