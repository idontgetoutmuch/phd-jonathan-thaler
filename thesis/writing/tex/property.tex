\chapter{Property-Based Testing in ABS}
\label{ch:property}

When implementing an Agent-Based Simulation (ABS) it is of fundamental importance that the implementation is correct up to some specification and that this specification matches the real world in some way. This process is called verification and validation (V\&V), where \textit{validation} is the process of ensuring that a model or specification is sufficiently accurate for the purpose at hand whereas \textit{verification} is the process of ensuring that the model design has been transformed into a computer model with sufficient accuracy \cite{robinson_simulation:_2014}. In other words, validation determines if we are we building the \textit{right model} and verification if we are building the \textit{model right} \cite{balci_verification_1998}.

% there is no general validity, an approach is TDD: V&V particularly difficult in ABS
One can argue that ABS should require more rigorous programming standards than other computer simulations \cite{polhill_ghost_2005}. Because researchers in ABS look for an emergent behaviour in the dynamics of the simulation, they are always tempted to look for some surprising behaviour and expect something unexpected from their simulation. 
Also, due to ABS mostly \textit{exploratory nature} \cite{epstein_chapter_2006, epstein_generative_2012}, there exists some amount of uncertainty about the dynamics the simulation will produce before running it. The authors \cite{ormerod_validation_2006} see the current process of building ABS as a discovery process where often models of an ABS lack an analytical solution (in general) which makes verification much harder if there is no such solution. Thus it is often very difficult to judge whether an unexpected outcome can be attributed to the model or has in fact its roots in a subtle programming error \cite{galan_errors_2009}.

In general this implies that it is not possible to prove that a model is valid in general but that the best we can do is to \textit{raise the confidence} in the correctness of the simulation. Therefore, the process of V\&V is not the proof that a model is correct but the \textit{process} of trying to show that the model is not incorrect. The more checks one carries out which show that it is not incorrect, the more confidence we can place on the models validity. To tackle such a problem in software, software engineers have developed the concept of test-driven development (TDD).

Test-Driven Development (TDD) was rediscovered in the early 00s by Kent Beck \cite{beck_test_2002} as a way to a more agile approach to software-engineering, where instead of doing each step (requirements, implementation, testing,...) as separated from each other, all of them are combined in shorter cycles. Put shortly, in TDD tests are written for each feature before actually implementing it, then the feature is fully implemented and the tests for it should pass. This cycle is repeated until the implementation of all requirements has finished. Traditionally TDD relies on so called unit-tests which can be understood as a piece of code which when run isolated, tests some functionality of an implementation. Thus we can say that test-driven development in general and unit-testing together with code-coverage in particular, guarantee the correctness of an implementation to some informal degree, which has been proven to be sufficiently enough through years of practice in the software industry all over the world. 

\medskip

% the gap 
In this chapter we introduce and discuss property-based testing, a complementary method for testing the implementation of an ABS. It allows the direct expression of model-specifications and laws in code and test them through \textit{automated} and \textit{randomised} test-data generation. We see it as an addition to TDD where it works in combination with unit-testing to verify and validate a simulation to increase the confidence in its correctness and is a useful tool for expressing regression tests. To our best knowledge property-based testing has never been looked at in the context of ABS and this thesis is the first one to do so.

Property-based testing has its origins \cite{claessen_quickcheck_2000,claessen_testing_2002,runciman_smallcheck_2008} in Haskell where it was first conceived and implemented. It has been successfully used for testing Haskell code for years and also been proven to be useful in the industry \cite{hughes_quickcheck_2007}.

A central hypothesis of this thesis is that due to ABS \textit{stochastic} and \textit{exploratory / generative / constructive } nature, property-based testing is a natural fit for testing ABS in general and pure functional ABS implementations in particular and a valuable addition to the already existing testing methods in this field. To substantiate and test our hypothesis, we present two case-studies. First, the agent-based SIR model as introduced in Chapter \ref{sec:sir_model}, which is of explanatory nature, where we show how to express formal model-specifications in property-tests. Second, the SugarScape model as introduced in Chapter \ref{sec:sugarscape}, which is of exploratory nature, where we show how to express hypotheses in property-tests and how to property-test agent functionality. 

TODO read / watch
% https://hackage.haskell.org/package/quickcheck-state-machine
% https://iohk.io/blog/an-in-depth-look-at-quickcheck-state-machine/
% https://www.stackbuilders.com/news/types-versus-tests-two-approaches-for-writing-correct-software
% https://blog.ploeh.dk/2019/03/11/an-example-of-state-based-testing-in-haskell/
% https://www.youtube.com/watch?v=NcJOiQlzlXQ

\input{./tex/property/verification.tex}

\input{./tex/property/proptesting.tex}

\input{./tex/property/explanatory.tex}

\input{./tex/property/exploratory.tex}

\input{./tex/property/discussion.tex}