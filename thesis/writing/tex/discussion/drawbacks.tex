\section{Drawbacks}
\label{sec:drawbacks}
The initially hypothesised drawbacks of performance issues and agent interaction were confirmed in our research. We discuss them here more in detail, together with other drawbacks and propose solutions where applicable.

\subsection{Efficiency}
\label{sec:drawback_efficiency}
As mentioned already in the discussions of the respective chapters, currently the performance of our approaches does not come close to imperative implementations. There are two main reasons for it: First, functional programming is known for being slower due to higher levels of abstraction, which are bought by slower code in general and second, updates are the main bottleneck due to immutable data requiring to copying of the whole or subparts of a data structure in cases of a change. The first one is easily addressable through the use of data parallelism and concurrency as shown in Chapter \ref{ch:parallelism_ABS} and \ref{ch:concurrent_abs}. The second reason could potentially be addressed by the use of linear types \cite{bernardy_linear_2017}, which allow to annotate a variable with how often it is used within a function. From this a compiler could derive aggressive optimisations, potentially resulting in imperative-style performance but retaining the declarative nature of the code. We leave this for further research. Also, the use of Monad Transformer stacks has performance implications, which can be quite subtle. A possible optimisation we followed is the careful usage and reordering of lifts, using \texttt{lift (mapM ...)} instead of \texttt{mapM (lift ...)}, which potentially results in increased performance.

However, it was shown by various people \cite{kqr_competing_2017, stewart_haskell_2008, stolarek_haskell_2013} that Haskell does not necessarily have to be slow and that it is indeed possible to reach C speed in Haskell. The direction to do this is using the worker/wrapper transformation \cite{gill_worker/wrapper_2009}, a clever combination of techniques with strict \texttt{foldl'} and data declaration with strictness annotation instead of lazy tuples and Stream Fusion \cite{coutts_stream_2007, mainland_haskell_2013}. The problem is, of course, that to apply these techniques one needs to have deep knowledge of Haskell and its subtle details of lazy evaluation, making this a highly non-trivial task. Another problem is that those techniques seem only applicable in the context of a tight loop, which crunches numbers of a list, thus it is not directly applicable in our case as we are clearly bound by the effectful computations: MSF and Monad Transformers are the limiting factor, not inner loops.

Concluding we can say that the current performance makes our approach not very attractive for real-world use \textit{at the moment}. Also, the fact that the sequential object-oriented implementation of the SIR model seems to outperform the concurrent and parallel implementations as well, seems to question our motivation as to why we are using pure functional programming and parallel computation at all. Still, the bad performance results do not invalidate our research, as this thesis aim is not the development of high-performance pure functional implementations, but rather exploring concepts of ABS in pure functional programming. Thus, this work is seen as a first step which needs to be developed further into something to be used in the real world. We hypothesise that it should be possible for our pure functional approach to come considerably closer to imperative performance, ultimately making it more applicable for real-world usage. We leave a deeper investigation of this problem for further research.

\subsection{Space Leaks}
Haskell is notorious for its memory leaks due to lazy evaluation: data is only evaluated when required. Even for simple programs, one can be hit hard by a serious space leak where thunks - unevaluated code pieces - build up in memory until they are needed, leading to dramatically increased memory usage. It is no surprise that our highly complex Sugarscape implementation initially suffered severely from space leaks, accumulating about 40 MBytes/second. In simulation this is a big issue, threatening the value of the whole implementation despite its other benefits. Due to the fact that simulations might run for a (very) long time or conceptually forever, one must make absolutely sure that the memory usage stays within reasonable bounds. As a remedy, Haskell allows us to add so-called strictness pragmas to code modules, which force strict evaluation of all data even if it is not used. %Carefully adding this conservatively, file-by-file applying other techniques of forcing evaluation removed most of the memory leaks.

Another memory leak was caused by selecting the wrong data structure for the environment, for which we initially used an immutable array. The problem is that in the case of an update the whole array is copied, causing memory leaks \textit{and} a performance problem. We replaced it by an \texttt{IntMap} which uses integers as key and is internally implemented as a radix tree which allows for very fast lookups and inserts because whole sub-trees can be reused.

\subsection{Agent Interactions}
Synchronous, direct agent interactions \textit{do} work in Haskell but they are cumbersome to get right when building from scratch. Furthermore, as we pointed out in Chapter \ref{ch:concurrent_abs}, it seems that our approach to synchronous direct agent interactions is not applicable to concurrency with STM. 

This leads to the fundamental conclusion that in models which require complex agent interactions in a potentially concurrent environment, we are hitting the limits of our pure functional approach. The reason for it is that we have a conceptual mismatch, as in such a setting, agents are more naturally represented using the Actor Model. The Actor Model, a model of concurrency, was initially conceived by Hewitt in 1973 \cite{hewitt_universal_1973} and refined later on \cite{hewitt_what_2007}, \cite{hewitt_actor_2010}. It was a major influence in designing the concept of agents and although there are important differences between actors and agents there are important similarities, thus the idea to use actors to build ABS comes quite natural.
An actor is a uniquely addressable entity which can do the following \textit{in response to a message}:
\begin{itemize}
	\item Send an arbitrary number of messages to other actors.
	\item Create an arbitrary number of actors.
	\item Define its own behaviour upon reception of the next message.
\end{itemize}

When comparing this definition to the one of agents we give in Chapter \ref{sec:method_abs}, it is clear that the Actor Model was quite influential to the development of the concept of agents in ABS, which borrowed it initially from Multi-Agent Systems \cite{wooldridge_introduction_2009}. Technically, it emphasises message-passing concurrency with shared-nothing semantics (no implicitly shared state through side effects between agents), which maps nicely to functional programming concepts.

Indeed, the programming model of actors \cite{agha_actors:_1986} was the inspiration for the functional programming language Erlang, thus we argue that a true concurrent actor approach like Erlang is substantially more natural and much more performant especially in a concurrent setting. Furthermore, we hypothesise that actor based ABS implementations might have a bright future as ABS tends to develop towards larger and larger, distributed, always-online simulations, for which Erlang is arguably perfectly suited. We have prototyped highly promising concurrent event-driven SIR and Sugarscape implementations in Erlang supporting our hypothesis. However, an in-depth discussion is beyond the scope of this thesis and we leave this topic for further research.

%This makes testing easier and also opens the way for property-based testing which is available in Erlang as well where it even allows to detect race conditions \cite{claessen_finding_2009}. 

%erlang processes can implement everything objects can but in a referential transparent and pure functional way: encapsulation, polymorphism, identity, message passing, even inheritance (which you wouldnt want to do)

%difference of erlang to objects is that although it encapsulate state it cannot be accessed at the same time but only through the message passing Interface with one message at a time. this means that state is not really shared and protected against mutation - the process is in full control. it is simply a function which captures the full state of the process in an immutable way: to change the state a recursive call needs to be done. so in the end although it seems conceptually related its technically difference is fundamental importance.

%my mistake was to confuse the concept of objects with their implementation. i was too focused on the drawbacks of e.g. java objects that i forgot that i was critisising its IMPLEMENTATION. the Original idea of alan kays objects IS a deep and strong idea, though it differes substantially from java objects, erlang comes closest. thus the concept is important and valid but different implementations have different benefits and drawbacks. 

\subsection{Productivity and Learning Curve}
A case study in \cite{hanenberg_experiment_2010} hints that simply by switching to a static type system alone does not gain anything and can even be detrimental. To be useful, it needs to have a certain level of abstractions like Haskells' type system. Although such case studies have to be taken with care, there is also some truth in it: working in a statically strong type system prevents the developer from moving quickly and making quick changes. This can be both a benefit and a drawback: in general, it prevents one from breaking changes which show up at compile time. At the same time, the whole program is much more rigid and a proper structure needs to be thought out and designed often up-front, slowing down the process. However, it is a contribution of this thesis that it outlines exactly these structures within ABS, so that implementers who want to use the same approach do not have to reinvent the wheel.

A more severe problem is that pure functional programming, especially Haskell, is regarded as hard to learn with a steep learning curve, putting a high barrier to implementers picking up a pure functional approach to ABS. Thus, the lack of broad availability of Haskell expertise can be enough to pose a serious drawback even if the approach of this thesis seems to be desirable in a project.