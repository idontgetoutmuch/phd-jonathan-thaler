\section{The Gintis case revisited}
\label{sec:gintis_case} 
After having discussed all the benefits and drawbacks pure functional programming has to offer for ABS, we want to return to the Introduction chapter again, where we mentioned the work of Gintis \cite{gintis_emergence_2006}. To repeat, in this paper the author has claimed to have found a mechanism in bilateral decentralized exchange, which resulted in Walrasian General Equilibrium without the neo-classical approach of a tatonement process through a central auctioneer. Due to its high-impact result for economics, researchers \cite{ionescu_dependently-typed_2012} tried to reproduce the results independently but were not able to do so. After Gintis provided the code, it was found that there was a bug in his implementation which led to the unexpected results, which were seriously damaged through this error. The work of \cite{evensen_extensible_2010} investigated the specific nature of Gintis bugs and reported the following (Section \textit{3.1.1  Deviations from the paper}, page 23):

\begin{enumerate}
	\item An agent calculates the optimum inventory (or demand) according to a specific formula, which involves a factor $\lambda$ which gets computed as $\lambda = \frac{\sum_{j}{} p_{ij}x_{ij}}{\sum_{j}{} p_{ij}x_{ij}}$. What the specific computation denotes is not important here, what is important is that this computation is always 1. The authors \cite{evensen_extensible_2010} claim that the correct formula should have been: $\lambda = \frac{\sum_{j}{} p_{ij}x_{ij}}{\sum_{j}{} p_{ij}o_{j}}$ with \textit{o} in the denominator instead of \textit{x}. 
	
	\item There seems to be a discrepancy between the paper and the implementation describing the trading of agents. According to the paper the amount they exchange follows $x_{ig} \equiv \frac{p_{ig}x_{ig}}{p_{ih}}$. In the implementation however, Gintis uses $x_{ig} \equiv \frac{p_{ih}x_{ih}}{p_{ig}}$ but seems to do so inconsistently throughout his code, leading to wrong calculations.
	
	\item Another bug was due to reversed ordering of events, where agents use old prices vectors due to missing recalculation which only happens in the next step.

	\item There are a number of other subtle bugs, which, according to the authors \cite{evensen_extensible_2010} seemed to have no impact on the outcome of the simulation: slight miscalculation of the standard deviation for consumer and producer prices, crashing the program at runtime when dividing the agents unequally between different production goods due to a negative random number which in turn raises an exception in the Delphi random function.
\end{enumerate}

After having hypothesised in the Introduction chapter that pure functional programming might be of help in implementing simulations which are more likely to be correct, the following questions arise:

\paragraph{Do the techniques introduced in this thesis transfer to this problem and model as well?}
The short answer is, yes they obviously do as Gintis models interacting individual agents which consume and produce and trade with each other. This could be implemented both with our time- and event-driven approach, with a better choice probably being the event-driven one due to agents directly trading with each other. However, for some models, our techniques introduced in Chapters \ref{ch:timedriven} and \ref{ch:eventdriven} are too powerful and a much simpler approach would suffice to implement it. In general too much power should always be avoided (at least in programming and software engineering) because with much power comes much responsibility: more power requires to pay more attention to details and thus there is increased risk to make mistakes. Thus we should always look for the technique with minimal power but maximum abstraction, which solves our problem sufficiently. Gintis model is such an example: it resides in a very different domain of ABS, called Agent-Based Computational Economics (ACE).

ACE is a very important field, which picked up ABS as a method for research in recent years. The field of economics is an immensely vast and complex one with many facets to it, ranging from firms, to financial markets to whole economies of a country \cite{bowles_understanding_2005}. Today its very foundations rest on rational expectations, optimization and the efficient market hypothesis. The idea is that the macroeconomics are explained by the micro foundations \cite{colell_microeconomic_1995} defined through behaviour of individual agents. These agents are characterised by rational expectations, optimizing behaviour, having perfect information, equilibrium \cite{focardi_is_2015}.
This approach to economics has come under heavy criticism in the last years for being not realistic, making impossible assumptions like perfect information, not being able to provide a process under which equilibrium is reached \cite{kirman_complex_2010} and failing to predict crashes like the sub-prime mortgage crisis despite all the promises - the science of economics is perceived to be detached from reality \cite{focardi_is_2015}. 
ACE is a promise to repair the empirical deficit which (neo-classic) economics seem to exhibit by allowing to make more realistic, empirical assumptions about the agents which form the micro foundations. The ACE agents are characterised by bounded rationality, local information, restricted interactions over networks and out-of-equilibrium behaviour \cite{farmer_economy_2009}. 
Works which investigate ACE as a discipline and discuss its methodology are \cite{ballot_agent-based_2015,blume_introduction_2015,richiardi_agent-based_2007,tesfatsion_agent-based_2006}.
Tesfatsion \cite{tesfatsion_agent-based_2017} defines ACE as \textit{[...] computational modelling of economic processes (including whole economies) as open-ended dynamic systems of interacting agents.}. 

It is important to understand, that ACE utilises ABS different than the social sciences do. The latter one focuses more on agent interactions, as it is apparent in the Sugarscape model, where in ACE the rational and non-rational actions of individual agents are more important. Thus in many ACE models, the full power of the techniques introduced in Chapters \ref{ch:timedriven} and \ref{ch:eventdriven} is not required. More specifically, agents of ACE models tend to have much simpler state, behave often in only one specific way, don't use synchronised direct agent interactions and are very rarely located in a spatial environment but focus more on network connections \cite{glasserman_contagion_2015,wilhite_economic_2006} or avoid the notion of connectivity altogether. This is certainly the fact in the case of the Gintis model, as implemented by Gintis himself and the Java implementation of \cite{evensen_extensible_2010}: 

\begin{itemize}
	\item Even though it is an agent-based model and there is a clear notion of agents in the code, where they are represented as objects, the agents are very simple in terms of their structure. They are characterised by a few floating-point values with very simple behaviour that does not change over time.

	\item There are only very simple direct agent interactions, exchanging bids and asks, leading to an exchange.

	\item There is no environment whatsoever and a fully connected network is implicitly assumed because each agent can trade with all other agents.
	
	\item The only side effect necessary in this simulation is to draw random numbers.
\end{itemize}

Thus, a Haskell implementation in this domain can be achieved completely without the full force of our techniques: agents can be represented as simple data structures without SF or MSF, interactions handled by the kernel, no need for an environment, scheduling is handled directly by the kernel and side effects are restricted to run in the \texttt{Rand} Monad only. Due to the substantial complexity of the Gintis model, we have refrained from attempting a full implementation of it in Haskell. However, to investigate this point more in depth we implemented a \href{https://github.com/thalerjonathan/zerointelligence}{simulation}~\cite{thaler_zerointelligence_repository} with so called Zero Intelligence traders \cite{gode_allocative_1993}, a well known and fundamental concept found in ACE. Our implementation was inspired by an implementation in Python by LeBaron \cite{lebaron_zerointelligence} and is a satisfactory proof-of-concept underlining the fact that we can do pure functional ABS also in a robust way without the full power offered by our techniques. However, a full treatment of this is beyond the scope of this thesis and is left for further research.

\paragraph{Would the use of Haskell have prevented the bugs which Gintis made?}
The first and second bugs as reported above are an indication for a problematic use of indexed lists or arrays. Generally, one can say that independent of programming languages, indices into an array or list are \textit{always} problematic because it is very easy to make very subtle mistakes by getting indices wrong. Pure functional programming would suffer the same problem \textit{if} a similar technique would have been used. However, due to the fact that data in Haskell is immutable, an \textit{idiomatic} implementation, following pure functional programming concepts, we would have probably not seen the use of lists but (Generalised) Algebraic Data Types, making this kind of bug much less likely. Further, due to the \textit{declarative} nature of pure functional programming in Haskell, it is more likely that the implementer, reading through the existing code might have spotted the bug: there is much less noise in an idiomatic functional implementation than in imperative code, making code highly expressive and concise, thus less to read and more obvious.

The third bug is a very subtle logical error, regarding the semantics of the simulation. A pure functional implementation alone would not have helped avoiding this mistake. However, we think the declarative style and immutability of data in pure functional programming would have made the fact that an old version of data is used much more explicit thus we think it would have been easier to spot.

The last bugs are typical run-time errors, which would and do occur in Haskell as well, so a pure functional approach would not necessarily avoid these kind of bugs. However, such bugs can be avoided by using a dependently typed functional language like Idris \cite{brady_idris_2013} as such a type system allows to ensure in the types that only positive random numbers are drawn, and that the input ranges are strictly positive.

Thus, summarizing we hypothesise that with a clean and \textit{idiomatic} pure functional implementation it would have been very likely that Gintis would have avoided or spot the bugs. Further, we claim that dependent types might have been of substantial benefit in the Gintis case, but we leave this for further research as it is beyond the scope of this thesis. %(see Appendix \ref{app:equilibrium_totality}).

\paragraph{Would property-based tests have been of any help to prevent the bugs?}
We hypothesise that it is very likely that if Gintis would have applied rigorous unit and property-based testing to his model - which he should have, due to the high impact of his outcome - he would have found the inconsistencies and could have corrected them. The code of \cite{evensen_extensible_2010} contains numerous \textit{checkInvariants} and assertions, which \textit{are} properties expressed in code, thus immediately applicable to property-based testing. Further, due to the mathematical nature of the problem, many properties in the form of formulas can be found in the paper specification, which should be directly expressible using property-based and unit testing.