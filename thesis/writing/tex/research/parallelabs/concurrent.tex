\chapter{Concurrency in ABS}
\label{ch:concurrent_abs}
In an ideal world, we would like to solve all our problems using parallelism but unfortunately, it can't be applied to all parallel problems and ABS is no exception. As soon as there are data dependencies we cannot avoid concurrency. This problem can be seen in the Sugarscape model, in the form of the mutable environment and synchronous agent interactions, and to a lesser extent in the monadic SIR with the \texttt{Rand} Monad. More generally, this issue is due to the fact that agents are executed within a monadic context, from which the  sequencing of effectful computations immediately follows. This is the very meaning of the Monad abstraction. Indeed, we have shown, both by argument and measurement in the previous chapter, the very fact that parallelism is simply not applicable to monadic execution of agents due to sequencing of effects. This fact renders all attempts of running monadic agents in parallel void. In this chapter we discuss the use of concurrency to run agents with a monadic context in parallel, which is the only way we can execute monadic agents at the same time.

\medskip

Traditional approaches to concurrency follow a lock-based approach, where sections which access shared data are synchronised through synchronisation primitives like mutexes, semaphores or monitors. However, with the established programming languages in the field, Python, Java and C++, it is not easy to address the complexities of parallel programming due to unrestricted side effects and the intricacies of low-level locking semantics. Therefore, in this chapter we follow a different path and look into using Software Transactional Memory (STM) for implementing concurrent ABS, which promises to overcome the problems of lock-based approaches. We hypothesise that by using STM in Haskell, implementing local parallel ABS is considerably easier than with lock-based approaches, less error prone and easier to validate.

Our hypothesis is supported by \cite{discolo_lock_2006}, which gives a good indication as to how difficult and complex constructing a correct concurrent program can be. In addition, \cite{discolo_lock_2006} shows how much easier, concise and less error prone an STM implementation is over traditional locking with mutexes and semaphores. More importantly, it indicates that STM consistently outperforms the lock-based implementations. We follow this work and compare the performance of lock-based and STM implementations and hypothesise that the reduced complexity and increased performance will be directly applicable to ABS as well.

The idea of applying transactional memory to simulation was already explored in the work \cite{hay_experiments_2015}, where the authors looked into how to apply Intelâ€™s \textit{hardware} transactional memory to simulations in the context of a Time Warp Parallel Discrete Event Simulation (PDES). The results showed that their approach generally outperformed traditional locking mechanisms. Although PDES is a different problem than ABS, they are related as both deal with events (in case of an event-driven ABS) and PDES has been successfully adopted to simulate parallel ABS \cite{suryanarayanan_pdes-mas_2013}.

To test our hypothesis, we present two case studies using the already introduced SIR (Chapter \ref{sec:sir_model}) and Sugarscape (Chapter \ref{sec:sugarscape}) models. We compare the performance of lock-based and STM implementations in each case where we investigate both the scaling performance under increasing number of CPU cores and agents. We show that the STM implementations consistently outperform the lock-based ones and scale much better to increasing number of CPU cores both on local hardware and on Amazon EC services.

Unfortunately, as soon as we employ concurrency, we lose all static guarantees about reproducibility and the use of STM is no exception. With reproducibility we mean the property of a simulation, that when executed repeatedly with identical initial conditions, will always yield the same result. This guarantee is lost with the use of STM due to potentially non-deterministic order of execution of code as expressed in the definition of concurrency in Chapter \ref{ch:parallel_abs}. Still, STM has the unique benefit that it can guarantee a lack of persistent side effects at compile time, allowing unproblematic retries of transactions, something of fundamental importance in STM as will be described below. This also implies another \textit{very} compelling advantage of STM over unrestricted lock-based approaches. By using STM, we can reduce the side effects allowed substantially and guarantee at compile time, that the differences between runs of same initial conditions will only stem from the fact that we run the simulation concurrently, \textit{and from nothing else}. All this makes the use of STM very compelling and to our best knowledge we are the very first to investigate the use of STM for implementing concurrent ABS in a systematic way.

\input{./tex/research/parallelabs/concurrent/stm.tex}

\input{./tex/research/parallelabs/concurrent/stmabs.tex}

\input{./tex/research/parallelabs/concurrent/sir.tex}

\input{./tex/research/parallelabs/concurrent/sugarscape.tex}

\input{./tex/research/parallelabs/concurrent/discussion.tex}