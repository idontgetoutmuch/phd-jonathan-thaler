\section{Discussion}
Our FRP based approach is different from traditional approaches in the ABS community. First it builds on the already quite powerful FRP paradigm. Second, due to our continuous time approach, it forces one to think properly of the time semantics of the model and what the correct $\Delta t$ should be. Third, it requires one to think about agent interactions in a new way instead of being just method calls as in object-oriented programming. Thus, the result of using FRP allows for the expression of continuous time semantics in a very clear, compositional and declarative way, abstracting away the low-level details of time stepping and progress of time within an agent.

\subsection{Static Guarantees}
Because no part of the simulation runs in the \texttt{IO} Monad and we do not use \texttt{unsafePerformIO} we can rule out a serious class of bugs caused by implicit data dependencies and side effects, which can occur in traditional imperative implementations.

Our approach can guarantee reproducibility already at compile time, which means that repeated runs of the simulation with the same initial conditions will always result in the same dynamics. This scenario is something highly desirable in simulation in general. Although we allow side effects within agents, we restrict them to the \texttt{Rand} Monad in a controlled, deterministic way and never use the \texttt{IO} Monad, which guarantees the absence of non-deterministic side effects within the agents and other parts of the simulation. This proves that this implementation is indeed \textit{pure} computation. This can only be achieved through purity, which guarantees the absence of implicit side effects. This allows for ruling out non-deterministic influences at compile time through the strong static type system, something which is not possible with traditional object-oriented approaches.

Determinism is also ensured by fixing the $\Delta t$ and not making it dependent on the performance of a rendering loop or other system dependent sources of non-determinism as described by \cite{perez_testing_2017}. Additionally, by using FRP we gain all the benefits from it and can use research on testing, debugging and exploring FRP systems \cite{perez_back_2017,perez_testing_2017}.

Moreover, we show how to implement the \textit{parallel} update strategy \cite{thaler_art_2017} in a way that the correct semantics are enforced and guaranteed already at compile time through correct types. Using pure functional programming, we can enforce the correct semantics of agent execution through types where we demonstrate that this allows us to have both, sequential monadic behaviour, and agents acting \textit{conceptually} at the same time in lock-step. This is not possible in traditional imperative implementations and poses another unique benefit for the use of functional programming in ABS.

\subsection{Drawbacks}
Despite the strengths and benefits we get by leveraging on FRP, there are errors that are not raised at compile time. For example, we can still have infinite loops and run-time errors. This was investigated in \cite{sculthorpe_safe_2009} where the authors use dependent types to avoid some run-time errors in FRP. We propose that one could go further and develop a domain specific type system for FRP that makes the FRP-based ABS more predictable, supporting further mathematical analysis of its properties. Furthermore, moving to dependent types would pose a unique benefit over the traditional object-oriented approach and should allow us to express and guarantee even more properties at compile time. We leave this for further research.

In our pure functional approach, agent identity is not as clear as in traditional object-oriented programming, where there is a quite clear concept of object-identity through the encapsulation of data and methods. Signal functions don't offer this strong identity, and one needs to build additional identity mechanisms on top. An example would be when sending messages to specific agents as will be shown in the next chapter.

We can conclude that the main difficulty of a pure functional approach evolves around the communication and interaction between agents, which is a direct consequence of the issue with agent identity. Agent interaction is straightforward in object-oriented programming, where it is achieved using method calls mutating the internal state of the agent. But, that comes at the cost of a new class of bugs due to implicit data flow. In pure functional programming these data flows are explicit but our current approach of feeding back the states of all agents as inputs is not very general. We address this problem in the next chapter.

\subsection{Performance}
\label{sub:timedriven_performance}
Currently, the performance of this approach does not come close to imperative implementations. We compared the performance of the time-driven SIR as presented in Section \ref{sec:adding_env} and measured in Chapter \ref{sec:concurrent_sir} to an implementation in Java using the ABS library RePast \cite{north_complex_2013}. The performance results make the lack of speed of our approach quite clear: the pure functional approach needs on average around 73.9 seconds whereas the Java RePast version with 8 runs averaged at just 10.8 seconds on our hardware to arrive at $t = 100$. It must be mentioned, that RePast does implement an event-driven approach to ABS, which can be much more effective \cite{meyer_event-driven_2014} than a time-driven one, so the comparison is not completely valid.

As an alternative performance indicator, we compared a time-driven SIR implementation in Java without RePast to the pure functional implementations of Chapter \ref{sec:timedriven_firststep} without the \texttt{Rand} Monad and the environment. In the Java implementations we tried to follow conceptually similar approaches to the pure functional implementations, but obviously that is not possible for every aspect. For example, we are not using any reactive programming library, but we follow a similar time-sampling approach. We ran the program for 150 time steps with 1,000 susceptible and 1 infected agents, $\beta = \frac{1}{5}$, $\gamma = 0.05$, $\delta = 15$ and $\Delta t = 0.01$. Moreover, we fixed the random-number generators to guarantee identical dynamics in every run and averaged 8 runs. The time-driven Java implementation averages at a performance of 0.5 seconds, compared to 27.6 seconds in Haskell.

We expect a substantial performance improvement when switching to an event-driven approach \cite{meyer_event-driven_2014} in Chapter \ref{ch:eventdriven}. Additionally, the performance issue will be addressed more in depth in the chapters on parallelism (Chapter \ref{ch:parallelism_ABS}) and concurrency (Chapter \ref{ch:concurrent_abs}).