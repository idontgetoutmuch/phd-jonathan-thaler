\subsection{Shared Mutable Proactive Environment}
In many agent-based models, agents are placed on a discrete 2D grid environment and can move around and interact with the environment. Often, there exist specific constraints. For example, that each position can only be occupied by one agent at most. This restriction requires specific iteration semantics, which make it impossible that two agents end up at the same time in the same spot. In general, such models solve this problem by using the sequential strategy as described in Chapter \ref{sec:seq_strategy}, where agents are run in random order, one after another. This allows the agents to access the globally shared, mutable environment exclusively when it is their turn and they interact and change it without the danger of other agents interfering.

To implement a shared, mutable and proactive environment, first we define a generic discrete 2D grid environment with polymorphic cells. The selection of the right data structure is crucial. Initially we used an \texttt{IArray} from the \href{http://hackage.haskell.org/package/array}{array library}~\cite{array_hackage}. This data structure has excellent read performance, but in performance tests we experienced serious performance and memory leak issues with updates. This issue lead to allocation of about 40 MByte per second on our hardware. Clearly this is unacceptable for simulation purposes, where software often runs for hours and requires memory consumption to stay within reasonable bounds. The solution was to switch to \texttt{IntMap} from the \href{http://hackage.haskell.org/package/containers}{container's library}~\cite{containers_library} as an underlying data structure which solved both the performance and memory leak issues.

\begin{HaskellCode}
type Discrete2dCoord  = (Int, Int)
type Discrete2dCell c = (Discrete2dCoord, c)
type Discrete2d c     = Map.IntMap (Discrete2dCell c)
\end{HaskellCode}

Having introduced the \texttt{AgentMSF} and fixed the \texttt{AgentMonad} with the \texttt{StateT ABSState} as the outermost Monad, adding a globally shared, mutable environment is straightforward. The solution is to simply add another \texttt{StateT} Transformer with the given environment as type. Below, we give the parametrised definition as in the Sugarscape implementation. Sugarscape closes the Monad stack with the \texttt{Rand} Monad as stochastics play an important role in the Sugarscape model as well. Therefore, a full expansion of the Monad stack used in Sugarscape is \texttt{StateT ABState (StateT SugEnvironment (Rand g))}.

\begin{HaskellCode}
data SugEnvSite = SugEnvSite 
  { sugEnvSiteSugarLevel    :: Double
  , sugEnvSiteSpiceLevel    :: Double
  , sugEnvSitePolutionLevel :: Double
  ...
  }

type SugEnvironment  = Discrete2d SugEnvSite
type SugAgentMonad g = AgentMonad (StateT SugEnvironment (Rand g))
\end{HaskellCode}

When implementing the proactivity of the environment, we must make a clear distinction between the environment's data structure, how agents access it, and the environment's behaviour. In the Sugarscape model, the behaviour of the environment is quite trivial, as it simply regrows resources over time and diffuses pollution in case the pollution is turned on. This behaviour is achieved by providing a pure function without any monadic context or \texttt{MSF}. This is not necessary because the environment, as we implement it, does not encapsulate local state and it does not interact with agents through messages and vice versa. Thus, a pure function of type \texttt{Time $\rightarrow$ SugEnvironment $\rightarrow$ SugEnvironment}, which maps the environment to the environment over time is enough for our purpose. It also takes the current simulation time so it can implement seasons, where the speed of regrowth of resources is different in different regions and swaps after some time. This function is called in the simulation kernel after every \texttt{Tick}.

\medskip

Generally, one can distinguish between four different types of environments in ABS:

\begin{enumerate}
	\item \textit{Passive Read Only} - Implemented in Chapter \ref{sec:adding_env}, where the environment itself is not modelled as an active process and is static information, for example, a list of neighbours, passed to each agent. The agents cannot change the environment actively and in the case of Chapter \ref{sec:adding_env}, this is enforced at compile time by simply making it read only, by including it in the input but not the output type of an agent. The agents change the environment implicitly by changing their state, but there is no notion of an active environment process.
	
	\item \textit{Passive Read and Write} - The environment is just shared data, which can be accessed and manipulated by the agents. This situation forces some arbitration mechanism to prevent conflicting updates. An example for preventing these updates would be running the agents sequentially one after the other, to ensure that only one agent has access at a time.
	
	\item \textit{Active Read and Write} - As implemented above. To make it active a pure function is used where the environment data is owned by the simulation kernel and then made available to the agents through a \texttt{State} Monad. Another approach would be to implement the environment process as an agent, which is run together with all the other agents. This allows the environment to send and receive messages but the guarantees about when the environment will be run is lost if agents are run sequentially in random order.
	
	\item \textit{Active Rad Only} - Can be implemented as above but instead of providing the environment data through a \texttt{State} Monad, a \texttt{Reader} Monad is used. The environment data is owned by the simulation kernel and the process runs as a pure function as before, but the data is provided in a read only way through the \texttt{Reader} Monad. The same can also be achieved by passing it as input only to the agent as was done in Chapter \ref{sec:adding_env}.
\end{enumerate}