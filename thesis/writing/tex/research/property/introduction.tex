\chapter{Property-Based Testing in ABS}
\label{ch:property}

When implementing an ABS, it is of fundamental importance that the implementation is correct up to some specification and that this specification matches the real world in some way. This process is called verification and validation (V\&V), where \textit{validation} is the process of ensuring that a model or specification is sufficiently accurate for the purpose at hand and \textit{verification} is the process of ensuring that the model design has been transformed into a computer model with sufficient accuracy \cite{robinson_simulation:_2014}. In other words, validation determines if we are building the \textit{right model} and verification determines if we are building the \textit{model right} up to some specification \cite{balci_verification_1998}.

One can argue that ABS should require more rigorous programming standards than other computer simulations \cite{polhill_ghost_2005}. Due to the fact that researchers in ABS are looking for an emergent behaviour in the dynamics of the simulation, they are always tempted to look for surprising behaviour and expect something unexpected from their simulation. 
Also, due to ABS's \textit{constructive} and \textit{exploratory} nature \cite{epstein_chapter_2006, epstein_generative_2012}, there exists some uncertainty about the dynamics that the simulation will produce before running it. The authors of \cite{ormerod_validation_2006} see the current process of building ABS as a discovery process, where models of an ABS often lack an analytical solution in general, which makes verification much harder if there is no such solution. Thus, it is often very difficult to judge whether an unexpected outcome can be attributed to the model, or has its roots in a subtle programming error \cite{galan_errors_2009}.

In general, this implies that in general it is not possible to prove that a model is valid but that the best we can do is to \textit{raise the confidence} in the correctness of the simulation. Therefore, the process of V\&V is not proving that a model is correct, but it is the \textit{process} of trying to show that the model is \textit{not incorrect}. The more checks one carries out which show that it is not incorrect, the more confidence we can place in the model's validity. To tackle such a problem in software, engineers have developed the concept of test-driven development (TDD).

TDD was popularised in the early 2000s by Kent Beck \cite{beck_test_2002} as a more agile approach to software engineering, where instead of doing each step (requirements, implementation, testing, delivery) separately from each other, all of them are combined in shorter cycles. In short in TDD tests are written for each feature before actually implementing it. Then, the feature is fully implemented and the tests for it should pass. This cycle is repeated until the implementation of all the requirements has finished. Traditionally, TDD relies on so called unit tests which can be understood as a piece of code which when run isolated, tests some functionality of an implementation. Thus, we can say that test-driven development in general and unit testing, together with some measure of code coverage in particular, guarantee the correctness of an implementation to some informal degree. This level of accuracy has been proven to be sufficient through years of practice in the software industry all over the world. 

\medskip

\section{Related Work}
The work \cite{collier_test-driven_2013} was the first to discuss how to apply TDD to ABS, using unit testing to verify the correctness of the implementation up to a certain level. They show how to implement unit tests within the RePast Framework \cite{north_complex_2013} and make the important point that such a software needs to be designed to be sufficiently modular otherwise testing becomes too cumbersome and involves too many parts. The paper \cite{asta_investigation_2014} discusses a similar approach to Discrete Event Simulation in the AnyLogic software toolkit. 

The paper \cite{onggo_test-driven_2016} proposes Test Driven Simulation Modelling (TDSM) which combines techniques from TDD to simulation modelling. The authors present a case study for maritime search operations where they employ ABS. They emphasise that simulation modelling is an iterative process, where changes are made to existing parts, making a TDD approach to simulation modelling a good match. They present how to validate their model against analytical solutions from theory using unit tests. They do this by running the whole simulation within a unit test and then perform a statistical comparison against a formal specification. %This approach will become of importance later on in our SIR and Sugarscape case studies.

The paper \cite{gurcan_generic_2013} gives an in-depth and detailed overview over verification, validation and testing of agent-based models and simulations and proposes a generic framework for it. The authors present a generic UML class model for their framework which they then implement in the two ABS frameworks RePast and MASON. Both of them are implemented in Java and the authors provide a detailed description of how their generic testing framework architecture works and how it utilises unit testing with JUnit to run automated tests. To demonstrate their framework they also provide a case study of an ABS of synaptic connectivity where they provide an in-depth explanation of their levels of tests together with code.

\section{Towards Property-Based Testing}
According to \cite{diehl_wishknewhaskell}, unit testing in Haskell is quite common and robust but generally speaking, it tends to be of less importance in Haskell since the type system makes an enormous amount of invalid programs completely inexpressible by construction. Unit tests tend to be written later in the development lifecycle and also tend to be about the core logic of the program and not the intermediate plumbing \cite{diehl_wishknewhaskell}. Additionally, this thesis claims that unit testing is not a very fitting tool for testing of ABS implementations, which is also reflected in the low number of research existing on this topic. The reason for it, we claim, is that the deterministic nature of unit testing, where each test case needs to be constructed manually, does not match the stochastic nature of ABS very well.

Thus, in this chapter we introduce an additional technique for TDD, \textit{property-based testing}, which can be seen as complementary to unit testing. Property-based testing has its origins in Haskell \cite{claessen_quickcheck_2000,claessen_testing_2002,runciman_smallcheck_2008}, where it was first conceived and implemented. It has been successfully used for testing Haskell code for years and has also been proven to be useful in the industry \cite{hughes_quickcheck_2007}. We show and discuss how this technique can be applied to test pure functional ABS implementations. To our best knowledge property-based testing has never been looked at in the context of ABS and this thesis is the first one to do so.

\medskip

The main idea of property-based testing is to express model specifications and laws directly in code and test them through \textit{automated} and \textit{randomised} test data generation. Thus, a central hypothesis of this thesis is that due to ABS's \textit{stochastic}, \textit{exploratory}, \textit{generative} and \textit{constructive} nature, property-based testing is a natural fit for testing ABS in general and pure functional ABS implementations in particular. It should consequently pose a valuable addition to the already existing testing methods in this field, which is worth exploring.

To substantiate and test our hypothesis, we conduct a few case studies. First, we look into how to express and test agent specifications for both the time and event-driven SIR implementations in Chapter \ref{ch:agentspec}. Then we show how to encode model invariants of the SIR implementation and validate it against the formal specification from System Dynamics using property tests in Chapter \ref{ch:sir_invariants}. We explicitly exclude obvious applications of property-based testing, for example boundary checks of the environment and helper functions of agents. Although they are used within an ABS implementation, there is nothing new in testing them.

\medskip

Property-based testing has close connections to model checking \cite{mcmillan_symbolic_1993}, where properties of a system are proved in a formal way. The important difference is that in property-based testing the checking happens directly in code and not on the abstract, formal model. Consequently, one can say that property-based testing combines model checking and unit testing, embedding it directly in the software development and TDD process without an intermediary step. We think that adding it to the already existing testing methods in the field of ABS is of substantial value as it allows for covering a much wider range of test cases due to automatic data generation. This can be used in two ways. First, to verify an implementation against a formal specification and second, to test hypotheses about an implemented simulation. This puts property-based testing on the same level as agent and system testing, where the technical implementation details are not checked as in unit tests, but their individual complete behaviour and the system behaviour as a whole is reviewed.

The work \cite{onggo_test-driven_2016} explicitly mentions the problem of test coverage which would often require manually writing a large number of tests to cover the parameter ranges sufficiently. Property-based testing addresses exactly this problem by \textit{automating} the test data generation. This is closely related to data generators \cite{gurcan_generic_2013}, load generators and random testing \cite{burnstein_practical_2010}. Property-based testing, however, goes one step further by integrating this into a specification language directly into code, emphasising a declarative approach and pushing the generators behind the scenes, making them transparent and focusing on the specification rather than on data generation. 

\input{./tex/research/property/proptesting.tex}