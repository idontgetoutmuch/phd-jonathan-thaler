\chapter{Parallel ABS}
\label{ch:parallel_abs}
In the introduction in Chapter \ref{ch:motivation}, this thesis hypothesised that functional programming should allow to easily apply parallel computation to ABS. The subsequent two chapters tests this hypothesis by performing a deeper investigation of the potential of parallel programming offered by pure functional programming to apply to ABS. An additional motivation for this undertaking are the notorious performance problems of our time- and event-driven implementations, and the work in these chapters can be seen as an attempt to at least mitigate the notorious performance problems of functional programming.

\medskip

It is reasonable to say that pure functional programming as in Haskell is well known and accepted as a remedy against the difficulties and problems of parallel computation \cite{hudak_history_2007}. The reason for it is that immutable data and explicit control of side effects removes a large class of bugs due to data conflicts and data races. A fundamental benefit and strength of Haskell is that it clearly distinguishes between parallelism and concurrency \textit{in its types} \cite{jones_tackling_2002}. It is very important for us to do so as well:

\begin{itemize}
	\item \textbf{Parallelism} - in parallelism, code runs in parallel solely for the purpose of doing more work within the same time, without interfering with other code through shared data (references, mutexes, semaphores,...). An example is the function \texttt{map :: (a $\rightarrow$ b) $\rightarrow$ [a] $\rightarrow$ [b]}, which maps each element of type \texttt{a} to \texttt{b} using the function \texttt{(a $\rightarrow$ b)}. It is a pure function and thus no sharing of data either through some monadic context or through the function \texttt{(a $\rightarrow$ b)} is possible. This opens the potential to run it in parallel as each function evaluation \texttt{(a $\rightarrow$ b)} could theoretically be executed at the same time, if we had enough CPU cores. Whether it runs actually in parallel or not has no influence on the outcome as it is not subject to any non-deterministic influences. Thus we identify parallelism with pure and deterministic execution of data transformations in parallel (data parallelism).

	\item \textbf{Concurrency} - concurrency refers to the decomposability property of a program, algorithm, or problem into order-independent or partially-ordered components or units \cite{lamport_time_1978}. Those parts \textit{can} be run in parallel which as a consequence \textit{might} give rise to asynchronous, non-deterministic events \footnote{The functional \textit{concurrent} programming language Erlang \cite{armstrong_erlang_2010}, which uses the actor model for its concurrency model, was single threaded from its conception in 1986 until around 2008. This might sound surprising but underlines the fact that concurrency per se has nothing to do with parallel execution.}.

	An example are two threads, running in parallel, which share data through a reference. Depending on the scheduling and the code which is run in each thread, this gives rise to very different access patterns - the events - to the shared data, with the potential for race conditions and dirty reads. In concurrency, per definition ordering is important and the challenge of implementing parallel, concurrent programs, is to write the program in a way that despite of these non-deterministic events it is still a correctly working program. Thus, we identify concurrency with parallel, impure, non-deterministic execution of imperative-style and ordered monadic evaluation.
\end{itemize}

In the next two chapters we investigate the application of both parallelism and concurrency to our pure functional ABS approach. In general, we want to see if and how parallel and concurrent programming in Haskell is transferable to pure functional ABS and what the benefits are. In particular we are interested in speeding up the existing implementations by generally developing techniques that allow us to  \textit{run agents in parallel \footnote{We use the term \textit{parallel} to identify both \textit{parallelism} and \textit{concurrency} and we distinguish between them whenever necessary using their respective terms.}}. 

The focus here is primarily on the conceptual nature of how to apply parallelism and concurrency to pure functional ABS, thus we refrain from doing in-depth performance analysis up-front as it is beyond the scope of this work. Still, we are very well aware that mindlessly trying to apply parallel computation can actually result in loss of performance as a problem can only be sped up in so far as we can partition it and run those partitions in parallel. Further, parallel computation comes with an overhead and if the partitioning is too fine-grained, this overhead might eat up the speedup or make it even worse. Thus, in real-world problems, performance measurements have to come first, then one can investigate where and why the performance is lost. Only if this is understood properly one can decide whether parallelism or concurrency is applicable - or none at all because the problem is actually completely sequential. %As D. Knuth famously put it: \textit{"Premature optimisation is the root of all evil"}, thus, when we see adding parallel computation as one way of optimising a problem, we need hard facts instead of wild guesses.

Besides performance improvement, we are generally interested in the implications of the way Haskell deals with parallelism and concurrency in its types. In particular we ask about the ability of keeping deterministic guarantees about the reproducibility of our simulations. We hypothesise that parallelism will allow us to retain \textit{all} static guarantees about reproducibility \textit{and} gives us a noticeable speedup. Further, we hypothesise, that in concurrency we might see a bigger speedup but sacrifice the very guarantee about reproducibility. However, we assume that by using Haskell's unique approach to Software Transactional Memory, we don't lose this guarantee completely, but it will get weakened by guaranteeing that the non-deterministic influence is through concurrency only \textit{and nothing else}.

\input{./tex/research/parallelabs/parallelism.tex}

\input{./tex/research/parallelabs/concurrent.tex}